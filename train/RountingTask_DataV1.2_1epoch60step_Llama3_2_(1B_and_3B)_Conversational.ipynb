{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DoanNgocCuong/MiniProd_NLP3_LLM1_RoutingFastResponse_FineTuningT3_2025_DoanhNghiepAnhSon_/blob/main/train/RountingTask_DataV1.2_1epoch60step_Llama3_2_(1B_and_3B)_Conversational.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGzwlSh_Dces"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGQMUC7zDcew"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i22jwpfiDcex"
      },
      "source": [
        "**Read our [Gemma 3 blog](https://unsloth.ai/blog/gemma3) for what's new in Unsloth and our [Reasoning blog](https://unsloth.ai/blog/r1-reasoning) on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgzRh1JxDcex"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zHcnMLNMDcey"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLW1bNuIDcez"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "1c6384b1f212446abd327aa3d13091de",
            "7c1d74c2f15044af9fe4033077e7f7ae",
            "69a34e345a93486593ac6043f3458004",
            "09f2a0084d134dbe92402177266492b6",
            "7452ccb8a900428f8e92e0e1cb79ca22",
            "a12d857b48e849488cb897ebf978371a",
            "d0f5c5a096184bf18b2436b622b9ae2e",
            "16ee02d4b9054159a3897bf8105c903f",
            "23185bc9d81340a7a51d900570721665",
            "fa857b7a66ee4e1caac5e820f55a45b6",
            "4c321ed9a4f446e1ac577db35b555111",
            "baf7c96661bf4415a271112654b259f2",
            "4453329737c8482baf632a4dac7268b8",
            "9b2e4804311a4bbc86d91893732fe34f",
            "27b1e06990f9471ab885b6be8328e960",
            "dcd94f17eacd416fb18448496b024922",
            "287048456b4644d28e36a25266fdb6bc",
            "47eed36adad442d59853f8a1243d90e8",
            "a863698fa76f4de5ab960232ed367bf8",
            "ee48ecaab31d4df2a007f24e8346828e",
            "ee5f8ba2dec94153821f3bc81b59457b",
            "d5990b6766dc454fba8c81bfc6c7b1e4",
            "98285664db874bef8ca985d4cf2e1f98",
            "b705313e5fb34662a143f00ac1e72e81",
            "2ae08fe4e1844336814ab54d16807ee6",
            "4f4ada6605bd46b28aad94cb299a1667",
            "e24e40079d804d4f8607d4ecfd512423",
            "ba407c2e00fa4d24bed452f30b5634f6",
            "9d0f018c0207448b8c386f7526a30b5d",
            "f35a35a7881043ffad022b243e26d327",
            "d69e2407465448dfb2360c1dad38b0ff",
            "5cf7c623df60435ead23ade8189a25e2",
            "78361572656643dbba4ae7e0c93e67b9",
            "8bb9efb10f9544c8bdebdfa47699dda8",
            "a6b0e10816aa491399a90d8d6ef3d8bf",
            "aff7d7105b3949ada048dbabcb94676f",
            "a7eb4b7641fc4ecbacb49a4c69e02a05",
            "8faeb5a617fb48a2a4040059710942e9",
            "f02daceba54740c6956f204f77a08a4f",
            "8629eaef818349ccbda2ba25763c97a1",
            "19ca2662b396459195b2bf6c76f21297",
            "506095da4fcb41f4b25cf399c8eed31f",
            "6041f6abb32b4edb84a591ee4f11d19b",
            "7afbad83e0a743bdbc1f6ee9bf835ade",
            "4c9798584a174ab4ac499bcd2f1a10ed",
            "ba2037c504b64a3db24f725cce2afa6e",
            "c1d904edfd3f4efda7be1015c68d4a07",
            "3c8d9dce829e4389bf54d3d2dff32902",
            "533eb9d0e2a347908c77bcde4caf323f",
            "d244239f6107409e925a2838a354b741",
            "6fa5b2ba9b7d47c9aa9762e3af119d93",
            "05551557875a4640aa0073d692c7059a",
            "c8f6fa2912644d1ebdac0a59d8eb9dbf",
            "899d1a1d58714f1d902dbc1aa4dd21c9",
            "017876ee706e46ad8a6b501fb13ee20e"
          ]
        },
        "id": "8HIHvIjIDce0",
        "outputId": "6b1fbbd9-1b95-4f25-a4b1-3110029fa1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.3.18: Fast Llama patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c6384b1f212446abd327aa3d13091de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baf7c96661bf4415a271112654b259f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98285664db874bef8ca985d4cf2e1f98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bb9efb10f9544c8bdebdfa47699dda8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c9798584a174ab4ac499bcd2f1a10ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
        "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-1B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "ef727cf7-aa49-4c57-abda-4473c3c25a62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.18 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "I'm great thanks!<|eot_id|>\n",
        "```\n",
        "\n",
        "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "e68ee188d19d41f0a4bcdaae03ab507f",
            "4709697b6c984ade8286340931bb322f",
            "8aab516dd25d4dbba9a442a38f0f1675",
            "cdd25e0c0e9b432dbd14386b86baa23f",
            "fb6b52578aff4b2c9c69f7d0dd36647d",
            "a4a77d4f34524d0aa5ca353ea8b2203c",
            "d3faa712ce464b4aa314f3e3bfd3522f",
            "c2f0fd0badb54f0b9a9c632570d46a95",
            "a1d0aff021ec42cf80196a7ec7a3aae8",
            "cdd8aadb8dca437fa27a89c4485572c1",
            "47ceb466537a44a3aa1cbc1936c035c4",
            "c6a82899b3f844ce9729ada19592e71c",
            "7fa865db91204697b2b2f48b728cc1fd",
            "448d404648b04e518b5e7d36bb9a5cc5",
            "cafaa12878c14f6b9d2408599ac00306",
            "f725dc3f6d694996a80b36ea07b08597",
            "c204744f05a541958dbfba729f44726a",
            "4577563c881a4376a3b2ea4a22432384",
            "c0513a34e9524c069a9dd270ea438a17",
            "447774b34e4142049108ae0d2b0e4a88",
            "75149660c3ef43e1a5a7cf035684354d",
            "cad345523e7a40db90d8dbfd735e8387",
            "eeab2ee6dc8748bc8bad5698ab9deb88",
            "abe819fba71245d5942a0cca19d4ad90",
            "5081494531e04b9eba67cedbf2d54f10",
            "7fb7c8f739e949a7a1c05e96b8fe3f81",
            "3ad85c98d2494064b6268d1d92762e04",
            "c573e52a2a494e3989ed592e5da79289",
            "746bedf554884b95aabe9123a5c33599",
            "81831cba627e49c383ff94c884c2faa4",
            "842ef96b344a4511ad31591fd147edf3",
            "37bd22ef564d4aa8ae9c9e8bb3c10376",
            "142e10c4b2c7411884a7d2cea478ac00"
          ]
        },
        "id": "LjY75GoYUCB8",
        "outputId": "bb233819-d1cd-49ee-ade8-87227e98c77e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e68ee188d19d41f0a4bcdaae03ab507f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/982 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6a82899b3f844ce9729ada19592e71c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/117M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eeab2ee6dc8748bc8bad5698ab9deb88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "# tokenizer = get_chat_template(\n",
        "#     tokenizer,\n",
        "#     chat_template = \"llama-3.1\",\n",
        "# )\n",
        "\n",
        "# def formatting_prompts_func(examples):\n",
        "#     convos = examples[\"conversations\"]\n",
        "#     texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "#     return { \"text\" : texts, }\n",
        "# pass\n",
        "\n",
        "# from datasets import load_dataset\n",
        "# dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")\n",
        "\n",
        "# Nh·∫≠p h√†m get_chat_template t·ª´ module unsloth.chat_templates\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "# S·ª≠ d·ª•ng h√†m get_chat_template ƒë·ªÉ c·∫•u h√¨nh l·∫°i tokenizer theo template chat \"llama-3.1\"\n",
        "# L∆∞u √Ω: bi·∫øn tokenizer ph·∫£i ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a tr∆∞·ªõc ƒë√≥ ho·∫∑c ƒë∆∞·ª£c truy·ªÅn v√†o t·ª´ m·ªôt ngu·ªìn kh√°c\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,                      # Bi·∫øn tokenizer ƒë√£ c√≥\n",
        "    chat_template=\"llama-3.1\",      # Ch·ªçn template chat \"llama-3.1\" ƒë·ªÉ ƒë·ªãnh d·∫°ng c√°c cu·ªôc h·ªôi tho·∫°i\n",
        ")\n",
        "\n",
        "# ƒê·ªãnh nghƒ©a h√†m formatting_prompts_func v·ªõi tham s·ªë ƒë·∫ßu v√†o l√† examples\n",
        "def formatting_prompts_func(examples):\n",
        "    # L·∫•y danh s√°ch c√°c cu·ªôc h·ªôi tho·∫°i t·ª´ key \"conversations\" trong ƒë·ªëi t∆∞·ª£ng examples\n",
        "    convos = examples[\"conversations\"]\n",
        "    # √Åp d·ª•ng template chat cho m·ªói cu·ªôc h·ªôi tho·∫°i trong convos, kh√¥ng th·ª±c hi·ªán tokenize v√† kh√¥ng th√™m generation prompt\n",
        "    # K·∫øt qu·∫£ l√† danh s√°ch c√°c chu·ªói vƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
        "    # Tr·∫£ v·ªÅ m·ªôt dictionary v·ªõi key \"text\" ch·ª©a danh s√°ch c√°c chu·ªói vƒÉn b·∫£n ƒë√£ ƒë·ªãnh d·∫°ng\n",
        "    return {\"text\": texts,}\n",
        "\n",
        "# D√≤ng pass ·ªü ƒë√¢y kh√¥ng c√≥ t√°c d·ª•ng c·ª• th·ªÉ v√¨ ƒë√£ c√≥ return, c√≥ th·ªÉ ƒë∆∞·ª£c gi·ªØ l·∫°i ho·∫∑c lo·∫°i b·ªè t√πy √Ω\n",
        "pass\n",
        "\n",
        "# Nh·∫≠p h√†m load_dataset t·ª´ th∆∞ vi·ªán datasets ƒë·ªÉ t·∫£i b·ªô d·ªØ li·ªáu\n",
        "from datasets import load_dataset\n",
        "\n",
        "# T·∫£i b·ªô d·ªØ li·ªáu \"mlabonne/FineTome-100k\" v·ªõi ph·∫ßn d·ªØ li·ªáu hu·∫•n luy·ªán (split=\"train\")\n",
        "dataset = load_dataset(\"mlabonne/FineTome-100k\", split=\"train\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFOddryqGby-",
        "outputId": "287e31e9-b986-4c16-8bd8-6b8a6b18caa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['conversations', 'source', 'score'],\n",
            "    num_rows: 100000\n",
            "})\n",
            "M·∫´u d·ªØ li·ªáu th·ª© 0:  {'conversations': [{'from': 'human', 'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'}, {'from': 'gpt', 'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}], 'source': 'infini-instruct-top-500k', 'score': 5.212620735168457}\n",
            "M·∫´u d·ªØ li·ªáu th·ª© 1:  {'conversations': [{'from': 'human', 'value': 'Explain how recursion works and provide a recursive function in Python that calculates the factorial of a given number.'}, {'from': 'gpt', 'value': \"Recursion is a programming technique where a function calls itself to solve a problem. It breaks down a complex problem into smaller, more manageable subproblems until a base case is reached. The base case is a condition where the function does not call itself, but instead returns a specific value or performs a specific action.\\n\\nIn the case of calculating the factorial of a number, recursion can be used to break down the problem into simpler subproblems. The factorial of a non-negative integer n is the product of all positive integers less than or equal to n.\\n\\nHere is a recursive function in Python that calculates the factorial of a given number:\\n\\n```python\\ndef factorial(n):\\n    # Base case: factorial of 0 or 1 is 1\\n    if n == 0 or n == 1:\\n        return 1\\n    # Recursive case: factorial of n is n multiplied by factorial of (n-1)\\n    else:\\n        return n * factorial(n - 1)\\n```\\n\\nIn this function, the base case is when n equals 0 or 1, as the factorial of these numbers is defined as 1. For any other positive integer, the function calls itself with a smaller value (n-1) and multiplies the result by n.\\n\\nFor example, let's calculate the factorial of 5 using this function:\\n\\n```python\\nprint(factorial(5))\\n```\\n\\nThe function will execute as follows:\\n1. factorial(5) calls factorial(4) and multiplies the result by 5.\\n2. factorial(4) calls factorial(3) and multiplies the result by 4.\\n3. factorial(3) calls factorial(2) and multiplies the result by 3.\\n4. factorial(2) calls factorial(1) and multiplies the result by 2.\\n5. factorial(1) is a base case and returns 1.\\n6. The final result is calculated as: 5 * 4 * 3 * 2 * 1 = 1\"}], 'source': 'infini-instruct-top-500k', 'score': 5.157649040222168}\n",
            "M·∫´u d·ªØ li·ªáu th·ª© 2:  {'conversations': [{'from': 'human', 'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions.\\n\\nFurthermore, discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. Finally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions.'}, {'from': 'gpt', 'value': 'Boolean operators are logical operators used to combine or manipulate boolean values in programming. They allow you to perform comparisons and create complex logical expressions. The three main boolean operators are:\\n\\n1. AND operator (&&): Returns true if both operands are true. Otherwise, it returns false. For example:\\n   - `true && true` returns true\\n   - `true && false` returns false\\n\\n2. OR operator (||): Returns true if either of the operands is true. Otherwise, it returns false. For example:\\n   - `true || false` returns true\\n   - `false || false` returns false\\n\\n3. NOT operator (!): Returns the opposite of the operand\\'s boolean value. If the operand is true, it returns false, and vice versa. For example:\\n   - `!true` returns false\\n   - `!false` returns true\\n\\nBoolean operators are commonly used in conditional statements and loops to control the flow of execution based on certain conditions. They help make decisions and determine the truthiness or falsiness of expressions.\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. In programming languages, certain operators have higher precedence than others, and they are evaluated first. For example, in the expression `a && b || c`, the && operator has higher precedence than the || operator, so `a && b` is evaluated first, and then the result is combined with c using ||.\\n\\nParentheses can be used to alter the precedence of operators. For example, `(a && b) || c` ensures that the && operator is evaluated before the || operator.\\n\\nShort-circuit evaluation is a behavior exhibited by some programming languages when evaluating boolean expressions. In short-circuit evaluation, the evaluation stops as soon as the final result is determined. For example, in the expression `a && b`, if a is false, there is no need to evaluate b because the overall result will always be false. Similarly, in the expression `a || b`, if a is true, there is no need to evaluate b because the overall result will always be true. This behavior can be useful for optimizing code and preventing unnecessary evaluations.\\n\\nHere are examples demonstrating short-circuit evaluation in code:\\n\\n```python\\n# Example 1\\na = False\\nb = True\\nif a and b:  # Since a is False, b is not evaluated\\n    print(\"This line won\\'t be executed\")\\n\\n# Example 2\\nx = 10\\ny = 0\\nif y != 0 and x / y > 2:  # Since y is 0, the division is not evaluated to avoid division by zero error\\n    print(\"This line won\\'t be executed\")\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are treated as booleans in certain contexts. In many programming languages, values other than true or false can be implicitly converted to boolean values. In this context, truthiness means that a value evaluates to true, and falsiness means that a value evaluates to false.\\n\\nIn most programming languages, the following values are considered falsy:\\n- false\\n- 0 (zero)\\n- \"\" (empty string)\\n- null or undefined\\n- NaN (not-a-number)\\n\\nAll other values are considered truthy.\\n\\nTruthiness and falsiness affect the evaluation of boolean expressions. For example, in an if statement, if the condition is a non-boolean value, it will be implicitly converted to a boolean value based on its truthiness or falsiness.\\n\\n```javascript\\n// Example\\nlet value = 0;\\nif (value) {\\n    console.log(\"This line won\\'t be executed\"); // value is falsy, so the condition is false\\n}\\n```\\n\\nUnderstanding boolean operators, operator precedence, short-circuit evaluation, and truthiness/falsiness is crucial for writing effective and correct code, especially in conditional logic.'}], 'source': 'infini-instruct-top-500k', 'score': 5.147540092468262}\n",
            "M·∫´u d·ªØ li·ªáu th·ª© 3:  {'conversations': [{'from': 'human', 'value': 'Explain the concept of recursion with an example, while also implementing a recursive function in a programming language of your choice. Your implementation should include at least two base cases and demonstrate the proper use of recursive calls.'}, {'from': 'gpt', 'value': \"Recursion is a programming concept where a function calls itself to solve a problem by breaking it down into smaller, more manageable subproblems. Each recursive call works on a smaller portion of the problem until a base case is reached, at which point the recursion stops and the function returns the result.\\n\\nLet's explain recursion with an example of calculating the factorial of a number. The factorial of a non-negative integer n, denoted by n!, is the product of all positive integers less than or equal to n.\\n\\nHere's an example implementation of a recursive function to calculate the factorial in Python:\\n\\n```python\\ndef factorial(n):\\n    # Base case 1: factorial of 0 or 1 is 1\\n    if n == 0 or n == 1:\\n        return 1\\n\\n    # Recursive call: factorial of n is n multiplied by factorial of (n-1)\\n    return n * factorial(n - 1)\\n```\\n\\nIn this implementation, we have two base cases. When n is 0 or 1, we know that the factorial is 1, so we return 1 to stop the recursion.\\n\\nFor any other positive integer n, we make a recursive call to the factorial function with n - 1. This breaks down the problem into smaller subproblems until one of the base cases is reached.\\n\\nHere's an example usage of the factorial function:\\n\\n```python\\nprint(factorial(5))  # Output: 120\\n```\\n\\nWhen we call `factorial(5)`, it starts the recursion process. The function calculates `5 * factorial(4)`, which further calculates `4 * factorial(3)`, and so on. Eventually, the recursion reaches the base case of `factorial(1)`, which returns 1. The intermediate results are then propagated back, and the final result of `5 * 4 * 3 * 2 * 1` is returned, which equals 1\"}], 'source': 'infini-instruct-top-500k', 'score': 5.053655624389648}\n",
            "M·∫´u d·ªØ li·ªáu th·ª© 4:  {'conversations': [{'from': 'human', 'value': 'Print the reverse of a string using a for loop.'}, {'from': 'gpt', 'value': 'Here is an example code using a for loop to print the reverse of a string along with a detailed docstring:\\n\\n```python\\ndef print_reverse_string(string):\\n    \"\"\"\\n    Prints the reverse of a given string using a for loop.\\n\\n    Parameters:\\n    string (str): The string to be reversed and printed.\\n\\n    Returns:\\n    None.\\n    \"\"\"\\n\\n    # Iterate through the characters of the string in reverse order\\n    for i in range(len(string)-1, -1, -1):\\n        print(string[i], end=\\'\\')\\n\\n    # Print a new line after printing the whole reversed string\\n    print()\\n\\n# Example usage\\ninput_string = input(\"Enter a string: \")\\nprint_reverse_string(input_string)\\n```\\n\\nIn this code, the `print_reverse_string` function takes a string as input. It uses a for loop to iterate through the characters of the string in reverse order. The for loop starts from the index of the last character (`len(string)-1`) and goes until the first character (`-1`), with a step of `-1`. In each iteration, the function prints the character using the `print` function and `end=\\'\\'` is used to avoid printing the default newline character after each character. Finally, after printing the whole reversed string, `print()` is called to print a new line.'}], 'source': 'infini-instruct-top-500k', 'score': 5.045647621154785}\n"
          ]
        }
      ],
      "source": [
        "# In ra th√¥ng tin t·ªïng quan c·ªßa dataset\n",
        "print(dataset)\n",
        "\n",
        "# In ra 5 m·∫´u d·ªØ li·ªáu ƒë·∫ßu ti√™n trong dataset\n",
        "for i in range(5):\n",
        "    print(f\"M·∫´u d·ªØ li·ªáu th·ª© {i}: \", dataset[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NOEtNJvNg-C",
        "outputId": "40a07253-7918-4e3b-a35f-2e4576e69d0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'from': 'human',\n",
              "  'value': 'How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?'},\n",
              " {'from': 'gpt',\n",
              "  'value': 'Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.'}]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[5][\"conversations\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "We now use `standardize_sharegpt` to convert ShareGPT style datasets into HuggingFace's generic format. This changes the dataset from looking like:\n",
        "```\n",
        "{\"from\": \"system\", \"value\": \"You are an assistant\"}\n",
        "{\"from\": \"human\", \"value\": \"What is 2+2?\"}\n",
        "{\"from\": \"gpt\", \"value\": \"It's 4.\"}\n",
        "```\n",
        "to\n",
        "```\n",
        "{\"role\": \"system\", \"content\": \"You are an assistant\"}\n",
        "{\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
        "{\"role\": \"assistant\", \"content\": \"It's 4.\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dXTSyNynI5-H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "64013e3effda4ef69c70a594dee38c52",
            "8e0c1d99321547f49263bec84dcda4bb",
            "4859770bd8f04f09aec5e52f7253d7b6",
            "26f5a1ec2e7549f19ac3bff1dfd54d07",
            "d1cd17b85c1c4634a06991bae10a42b6",
            "82c0e3ffbf344f2ab2db5a560112925d",
            "afd2a2e6db0041be993f9c402a3691bc",
            "03c07ba76cdf42468333d70f1a2a60de",
            "e93a06aa6e504616890890eb80dc23c7",
            "1e2bff362abb474ba86bd044c58f292c",
            "e801fc7156854a61b049432c17b4abba",
            "588d180dd44f42bc95dafc198e40191f",
            "3f573ea4e5554044b4019374859b50b9",
            "1b463ba27b514b73861066a86b410b51",
            "d19900d70c0245baa491690339acb455",
            "0d6209bf037b49be8127d2dc262361b4",
            "ce47bc3177604cd2ad4da725dd32d803",
            "aa7146540c344f1b9b69f2daa54977e8",
            "250257655a514463819c8a9e3719dcd2",
            "058d6688c859483aae3d4208f4675b4c",
            "5a8ac1b0b9184b168dd0a1370ef64f07",
            "2d5734dad68f4fe4a95d129fe48686f5"
          ]
        },
        "id": "oPXzJZzHEgXe",
        "outputId": "0338fc3d-6cf5-4d4b-fe81-3542c7dfb0e1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64013e3effda4ef69c70a594dee38c52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Standardizing formats (num_proc=2):   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "588d180dd44f42bc95dafc198e40191f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from unsloth.chat_templates import standardize_sharegpt\n",
        "# dataset = standardize_sharegpt(dataset)\n",
        "# dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "\n",
        "# Nh·∫≠p h√†m standardize_sharegpt t·ª´ module unsloth.chat_templates ƒë·ªÉ chu·∫©n h√≥a ƒë·ªãnh d·∫°ng d·ªØ li·ªáu\n",
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "\n",
        "# S·ª≠ d·ª•ng h√†m standardize_sharegpt ƒë·ªÉ chu·∫©n h√≥a dataset v·ªÅ ƒë·ªãnh d·∫°ng sharegpt\n",
        "dataset = standardize_sharegpt(dataset)\n",
        "\n",
        "# √Åp d·ª•ng h√†m formatting_prompts_func cho t·ª´ng m·∫´u trong dataset b·∫±ng c√°ch s·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c map\n",
        "# Tham s·ªë batched=True cho ph√©p x·ª≠ l√Ω nhi·ªÅu m·∫´u c√πng l√∫c, gi√∫p tƒÉng hi·ªáu qu·∫£ khi √°p d·ª•ng h√†m\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE9zYJjIHnyE"
      },
      "source": [
        "H·ªèi:\n",
        "```\n",
        "H√†m n√†y ch·ªâ x·ª≠ l√Ω conversations thui ch·ª© source, v·ªõi score ko x·ª≠ l√Ω nh·ªâ. gi·ªù t√¥i ƒëang c√≥ 1 b·ªô dataset kh√°c √Ω n√≥ c√≥ conversations ko c√≥ source v·ªõi score\n",
        "```\n",
        "=> ƒê√∫ng v·∫≠y. H√†m `formatting_prompts_func` m√† b·∫°n ƒë√£ ƒë·ªãnh nghƒ©a ch·ªâ t·∫≠p trung x·ª≠ l√Ω tr∆∞·ªùng `conversations`, c√≤n c√°c tr∆∞·ªùng nh∆∞ `source` v√† `score` kh√¥ng ƒë∆∞·ª£c ·∫£nh h∆∞·ªüng. N·∫øu b·∫°n c√≥ m·ªôt b·ªô dataset kh√°c m√† ch·ªâ ch·ª©a tr∆∞·ªùng `conversations` (kh√¥ng c√≥ `source` v√† `score`), th√¨ h√†m n√†y v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng, v√¨ n√≥ ch·ªâ l·∫•y v√† x·ª≠ l√Ω n·ªôi dung c·ªßa `conversations` ƒë·ªÉ t·∫°o ra c√°c prompt ƒë·ªãnh d·∫°ng. B·∫°n kh√¥ng c·∫ßn thay ƒë·ªïi g√¨ n·∫øu b·∫°n ch·ªâ mu·ªën x·ª≠ l√Ω cu·ªôc h·ªôi tho·∫°i.\n",
        "\n",
        "H·ªèi:\n",
        "```\n",
        "t·ª©c l√† n·∫øu n√≥ chu·∫©n r·ªìi th√¨ sao, ki·ªÉu data c·ªßa m√¨nh ƒë√£ chu·∫©n lu√¥n system - user - assistant r·ªìi\n",
        "```\n",
        "\n",
        "\n",
        "N·∫øu d·ªØ li·ªáu c·ªßa b·∫°n ƒë√£ c√≥ c·∫•u tr√∫c chu·∫©n (c√°c tin nh·∫Øn ƒë√£ c√≥ kh√≥a \"role\" v√† \"content\", v·ªõi gi√° tr·ªã c·ªßa \"role\" l√† \"system\", \"user\", \"assistant\"), th√¨ h√†m `standardize_data_formats` v·∫´n s·∫Ω th·ª±c hi·ªán c√°c b∆∞·ªõc ki·ªÉm tra v√† √°nh x·∫° nh∆∞ b√¨nh th∆∞·ªùng. C·ª• th·ªÉ:\n",
        "\n",
        "- H√†m s·∫Ω duy·ªát qua m·ªôt s·ªë m·∫´u t·ª´ tr∆∞·ªùng `conversations` v√† l·∫•y ra c√°c kh√≥a c·ªßa t·ª´ng tin nh·∫Øn.  \n",
        "- N√≥ s·∫Ω nh·∫≠n th·∫•y r·∫±ng c√≥ ƒë√∫ng 2 kh√≥a (gi·∫£ s·ª≠ l√† `\"role\"` v√† `\"content\"`).  \n",
        "- Sau ƒë√≥, d·ª±a v√†o s·ªë l∆∞·ª£ng gi√° tr·ªã duy nh·∫•t, n√≥ s·∫Ω x√°c ƒë·ªãnh kh√≥a n√†o l√† vai tr√≤ (role) v√† kh√≥a n√†o l√† n·ªôi dung (content).  \n",
        "- Ti·∫øp theo, n√≥ s·∫Ω ki·ªÉm tra c√°c gi√° tr·ªã c·ªßa kh√≥a vai tr√≤ c√≥ n·∫±m trong t·∫≠p c√°c alias ƒë√£ ƒë·ªãnh nghƒ©a hay kh√¥ng. N·∫øu d·ªØ li·ªáu c·ªßa b·∫°n ƒë√£ chu·∫©n th√¨ c√°c gi√° tr·ªã n√†y ƒë√£ l√† `\"system\"`, `\"user\"` ho·∫∑c `\"assistant\"` n√™n s·∫Ω kh·ªõp v·ªõi alias ƒë√£ ƒë∆∞·ª£c mapping.  \n",
        "- Cu·ªëi c√πng, m·ªói tin nh·∫Øn s·∫Ω ƒë∆∞·ª£c x√¢y d·ª±ng l·∫°i v·ªõi ƒë·ªãnh d·∫°ng: `{\"role\": <role chu·∫©n>, \"content\": <n·ªôi dung>}`. N·∫øu d·ªØ li·ªáu ƒë√£ chu·∫©n, k·∫øt qu·∫£ cu·ªëi c√πng s·∫Ω gi·ªëng v·ªõi d·ªØ li·ªáu ban ƒë·∫ßu.\n",
        "\n",
        "T√≥m l·∫°i, n·∫øu d·ªØ li·ªáu c·ªßa b·∫°n ƒë√£ chu·∫©n, h√†m n√†y s·∫Ω kh√¥ng thay ƒë·ªïi n·ªôi dung, m√† ch·ªâ \"t√°i ƒë√≥ng g√≥i\" d·ªØ li·ªáu theo ƒë√∫ng ƒë·ªãnh d·∫°ng ti√™u chu·∫©n c·ªßa Hugging Face. B·∫°n c√≥ th·ªÉ ch·∫°y h√†m n√†y m√† kh√¥ng lo b·ªã l·ªói, nh∆∞ng v·ªÅ c∆° b·∫£n n√≥ s·∫Ω kh√¥ng t·∫°o ra s·ª± kh√°c bi·ªát so v·ªõi d·ªØ li·ªáu ban ƒë·∫ßu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for item 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFzmplrEy9I",
        "outputId": "7f7abf2d-98e3-4ecc-c65d-09969aed6312"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'content': 'How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?',\n",
              "  'role': 'user'},\n",
              " {'content': 'Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.',\n",
              "  'role': 'assistant'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[5][\"conversations\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfzTdMtvGE6w"
      },
      "source": [
        "And we see how the chat template transformed these conversations.\n",
        "\n",
        "**[Notice]** Llama 3.1 Instruct's default chat template default adds `\"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\"`, so do not be alarmed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "vhXv0xFMGNKE",
        "outputId": "94f4e2f2-0a00-4409-eb8c-929b2144a750"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed_vNxySOA9Z"
      },
      "source": [
        "### ‚úÖ T√≥m t·∫Øt qu√° tr√¨nh chu·∫©n h√≥a v√† ƒë·ªãnh d·∫°ng d·ªØ li·ªáu v·ªõi `standardize_sharegpt` + `formatting_prompts_func`\n",
        "\n",
        "1. **`standardize_sharegpt(dataset)`**  \n",
        "   ‚Üí Chuy·ªÉn d·ªØ li·ªáu v·ªÅ ƒë·ªãnh d·∫°ng chu·∫©n ki·ªÉu ShareGPT:\n",
        "   - M·ªói tin nh·∫Øn c√≥ d·∫°ng `{\"from\": ..., \"value\": ...}`\n",
        "   - Chuy·ªÉn `from = \"human\"` th√†nh `\"user\"`, `\"gpt\"` th√†nh `\"assistant\"` ƒë·ªÉ ƒë·ªìng b·ªô vai tr√≤.\n",
        "\n",
        "2. **`dataset.map(formatting_prompts_func, batched=True)`**  \n",
        "   ‚Üí Duy·ªát t·ª´ng h·ªôi tho·∫°i, √°p d·ª•ng **chat template** ƒë·ªÉ t·∫°o chu·ªói ƒë·ªãnh d·∫°ng c√≥ token ƒë·∫∑c bi·ªát:\n",
        "   - Sinh ra tr∆∞·ªùng `\"text\"` ch·ª©a n·ªôi dung ƒë√£ ƒë∆∞·ª£c ch√®n c√°c th·∫ª nh∆∞:  \n",
        "     `<|begin_of_text|>`, `<|start_header_id|>user<|end_header_id|>`, `<|eot_id|>`, v.v.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ **M·ª•c ti√™u**:  \n",
        "ƒê·ªãnh d·∫°ng l·∫°i h·ªôi tho·∫°i sao cho m√¥ h√¨nh d·ªÖ hi·ªÉu vai tr√≤ `system`, `user`, `assistant` v√† ng·ªØ c·∫£nh t·ª´ng l∆∞·ª£t n√≥i.\n",
        "\n",
        "üìå **K·∫øt qu·∫£**:  \n",
        "Dataset c√≥ th√™m c·ªôt `\"text\"` ‚Üí d√πng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh ng√¥n ng·ªØ theo phong c√°ch chat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVZKVOKpKbJf"
      },
      "source": [
        "## My Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "72e8f2ad4c5149bab1ae408fbb7256b2",
            "e80052a8c8b841bba8deeb1932026498",
            "78599ca1e4b5497d923fffef679b5b9b",
            "deb38efb9cc24884a5791146222588f3",
            "1ab62048a3e6404f86f6f06bfc9b6f09",
            "18d327df941f44ef80c83ce64e70cfbc",
            "84e1da25e8e74367baa91f079f32a894",
            "c756e9df18a74abb8a077f1afe4fec4f",
            "def75a05364f447096be1e47fb0802f7",
            "85a83f0d471f4d7dadc74c504a93e6bb",
            "38629e76fb6f4d60b9f4ef878f735a86",
            "d04c5cdf93ae4632a0bfa75a3577ec43",
            "ebef9e31e63d4909ba0067eeef482e37",
            "d951a1aca8ab4bf5baa32b9051507e7c",
            "57da248e03014383abaed60ea25d85f1",
            "e8ed858cc8c448b5a02fd5666a0e5749",
            "940233f16aaf437c8c6fbb2eeb225cb6",
            "049d88b5159a44dc9d5a2e6c49eddc71",
            "3f4d3686e13342eea8c4bb8195ef11de",
            "f3d1352f4c404c9d8884eac634fc15a1",
            "da578300a4f149f2b49131f86285b4a3",
            "940fc2a62f7b4d6d944c4472aaa893d4"
          ]
        },
        "id": "dCOl1LRm4akb",
        "outputId": "375445bf-1504-4599-c513-2b9f08ffba41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D·ªØ li·ªáu g·ªëc (5 d√≤ng ƒë·∫ßu):\n",
            "                                       conversations\n",
            "0  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "1  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "2  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "3  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "4  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "\n",
            "Ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n c·ªßa my_dataset tr∆∞·ªõc khi chu·∫©n h√≥a:\n",
            "{'conversations': [{'content': 'You are an intelligent task classification and response generation assistant.\\nYour job is to analyze user commands and generate structured JSON responses according to the correct task category.\\n\\nYou will be given a User Input ‚Äì a natural language command from the user.\\n\\nYour task is to:\\n1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\\n- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\\n2. Determine the appropriate action based on user intent:\\n   - \"todo\" ‚Üí [create, get_all, update, delete, complete]\\n   - \"todo_with_calendar\" ‚Üí [create, get_upcoming, get_past, get_now, update, delete, invite]\\n   - \"email\" ‚Üí [compose, get_inbox, reply, save_draft, delete, mark_important]\\n   - \"article\" ‚Üí [create, get_all, get_published, update, delete, publish, save_draft]\\n   - \"thutuchanhchinh\" ‚Üí [lookup_inf]\\n\\n3. Extract any relevant summary_task and event_time.\\n\\nRespond ONLY with a valid JSON object following this exact template:\\n{\\n  \"tool\": \"<tool>\",\\n  \"action\": \"<action>\",\\n  \"details\": {\\n    \"summary_task\": \"<summary>\",\\n    \"event_time\": \"<time or null>\"\\n  }\\n}\\n\\nDO NOT explain. DO NOT include markdown. DO NOT add extra text.', 'role': 'system'}, {'content': 'Ti·∫øp t·ª•c h·ªçc ti·∫øng anh', 'role': 'user'}, {'content': '\\n{\\n  \"tool\": \"todo\",\\n  \"action\": \"create\",\\n  \"details\": {\\n    \"summary_task\": \"Ti·∫øp t·ª•c h·ªçc ti·∫øng Anh\",\\n    \"event_time\": null\\n  }\\n}\\n', 'role': 'assistant'}]}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72e8f2ad4c5149bab1ae408fbb7256b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Unsloth: Standardizing formats (num_proc=2):   0%|          | 0/3892 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d04c5cdf93ae4632a0bfa75a3577ec43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3892 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n sau khi chu·∫©n h√≥a:\n",
            "{'conversations': [{'content': 'You are an intelligent task classification and response generation assistant.\\nYour job is to analyze user commands and generate structured JSON responses according to the correct task category.\\n\\nYou will be given a User Input ‚Äì a natural language command from the user.\\n\\nYour task is to:\\n1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\\n- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\\n2. Determine the appropriate action based on user intent:\\n   - \"todo\" ‚Üí [create, get_all, update, delete, complete]\\n   - \"todo_with_calendar\" ‚Üí [create, get_upcoming, get_past, get_now, update, delete, invite]\\n   - \"email\" ‚Üí [compose, get_inbox, reply, save_draft, delete, mark_important]\\n   - \"article\" ‚Üí [create, get_all, get_published, update, delete, publish, save_draft]\\n   - \"thutuchanhchinh\" ‚Üí [lookup_inf]\\n\\n3. Extract any relevant summary_task and event_time.\\n\\nRespond ONLY with a valid JSON object following this exact template:\\n{\\n  \"tool\": \"<tool>\",\\n  \"action\": \"<action>\",\\n  \"details\": {\\n    \"summary_task\": \"<summary>\",\\n    \"event_time\": \"<time or null>\"\\n  }\\n}\\n\\nDO NOT explain. DO NOT include markdown. DO NOT add extra text.', 'role': 'system'}, {'content': 'Ti·∫øp t·ª•c h·ªçc ti·∫øng anh', 'role': 'user'}, {'content': '\\n{\\n  \"tool\": \"todo\",\\n  \"action\": \"create\",\\n  \"details\": {\\n    \"summary_task\": \"Ti·∫øp t·ª•c h·ªçc ti·∫øng Anh\",\\n    \"event_time\": null\\n  }\\n}\\n', 'role': 'assistant'}], 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nYou are an intelligent task classification and response generation assistant.\\nYour job is to analyze user commands and generate structured JSON responses according to the correct task category.\\n\\nYou will be given a User Input ‚Äì a natural language command from the user.\\n\\nYour task is to:\\n1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\\n- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\\n2. Determine the appropriate action based on user intent:\\n   - \"todo\" ‚Üí [create, get_all, update, delete, complete]\\n   - \"todo_with_calendar\" ‚Üí [create, get_upcoming, get_past, get_now, update, delete, invite]\\n   - \"email\" ‚Üí [compose, get_inbox, reply, save_draft, delete, mark_important]\\n   - \"article\" ‚Üí [create, get_all, get_published, update, delete, publish, save_draft]\\n   - \"thutuchanhchinh\" ‚Üí [lookup_inf]\\n\\n3. Extract any relevant summary_task and event_time.\\n\\nRespond ONLY with a valid JSON object following this exact template:\\n{\\n  \"tool\": \"<tool>\",\\n  \"action\": \"<action>\",\\n  \"details\": {\\n    \"summary_task\": \"<summary>\",\\n    \"event_time\": \"<time or null>\"\\n  }\\n}\\n\\nDO NOT explain. DO NOT include markdown. DO NOT add extra text.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTi·∫øp t·ª•c h·ªçc ti·∫øng anh<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\\n{\\n  \"tool\": \"todo\",\\n  \"action\": \"create\",\\n  \"details\": {\\n    \"summary_task\": \"Ti·∫øp t·ª•c h·ªçc ti·∫øng Anh\",\\n    \"event_time\": null\\n  }\\n}\\n<|eot_id|>'}\n",
            "[{'content': 'You are an intelligent task classification and response generation assistant.\\nYour job is to analyze user commands and generate structured JSON responses according to the correct task category.\\n\\nYou will be given a User Input ‚Äì a natural language command from the user.\\n\\nYour task is to:\\n1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\\n- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\\n2. Determine the appropriate action based on user intent:\\n   - \"todo\" ‚Üí [create, get_all, update, delete, complete]\\n   - \"todo_with_calendar\" ‚Üí [create, get_upcoming, get_past, get_now, update, delete, invite]\\n   - \"email\" ‚Üí [compose, get_inbox, reply, save_draft, delete, mark_important]\\n   - \"article\" ‚Üí [create, get_all, get_published, update, delete, publish, save_draft]\\n   - \"thutuchanhchinh\" ‚Üí [lookup_inf]\\n\\n3. Extract any relevant summary_task and event_time.\\n\\nRespond ONLY with a valid JSON object following this exact template:\\n{\\n  \"tool\": \"<tool>\",\\n  \"action\": \"<action>\",\\n  \"details\": {\\n    \"summary_task\": \"<summary>\",\\n    \"event_time\": \"<time or null>\"\\n  }\\n}\\n\\nDO NOT explain. DO NOT include markdown. DO NOT add extra text.', 'role': 'system'}, {'content': 'Ti·∫øp t·ª•c h·ªçc ti·∫øng anh', 'role': 'user'}, {'content': '\\n{\\n  \"tool\": \"todo\",\\n  \"action\": \"create\",\\n  \"details\": {\\n    \"summary_task\": \"Ti·∫øp t·ª•c h·ªçc ti·∫øng Anh\",\\n    \"event_time\": null\\n  }\\n}\\n', 'role': 'assistant'}]\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an intelligent task classification and response generation assistant.\n",
            "Your job is to analyze user commands and generate structured JSON responses according to the correct task category.\n",
            "\n",
            "You will be given a User Input ‚Äì a natural language command from the user.\n",
            "\n",
            "Your task is to:\n",
            "1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\n",
            "- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\n",
            "2. Determine the appropriate action based on user intent:\n",
            "   - \"todo\" ‚Üí [create, get_all, update, delete, complete]\n",
            "   - \"todo_with_calendar\" ‚Üí [create, get_upcoming, get_past, get_now, update, delete, invite]\n",
            "   - \"email\" ‚Üí [compose, get_inbox, reply, save_draft, delete, mark_important]\n",
            "   - \"article\" ‚Üí [create, get_all, get_published, update, delete, publish, save_draft]\n",
            "   - \"thutuchanhchinh\" ‚Üí [lookup_inf]\n",
            "\n",
            "3. Extract any relevant summary_task and event_time.\n",
            "\n",
            "Respond ONLY with a valid JSON object following this exact template:\n",
            "{\n",
            "  \"tool\": \"<tool>\",\n",
            "  \"action\": \"<action>\",\n",
            "  \"details\": {\n",
            "    \"summary_task\": \"<summary>\",\n",
            "    \"event_time\": \"<time or null>\"\n",
            "  }\n",
            "}\n",
            "\n",
            "DO NOT explain. DO NOT include markdown. DO NOT add extra text.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Ti·∫øp t·ª•c h·ªçc ti·∫øng anh<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "{\n",
            "  \"tool\": \"todo\",\n",
            "  \"action\": \"create\",\n",
            "  \"details\": {\n",
            "    \"summary_task\": \"Ti·∫øp t·ª•c h·ªçc ti·∫øng Anh\",\n",
            "    \"event_time\": null\n",
            "  }\n",
            "}\n",
            "<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from datasets import Dataset\n",
        "from unsloth.chat_templates import standardize_data_formats  # Ho·∫∑c h√†m t∆∞∆°ng ƒë∆∞∆°ng\n",
        "\n",
        "# B∆∞·ªõc 1: ƒê·ªçc file Excel\n",
        "# Gi·∫£ s·ª≠ file n·∫±m t·∫°i \"/content/DataFineTunev1.1_conversations_format.xlsx\"\n",
        "df = pd.read_excel(\"/content/DataFineTunev1.2_conversations_format.xlsx\")\n",
        "\n",
        "# Ki·ªÉm tra nhanh 5 d√≤ng ƒë·∫ßu\n",
        "print(\"D·ªØ li·ªáu g·ªëc (5 d√≤ng ƒë·∫ßu):\")\n",
        "print(df.head())\n",
        "\n",
        "# B∆∞·ªõc 2: M·ªói d√≤ng trong df ƒë√£ ch·ª©a m·ªôt cu·ªôc h·ªôi tho·∫°i ·ªü d·∫°ng chu·ªói JSON.\n",
        "# Ta c·∫ßn chuy·ªÉn c·ªôt `conversations` t·ª´ chu·ªói JSON sang list[dict].\n",
        "\n",
        "all_data = []\n",
        "for idx, row in df.iterrows():\n",
        "    # row[\"conversations\"] l√† m·ªôt chu·ªói JSON,\n",
        "    # v√≠ d·ª•: '[{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"Hello\"}, ...]'\n",
        "    conv_str = row[\"conversations\"]\n",
        "\n",
        "    # Ki·ªÉm tra chu·ªói JSON c√≥ b·ªã r·ªóng, None ho·∫∑c l·ªói format kh√¥ng\n",
        "    if not isinstance(conv_str, str):\n",
        "        raise ValueError(f\"H√†ng th·ª© {idx} kh√¥ng ph·∫£i chu·ªói JSON h·ª£p l·ªá: {conv_str}\")\n",
        "\n",
        "    # Gi·∫£i m√£ chu·ªói JSON th√†nh list[dict]\n",
        "    conv_list = json.loads(conv_str)\n",
        "\n",
        "    # T·∫°o dictionary c√≥ key \"conversations\" cho m·ªói h√†ng\n",
        "    all_data.append({\"conversations\": conv_list})\n",
        "\n",
        "# B∆∞·ªõc 3: T·∫°o Dataset c·ªßa Hugging Face t·ª´ danh s√°ch all_data\n",
        "my_dataset = Dataset.from_list(all_data)\n",
        "\n",
        "# Ki·ªÉm tra c·∫•u tr√∫c ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n\n",
        "print(\"\\nPh·∫ßn t·ª≠ ƒë·∫ßu ti√™n c·ªßa my_dataset tr∆∞·ªõc khi chu·∫©n h√≥a:\")\n",
        "print(my_dataset[0])\n",
        "\n",
        "# B∆∞·ªõc 4: Chu·∫©n h√≥a d·ªØ li·ªáu (n·∫øu c·∫ßn) b·∫±ng h√†m standardize_data_formats\n",
        "# - H√†m n√†y s·∫Ω ƒë·ªìng nh·∫•t role = system / user / assistant theo alias\n",
        "my_dataset = standardize_data_formats(my_dataset)\n",
        "\n",
        "# - Trong qu√° tr√¨nh format, c√≥ th·ªÉ `formatting_prompts_func` (ho·∫∑c m·ªôt h√†m template t∆∞∆°ng t·ª±) ch√®n c√°c token ƒë·∫∑c bi·ªát v√† c√°c th·∫ª ƒë√°nh d·∫•u vai tr√≤ (system/user/assistant).\n",
        "# - C√°c th·∫ª n√†y gi√∫p m√¥ h√¨nh (ho·∫∑c pipeline hu·∫•n luy·ªán) ph√¢n bi·ªát ranh gi·ªõi t·ª´ng vai tr√≤ trong h·ªôi tho·∫°i, c≈©ng nh∆∞ h·ªó tr·ª£ m·ªôt s·ªë t√≠nh nƒÉng n·ªôi b·ªô (nh∆∞ ‚Äúend of text‚Äù, ‚Äústart header‚Äù, v.v.).\n",
        "# Tham s·ªë batched=True cho ph√©p x·ª≠ l√Ω nhi·ªÅu m·∫´u c√πng l√∫c, gi√∫p tƒÉng hi·ªáu qu·∫£ khi √°p d·ª•ng h√†m\n",
        "my_dataset = my_dataset.map(formatting_prompts_func, batched=True,)\n",
        "\n",
        "# Ki·ªÉm tra sau chu·∫©n h√≥a\n",
        "print(\"\\nPh·∫ßn t·ª≠ ƒë·∫ßu ti√™n sau khi chu·∫©n h√≥a:\")\n",
        "print(my_dataset[0])\n",
        "print(my_dataset[0][\"conversations\"])\n",
        "print(my_dataset[0][\"text\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoainQgOPXyZ"
      },
      "source": [
        "N·ªôi dung hi·ªÉn th·ªã cho ta th·∫•y r√µ c√°ch th·ª©c d·ªØ li·ªáu ƒëang ƒë∆∞·ª£c ‚Äúƒë√≥ng g√≥i‚Äù v√† ‚Äúƒë·ªãnh d·∫°ng‚Äù sau khi s·ª≠ d·ª•ng c√°c h√†m chu·∫©n h√≥a t·ª´ th∆∞ vi·ªán `unsloth`. C·ª• th·ªÉ:\n",
        "\n",
        "1. **C√≥ tr∆∞·ªùng** `\"conversations\"` **l∆∞u danh s√°ch tin nh·∫Øn**  \n",
        "   M·ªói tin nh·∫Øn l√† m·ªôt dictionary g·ªìm:\n",
        "   - `\"role\"`: x√°c ƒë·ªãnh ng∆∞·ªùi g·ª≠i l√† `system`, `user`, hay `assistant`.\n",
        "   - `\"content\"`: n·ªôi dung vƒÉn b·∫£n th·ª±c t·∫ø.\n",
        "\n",
        "2. **Xu·∫•t hi·ªán tr∆∞·ªùng** `\"text\"` **ch·ª©a n·ªôi dung ƒë√£ ƒë∆∞·ª£c th√™m c√°c token ƒë·∫∑c bi·ªát**  \n",
        "   Trong ƒë√≥ g·ªìm nh·ªØng token nh∆∞:\n",
        "   - `\"<|begin_of_text|>\"` v√† `\"<|eot_id|>\"` ƒë·ªÉ ƒë√°nh d·∫•u b·∫Øt ƒë·∫ßu/k·∫øt th√∫c n·ªôi dung.  \n",
        "   - `\"<|start_header_id|>system<|end_header_id|>\"`, `\"<|start_header_id|>user<|end_header_id|>\"`, `\"<|start_header_id|>assistant<|end_header_id|>\"` ƒë·ªÉ bi·ªÉu di·ªÖn vai tr√≤.  \n",
        "   - C√°c d√≤ng ‚ÄúCutting Knowledge Date: ‚Ä¶‚Äù v√† ‚ÄúToday Date: ‚Ä¶‚Äù cho th·∫•y m√¥ ph·ªèng ng·ªØ c·∫£nh ho·∫∑c metadata v·ªÅ ng√†y th√°ng (n·∫øu c√≥).  \n",
        "\n",
        "3. **C·∫•u tr√∫c text**  \n",
        "   Text n√†y tr·ªôn c·∫£ n·ªôi dung th·ª±c t·∫ø (v√≠ d·ª• ‚ÄúYou are an intelligent ‚Ä¶,‚Äù ‚ÄúTi·∫øp t·ª•c h·ªçc ti·∫øng anh,‚Äù ‚Ä¶) v·ªõi c√°c ƒëo·∫°n ƒë√°nh d·∫•u (token ƒë·∫∑c bi·ªát), nh·ªù ƒë√≥ m√¥ h√¨nh hu·∫•n luy·ªán ho·∫∑c m√¥ h√¨nh inference c√≥ th·ªÉ ph√¢n bi·ªát ranh gi·ªõi gi·ªØa c√°c vai tr√≤, ho·∫∑c nh·∫≠n bi·∫øt c√°c si√™u th√¥ng tin kh√°c.\n",
        "\n",
        "4. **Nh·∫≠n x√©t t·ªïng quan**  \n",
        "   - D·ªØ li·ªáu ·ªü d·∫°ng `\"conversations\"` + `\"text\"` n√†y r·∫•t h·ªØu √≠ch ƒë·ªÉ **hu·∫•n luy·ªán m√¥ h√¨nh** theo k·ªãch b·∫£n h·ªôi tho·∫°i (chat-based).  \n",
        "   - Ph·∫ßn `\"text\"` ƒë∆∞·ª£c ‚Äúrender‚Äù d·ª±a tr√™n template, gi√∫p **ƒë·ªìng nh·∫•t** vi·ªác cung c·∫•p ng·ªØ c·∫£nh, role, v√† n·ªôi dung cho m√¥ h√¨nh.  \n",
        "   - N·∫øu b·∫°n kh√¥ng mu·ªën c√°c token ƒë·∫∑c bi·ªát (nh∆∞ `\"<|begin_of_text|>\"`‚Ä¶), b·∫°n c√≥ th·ªÉ t√πy bi·∫øn l·∫°i ph·∫ßn template.  \n",
        "   - Ng∆∞·ª£c l·∫°i, n·∫øu b·∫°n c·∫ßn m√¥ h√¨nh hi·ªÉu ƒë∆∞·ª£c ng·ªØ c·∫£nh ‚Äúsystem‚Äù / ‚Äúuser‚Äù / ‚Äúassistant‚Äù t√°ch bi·ªát, th√¨ c√°ch t·∫°o nh·ªØng token n√†y l√† c·∫ßn thi·∫øt.\n",
        "\n",
        "Nh∆∞ v·∫≠y, to√†n b·ªô ƒëo·∫°n ‚Äútext‚Äù n√†y ƒë∆°n gi·∫£n l√† **s·∫£n ph·∫©m** c·ªßa qu√° tr√¨nh chuy·ªÉn ƒë·ªïi v√† ƒë·ªãnh d·∫°ng nh·∫±m ph·ª•c v·ª• nhu c·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh ki·ªÉu h·ªôi tho·∫°i."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrdefPpwRcLz"
      },
      "source": [
        "### ‚úÖ T√≥m t·∫Øt: **Token ƒë∆∞·ª£c t√≠nh t·ª´ ƒë√¢u ƒë·∫øn ƒë√¢u?**\n",
        "\n",
        "- **Token ƒë∆∞·ª£c t√≠nh t·ª´ to√†n b·ªô n·ªôi dung trong tr∆∞·ªùng `\"text\"`**, sau khi √°p d·ª•ng template ChatML.\n",
        "  \n",
        "- Bao g·ªìm t·∫•t c·∫£:\n",
        "  - `<|begin_of_text|>` ‚Äì b·∫Øt ƒë·∫ßu chu·ªói\n",
        "  - `<|start_header_id|>system<|end_header_id|>` + n·ªôi dung system\n",
        "  - `<|start_header_id|>user<|end_header_id|>` + prompt ng∆∞·ªùi d√πng\n",
        "  - `<|start_header_id|>assistant<|end_header_id|>` + c√¢u tr·∫£ l·ªùi\n",
        "  - `<|eot_id|>` ‚Äì ƒë√°nh d·∫•u k·∫øt th√∫c m·ªói ph·∫ßn\n",
        "\n",
        "- üëâ V√¨ prompt `\"system\"` c·ªßa b·∫°n r·∫•t d√†i, b·∫°n n√™n **tƒÉng `max_seq_length`** (n·∫øu m√¥ h√¨nh h·ªó tr·ª£), v√≠ d·ª•:\n",
        "  - 1024 ‚Üí c√≥ th·ªÉ b·ªã c·∫Øt\n",
        "  - 2048 ho·∫∑c 4096 ‚Üí an to√†n h∆°n\n",
        "\n",
        "- ‚úÖ B·∫°n c√≥ th·ªÉ d√πng `tokenizer(text)` ƒë·ªÉ ƒë·∫øm ch√≠nh x√°c s·ªë token.\n",
        "\n",
        "---\n",
        "\n",
        "N·∫øu c·∫ßn, m√¨nh c√≥ th·ªÉ gi√∫p b·∫°n:  \n",
        "- T√≠nh s·ªë token th·∫≠t s·ª± c·ªßa t·ª´ng m·∫´u  \n",
        "- G·ª£i √Ω r√∫t g·ªçn prompt `\"system\"`  \n",
        "- T·ªëi ∆∞u h√≥a cho LoRA ho·∫∑c c·∫•u h√¨nh hu·∫•n luy·ªán ph√π h·ª£p h∆°n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "95_Nn-89DhsL"
      },
      "outputs": [],
      "source": [
        "# from trl import SFTTrainer\n",
        "# from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "# from unsloth import is_bfloat16_supported\n",
        "\n",
        "# trainer = SFTTrainer(\n",
        "#     model = model,\n",
        "#     tokenizer = tokenizer,\n",
        "#     train_dataset = dataset,\n",
        "#     dataset_text_field = \"text\",\n",
        "#     max_seq_length = max_seq_length,\n",
        "#     data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "#     dataset_num_proc = 2,\n",
        "#     packing = False, # Can make training 5x faster for short sequences.\n",
        "#     args = TrainingArguments(\n",
        "#         per_device_train_batch_size = 2,\n",
        "#         gradient_accumulation_steps = 4,\n",
        "#         warmup_steps = 5,\n",
        "#         # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "#         max_steps = 60,\n",
        "#         learning_rate = 2e-4,\n",
        "#         fp16 = not is_bfloat16_supported(),\n",
        "#         bf16 = is_bfloat16_supported(),\n",
        "#         logging_steps = 1,\n",
        "#         optim = \"adamw_8bit\",\n",
        "#         weight_decay = 0.01,\n",
        "#         lr_scheduler_type = \"linear\",\n",
        "#         seed = 3407,\n",
        "#         output_dir = \"outputs\",\n",
        "#         report_to = \"none\", # Use this for WandB etc\n",
        "#     ),\n",
        "# )\n",
        "\n",
        "\n",
        "# Import c√°c h√†m v√† l·ªõp c·∫ßn thi·∫øt\n",
        "# - SFTTrainer: L·ªõp hu·∫•n luy·ªán m√¥ h√¨nh ki·ªÉu \"Supervised Fine-Tuning\" (ƒëi·ªÅu ch·ªânh c√≥ gi√°m s√°t)\n",
        "# - TrainingArguments: ƒê·ªëi t∆∞·ª£ng c·∫•u h√¨nh cho qu√° tr√¨nh hu·∫•n luy·ªán (v√≠ d·ª• s·ªë b∆∞·ªõc, lr, v.v.)\n",
        "# - DataCollatorForSeq2Seq: C√¥ng c·ª• gom d·ªØ li·ªáu theo batch, ph√π h·ª£p v·ªõi m√¥ h√¨nh d·∫°ng seq2seq\n",
        "# - is_bfloat16_supported: H√†m ki·ªÉm tra xem m√°y t√≠nh c√≥ h·ªó tr·ª£ ki·ªÉu s·ªë bfloat16 kh√¥ng\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "# Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng SFTTrainer ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh\n",
        "trainer = SFTTrainer(\n",
        "    model = model,                       # M√¥ h√¨nh (ƒë√£ ƒë∆∞·ª£c n·∫°p s·∫µn)\n",
        "    tokenizer = tokenizer,               # Tokenizer ƒë·ªÉ bi·∫øn vƒÉn b·∫£n th√†nh s·ªë v√† ng∆∞·ª£c l·∫°i\n",
        "    train_dataset = dataset,             # D·ªØ li·ªáu hu·∫•n luy·ªán (d·∫°ng Dataset)\n",
        "    dataset_text_field = \"text\",         # T√™n c·ªôt (field) ch·ª©a chu·ªói vƒÉn b·∫£n trong dataset\n",
        "    max_seq_length = max_seq_length,     # ƒê·ªô d√†i t·ªëi ƒëa c·ªßa m·ªói chu·ªói sau khi tokenizer\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    # DataCollatorForSeq2Seq gi√∫p gom c√°c m·∫´u theo batch, th√™m m√£ ho√° ƒë·∫∑c bi·ªát n·∫øu c·∫ßn\n",
        "\n",
        "    dataset_num_proc = 2,               # S·ªë lu·ªìng CPU ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu song song\n",
        "    packing = False,                     # C√≥ g·ªôp (packing) c√°c chu·ªói ng·∫Øn l·∫°i hay kh√¥ng\n",
        "    # (t·∫Øt packing c√≥ th·ªÉ hu·∫•n luy·ªán ch·∫≠m h∆°n, nh∆∞ng code d·ªÖ theo d√µi h∆°n)\n",
        "\n",
        "    # C√°c tham s·ªë hu·∫•n luy·ªán ƒë∆∞·ª£c ƒë∆∞a v√†o TrainingArguments\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 4, # M·ªói thi·∫øt b·ªã (GPU/CPU) s·∫Ω l·∫•y 2 m·∫´u cho m·ªói batch\n",
        "        gradient_accumulation_steps = 4, # T√≠ch l≈©y gradient 4 l·∫ßn tr∆∞·ªõc khi c·∫≠p nh·∫≠t m√¥ h√¨nh\n",
        "        warmup_steps = 5,               # S·ªë b∆∞·ªõc \"h√¢m n√≥ng\" (warmup) tr∆∞·ªõc khi v√†o giai ƒëo·∫°n ch√≠nh\n",
        "        max_steps = 6000,                 # Hu·∫•n luy·ªán t·ªïng c·ªông 60 b∆∞·ªõc\n",
        "        learning_rate = 2e-4,           # T·ªëc ƒë·ªô h·ªçc (learning rate) l√† 0.0002\n",
        "        fp16 = not is_bfloat16_supported(), # N·∫øu m√°y kh√¥ng h·ªó tr·ª£ bfloat16 th√¨ d√πng fp16\n",
        "        bf16 = is_bfloat16_supported(), # N·∫øu m√°y h·ªó tr·ª£ bfloat16 th√¨ d√πng bfloat16\n",
        "        logging_steps = 1,              # C·ª© 1 b∆∞·ªõc th√¨ in th√¥ng tin log (ti·∫øn tr√¨nh) 1 l·∫ßn\n",
        "        optim = \"adamw_8bit\",           # S·ª≠ d·ª•ng tr√¨nh t·ªëi ∆∞u AdamW, t√≠nh to√°n v·ªõi s·ªë 8-bit ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ\n",
        "        weight_decay = 0.01,            # H·ªá s·ªë tr·ª´ng ph·∫°t ƒë·ªô l·ªõn tham s·ªë (regularization)\n",
        "        lr_scheduler_type = \"linear\",   # Ki·ªÉu thay ƒë·ªïi learning rate (tuy·∫øn t√≠nh)\n",
        "        seed = 3407,                    # H·∫°t ng·∫´u nhi√™n (random seed) ƒë·ªÉ k·∫øt qu·∫£ l·∫∑p l·∫°i ƒë∆∞·ª£c\n",
        "        output_dir = \"outputs\",         # Th∆∞ m·ª•c ƒë·ªÉ l∆∞u k·∫øt qu·∫£ v√† m√¥ h√¨nh sau hu·∫•n luy·ªán\n",
        "        report_to = \"none\",             # Ch·ªó b√°o c√°o k·∫øt qu·∫£ (none = kh√¥ng b√°o)\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsRDH37fQvIx"
      },
      "source": [
        "ƒê√¢y l√† th√¥ng b√°o qu√° tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu khi hu·∫•n luy·ªán, m·ªói d√≤ng cho bi·∫øt m·ªôt b∆∞·ªõc v√† ti·∫øn ƒë·ªô th·ª±c hi·ªán:\n",
        "\n",
        "1. **Converting train dataset to ChatML (num_proc=2): 100%**  \n",
        "   - H·ªá th·ªëng ƒëang **chuy·ªÉn ƒë·ªïi** b·ªô d·ªØ li·ªáu hu·∫•n luy·ªán (train dataset) sang **ƒë·ªãnh d·∫°ng ChatML** (m·ªôt ƒë·ªãnh d·∫°ng ƒë·∫∑c bi·ªát ƒë·ªÉ m√¥ h√¨nh hi·ªÉu ƒë∆∞·ª£c h·ªôi tho·∫°i).  \n",
        "   - `num_proc=2` cho bi·∫øt ƒëang x·ª≠ l√Ω b·∫±ng 2 lu·ªìng (ho·∫∑c 2 ti·∫øn tr√¨nh) song song.  \n",
        "   - Khi b√°o `100000/100000 [00:24<00:00, 1501.55 examples/s]` nghƒ©a l√† ƒë√£ x·ª≠ l√Ω xong **100.000 m·∫´u** trong **24 gi√¢y**, t·ªëc ƒë·ªô kho·∫£ng **1.501 m·∫´u/gi√¢y**.\n",
        "\n",
        "2. **Applying chat template to train dataset (num_proc=2): 100%**  \n",
        "   - Sau b∆∞·ªõc chuy·ªÉn ƒë·ªïi sang ChatML, h·ªá th·ªëng **√°p d·ª•ng m·ªôt ‚Äúchat template‚Äù** (m·ªôt khu√¥n m·∫´u ƒë·ªãnh d·∫°ng) cho d·ªØ li·ªáu.  \n",
        "   - D·ªØ li·ªáu ƒë∆∞·ª£c duy·ªát qua v√† b·ªï sung c√°c token ƒë·∫∑c bi·ªát (v√≠ d·ª•: hi·ªÉn th·ªã user/assistant, c·∫Øt b·ªõt, v.v.) theo template m√† b·∫°n ƒë√£ c·∫•u h√¨nh.  \n",
        "   - T∆∞∆°ng t·ª±, `100000/100000 [00:30<00:00, 4935.73 examples/s]` cho th·∫•y ƒë√£ x·ª≠ l√Ω xong 100.000 m·∫´u trong 30 gi√¢y, t·ªëc ƒë·ªô g·∫ßn 4.935 m·∫´u/gi√¢y.\n",
        "\n",
        "3. **Tokenizing train dataset (num_proc=2): 100%**  \n",
        "   - ƒê√¢y l√† **b∆∞·ªõc bi·∫øn ƒë·ªïi vƒÉn b·∫£n th√†nh c√°c token** ‚Äì nghƒ©a l√† bi·∫øn c√¢u ch·ªØ th√†nh c√°c ch·ªâ s·ªë (s·ªë nguy√™n) ƒë·ªÉ m√¥ h√¨nh hi·ªÉu ƒë∆∞·ª£c.  \n",
        "   - V·ªõi 100.000 m·∫´u, qu√° tr√¨nh n√†y m·∫•t kho·∫£ng 3 ph√∫t 31 gi√¢y (t·ªëc ƒë·ªô ~503 m·∫´u/gi√¢y).\n",
        "\n",
        "4. **Truncating train dataset (num_proc=2): 100%**  \n",
        "   - B∆∞·ªõc **truncating** (c·∫Øt ng·∫Øn) s·∫Ω gi·ªõi h·∫°n ƒë·ªô d√†i m·ªói m·∫´u (th∆∞·ªùng l√† theo `max_seq_length`) ƒë·ªÉ tr√°nh v∆∞·ª£t qu√° m·ª©c cho ph√©p c·ªßa m√¥ h√¨nh.  \n",
        "   - Th·ªùi gian th·ª±c hi·ªán ng·∫Øn (ch·ªâ 2 gi√¢y) do ƒë√¢y l√† thao t√°c c·∫Øt b·ªè ph·∫ßn v∆∞·ª£t qu√°. T·ªëc ƒë·ªô kh√° cao (~44.089 m·∫´u/gi√¢y).\n",
        "\n",
        "T√≥m l·∫°i, c√°c d√≤ng log n√†y cho th·∫•y **b·ªën b∆∞·ªõc n·ªëi ti·∫øp** trong vi·ªác chu·∫©n b·ªã d·ªØ li·ªáu hu·∫•n luy·ªán:  \n",
        "- Chuy·ªÉn ƒë·ªïi sang ChatML,  \n",
        "- √Åp d·ª•ng template h·ªôi tho·∫°i,  \n",
        "- Tokenize (m√£ h√≥a vƒÉn b·∫£n),  \n",
        "- V√† cu·ªëi c√πng l√† c·∫Øt ng·∫Øn d·ªØ li·ªáu v∆∞·ª£t qu√° ƒë·ªô d√†i cho ph√©p.  \n",
        "\n",
        "M·ªói b∆∞·ªõc c√≥ `num_proc=2` nghƒ©a l√† chia vi·ªác x·ª≠ l√Ω cho 2 ti·∫øn tr√¨nh, tƒÉng t·ªëc ƒë·ªô so v·ªõi vi·ªác ch·∫°y ƒë∆°n lu·ªìng."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahxwh6_CRp7m"
      },
      "source": [
        "### ‚úÖ T√≥m t·∫Øt: **Token ƒë∆∞·ª£c t√≠nh t·ª´ ƒë√¢u ƒë·∫øn ƒë√¢u?**\n",
        "\n",
        "- **Token ƒë∆∞·ª£c t√≠nh t·ª´ to√†n b·ªô n·ªôi dung trong tr∆∞·ªùng `\"text\"`**, sau khi √°p d·ª•ng template ChatML.\n",
        "  \n",
        "- Bao g·ªìm t·∫•t c·∫£:\n",
        "  - `<|begin_of_text|>` ‚Äì b·∫Øt ƒë·∫ßu chu·ªói\n",
        "  - `<|start_header_id|>system<|end_header_id|>` + n·ªôi dung system\n",
        "  - `<|start_header_id|>user<|end_header_id|>` + prompt ng∆∞·ªùi d√πng\n",
        "  - `<|start_header_id|>assistant<|end_header_id|>` + c√¢u tr·∫£ l·ªùi\n",
        "  - `<|eot_id|>` ‚Äì ƒë√°nh d·∫•u k·∫øt th√∫c m·ªói ph·∫ßn\n",
        "\n",
        "- üëâ V√¨ prompt `\"system\"` c·ªßa b·∫°n r·∫•t d√†i, b·∫°n n√™n **tƒÉng `max_seq_length`** (n·∫øu m√¥ h√¨nh h·ªó tr·ª£), v√≠ d·ª•:\n",
        "  - 1024 ‚Üí c√≥ th·ªÉ b·ªã c·∫Øt\n",
        "  - 2048 ho·∫∑c 4096 ‚Üí an to√†n h∆°n\n",
        "\n",
        "- ‚úÖ B·∫°n c√≥ th·ªÉ d√πng `tokenizer(text)` ƒë·ªÉ ƒë·∫øm ch√≠nh x√°c s·ªë token.\n",
        "\n",
        "---\n",
        "\n",
        "N·∫øu c·∫ßn, m√¨nh c√≥ th·ªÉ gi√∫p b·∫°n:  \n",
        "- T√≠nh s·ªë token th·∫≠t s·ª± c·ªßa t·ª´ng m·∫´u  \n",
        "- G·ª£i √Ω r√∫t g·ªçn prompt `\"system\"`  \n",
        "- T·ªëi ∆∞u h√≥a cho LoRA ho·∫∑c c·∫•u h√¨nh hu·∫•n luy·ªán ph√π h·ª£p h∆°n.\n",
        "\n",
        "---\n",
        "\n",
        "ƒê·∫øm = tool: 608"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVuk-fowRumq",
        "outputId": "15e2fadc-c219-46e0-b7b6-53a32b67f83c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "S·ªë l∆∞·ª£ng token: 381\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ tokenizer\n",
        "text = my_dataset[0][\"text\"]  # ho·∫∑c standardized_dataset[0][\"text\"]\n",
        "tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "print(f\"S·ªë l∆∞·ª£ng token: {len(tokens['input_ids'][0])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "juQiExuBG5Bt"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "We verify masking is actually done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "LtsMVtlkUhja",
        "outputId": "cb44c93c-e8fa-43e2-aa9d-0447cccd33ae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "_rD6fl8EUxnG",
        "outputId": "df2617f3-032b-43bd-a0f9-3a9793fe7939"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'                                                                  Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enWUM0jV-jV"
      },
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "2753ec0e-23bb-443a-a4f2-1a0a76d47279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "2.822 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TRNSs5MzTKWc",
        "outputId": "fda81c2a-f440-45a3-e9f4-2873058e26bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 100,000 | Num Epochs = 1 | Total steps = 6,000\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
            " \"-____-\"     Trainable parameters = 11,272,192/1,000,000,000 (1.13% trained)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='310' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 310/6000 35:20 < 10:53:00, 0.15 it/s, Epoch 0.05/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.675300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.810900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.728500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.686500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.788400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.986100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.736600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.768500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.923400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.820000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.895400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.025700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.742900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.773600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.107000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.584400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.581900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.862500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.773100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.906500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.927600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.778600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.798300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.693300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.010500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.768500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.118500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.133800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.828400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.852600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.832100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.878500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.872600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.808000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.780300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.615300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.954700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.664600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.877000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.958600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.756300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.973800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.773100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.783900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.102100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.656700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.777100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.554300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.682400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.759800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.735300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.768000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.979900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.749900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.746800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.724800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.779300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.685300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.584100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.732700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.755300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.763200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.802800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.793600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.936000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.675100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.502400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.528600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.711500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.741400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.763300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.848900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.797400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.742100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.939400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.639600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.904800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.779400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.975100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.958800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.698600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.814300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.840500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.908500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.899600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.800100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.833500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.713400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.916400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.939800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.830800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.702900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.774400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.905900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.757900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.836900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.614800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.657700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>0.790800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>0.615300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>0.740500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>0.706400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.847500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>0.748700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>1.018900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>0.776000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>1.028900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.935100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>0.805500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.803700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>0.597000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>0.809100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.785200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.732600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>0.717400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>1.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>0.960400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.990600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.613900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>0.710200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>0.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>1.020600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>0.806800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>0.947600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.958800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>0.757500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.914900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>0.779900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>0.839700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>0.649000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>0.784100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.979700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>0.703400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>0.920200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>0.724000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.746900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.806100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>0.959000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>0.673200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>0.649900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.807400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.763900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>1.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>0.723000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>0.924700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>0.923600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.019500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>0.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>0.690600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>0.874200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>0.626500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>0.809800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>0.865100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>0.986800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>0.794300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.851500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.790900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>0.781100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>0.593500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>0.753400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>1.023700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.753200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>1.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>0.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.595700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>0.709700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.849100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>0.913600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>0.757600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>0.862700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>0.939800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.615500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.668700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>0.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>0.839400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>0.761800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.827600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>0.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>0.674800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>0.906100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>0.895900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>0.691900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>0.870600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>0.905300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.842400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>0.694800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.712000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>0.847800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.757200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.862700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>0.838200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>0.876700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>0.843600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.815400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>1.078200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>0.707800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.868700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>0.995900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>1.047200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>0.904700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.804300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>0.862300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>0.774300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.903900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>0.905500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>0.709200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.772900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>0.983900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>0.814000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>0.710300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>1.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.682600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>0.787000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>0.794500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>0.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.806200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>0.851000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>0.929800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>0.994200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>1.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.788600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>1.155900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>1.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>0.886200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>0.942000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.782800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>0.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.716500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>0.844400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>0.814700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>0.862100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>0.655600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>0.870100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>0.950400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.894200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>0.617800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>1.026200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.821000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.709800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>0.637400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>0.834900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>0.913600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>0.610700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.638600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.887300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>0.762200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>0.729900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>0.712400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>0.599300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>1.079800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>0.909900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>0.726100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>0.606500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.799100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>0.884200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>0.806000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>0.928300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.990700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>1.019600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>0.929700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>0.775200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>0.809700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>0.799000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.768200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>0.966100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>0.683700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>0.746700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>1.010200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.897000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>0.796200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>0.701600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>0.935600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>1.122500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.908800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>0.777400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>0.912600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>0.954200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>0.917500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.715500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>1.005200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>0.870600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.734900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>0.721200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.863700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>0.721300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>0.957900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>0.772400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>0.833300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>0.785100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>0.805100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>0.907900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>0.859800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>0.827000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.060300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>301</td>\n",
              "      <td>0.845200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>302</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>303</td>\n",
              "      <td>0.944900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>304</td>\n",
              "      <td>0.953600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>0.935000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>0.852700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>307</td>\n",
              "      <td>0.891600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>308</td>\n",
              "      <td>0.720900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WvsZ9ydUnTt"
      },
      "source": [
        "### ‚úÖ T√≥m t·∫Øt k·∫øt qu·∫£ hu·∫•n luy·ªán t·ª´ log Unsloth\n",
        "\n",
        "---\n",
        "\n",
        "#### üöÄ **C·∫•u h√¨nh hu·∫•n luy·ªán:**\n",
        "- **T·ªïng s·ªë m·∫´u:** 100,000  \n",
        "- **S·ªë epoch:** 1  \n",
        "- **S·ªë b∆∞·ªõc hu·∫•n luy·ªán (steps):** 60  \n",
        "- **Batch size:**  \n",
        "  - M·ªói thi·∫øt b·ªã: 2  \n",
        "  - `gradient_accumulation_steps = 4`  \n",
        "  - T·ªïng batch size: `2 x 4 x 1 GPU = 8`  \n",
        "- **S·ªë tham s·ªë ƒë∆∞·ª£c hu·∫•n luy·ªán:** 24.3 tri·ªáu / 3 t·ª∑ (~0.81%) ‚Üí ƒëang d√πng **LoRA ho·∫∑c partial fine-tuning**\n",
        "- ‚úÖ **T·ªëi ∆∞u VRAM:** c√≥ offload gradients th√¥ng minh.\n",
        "\n",
        "---\n",
        "\n",
        "#### üìâ **Di·ªÖn bi·∫øn Loss qua t·ª´ng b∆∞·ªõc:**\n",
        "- Loss dao ƒë·ªông t·ª´ kho·∫£ng **0.45 ƒë·∫øn 1.3**, trung b√¨nh ~**0.8‚Äì0.9**\n",
        "- C√≥ v√†i b∆∞·ªõc loss cao ƒë·ªôt bi·∫øn (v√≠ d·ª• b∆∞·ªõc 53: **1.3178**), nh∆∞ng ph·∫ßn l·ªõn gi·ªØ ·ªü m·ª©c ·ªïn ƒë·ªãnh.\n",
        "- M·ªôt s·ªë b∆∞·ªõc c√≥ loss th·∫•p r√µ r·ªát (v√≠ d·ª• b∆∞·ªõc 51: **0.4573**, b∆∞·ªõc 34: **0.5803**) ‚Üí m√¥ h√¨nh c√≥ th·ªÉ h·ªçc t·ªët tr√™n c√°c m·∫´u ƒë√≥.\n",
        "\n",
        "---\n",
        "\n",
        "#### üîç **ƒê√°nh gi√° nhanh:**\n",
        "- V·ªõi ch·ªâ **60 b∆∞·ªõc training**, ƒë√¢y l√† giai ƒëo·∫°n **warmup ho·∫∑c th·ª≠ nghi·ªám nhanh**, kh√¥ng ƒë·∫°i di·ªán cho training d√†i h·∫°n.\n",
        "- M·ª©c loss t∆∞∆°ng ƒë·ªëi ·ªïn ƒë·ªãnh, kh√¥ng tƒÉng li√™n t·ª•c ‚áí **m√¥ h√¨nh ƒëang h·ªçc ƒë∆∞·ª£c**.\n",
        "- B·∫°n c√≥ th·ªÉ:\n",
        "  - ‚úÖ D√πng checkpoint n√†y ƒë·ªÉ **inference th·ª≠**.\n",
        "  - üîÅ TƒÉng s·ªë b∆∞·ªõc (ho·∫∑c epoch) n·∫øu mu·ªën hu·∫•n luy·ªán th·ª±c s·ª± nghi√™m t√∫c.\n",
        "  - üìâ Theo d√µi th√™m `eval loss` (n·∫øu c√≥ t·∫≠p validation) ƒë·ªÉ ƒë√°nh gi√° overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "N·∫øu b·∫°n mu·ªën m√¨nh:\n",
        "- V·∫Ω bi·ªÉu ƒë·ªì Loss  \n",
        "- G·ª£i √Ω c√°ch ƒë√°nh gi√° output sau hu·∫•n luy·ªán  \n",
        "- G·ª£i √Ω checkpoint saving, inference ho·∫∑c ti·∫øp t·ª•c training  \n",
        "\n",
        "üëâ c·ª© n√≥i nh√©!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9"
      },
      "outputs": [],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Unsloth_Studio.ipynb)**\n",
        "\n",
        "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR3gIAX-SM2q"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pEuRb1r2Vg",
        "outputId": "e6912c4e-583e-49a6-8a10-6176d6817b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"tool\": \"email\",\n",
            "  \"action\": \"compose\",\n",
            "  \"details\": {\n",
            "    \"subject\": \"G·ª≠i email qu·ªëc t·∫ø v√†o ng√†y mai\",\n",
            "    \"content\": \"Vui l√≤ng g·ª≠i email v√†o ng√†y mai ƒë·ªÉ x·ª≠ l√Ω c√°c cu·ªôc li√™n h·ªá qu·ªëc t·∫ø v√† ƒë·∫£m b·∫£o t√≠nh tin c·∫≠y.\"\n",
            "  }\n",
            "}<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "from transformers import TextStreamer\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "FastLanguageModel.for_inference(model)  # B·∫≠t ch·∫ø ƒë·ªô suy lu·∫≠n nhanh\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"\n",
        "You are an intelligent task classification and response generation assistant.\n",
        "Your job is to analyze user commands and generate structured JSON responses according to the correct task category.\n",
        "\n",
        "You will be given a User Input ‚Äì a natural language command from the user.\n",
        "\n",
        "Your task is to:\n",
        "1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\n",
        "2. Determine the appropriate action based on user intent:\n",
        "   - \"todo\" ‚Üí [create, get_all, update, delete, complete]\n",
        "   - \"todo_with_calendar\" ‚Üí [create, get_upcoming, get_past, get_now, update, delete, invite]\n",
        "   - \"email\" ‚Üí [compose, get_inbox, reply, save_draft, delete, mark_important]\n",
        "   - \"article\" ‚Üí [create, get_all, get_published, update, delete, publish, save_draft]\n",
        "   - \"thutuchanhchinh\" ‚Üí [lookup_inf]\n",
        "\n",
        "3. Extract any relevant summary_task and event_time.\n",
        "\n",
        "Respond ONLY with a valid JSON object following this exact template:\n",
        "{\n",
        "  \"tool\": \"<tool>\",\n",
        "  \"action\": \"<action>\",\n",
        "  \"details\": {\n",
        "    \"summary_task\": \"<summary>\",\n",
        "    \"event_time\": \"<time or null>\"\n",
        "  }\n",
        "}\n",
        "\n",
        "DO NOT explain. DO NOT include markdown. DO NOT add extra text.\n",
        "\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"G·ª≠i email cho kh√°ch h√†ng qu·ªëc t·∫ø v√†o ng√†y mai\"\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "_ = model.generate(\n",
        "    input_ids=inputs,\n",
        "    streamer=text_streamer,\n",
        "    max_new_tokens=128,\n",
        "    use_cache=True,\n",
        "    temperature=1.5,\n",
        "    min_p=0.1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_0ByZfaZUyg"
      },
      "source": [
        "1 prompt ƒë∆∞·ª£c GPT ƒë·ªÅ xu·∫•t ƒë·ªÉ ch·ªëng vi·ªác gen th·ª´a. Ngon ph·∫øt. (trong khi prompt c≈© c·ªßa m√¨nh b·ªã gen th·ª´a nhi·ªÅu)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJcmMC7VfUA"
      },
      "source": [
        "B·∫°n v·ª´a ƒë∆∞a ra hai ƒëo·∫°n code s·ª≠ d·ª•ng m√¥ h√¨nh ng√¥n ng·ªØ (c√≥ v·∫ª l√† LLaMA 3.1 qua Unsloth) ƒë·ªÉ **sinh vƒÉn b·∫£n (generate)** d·ª±a tr√™n input ng∆∞·ªùi d√πng. C·∫£ hai ƒëo·∫°n ƒë·ªÅu ƒë√∫ng, v√† d√πng trong c√°c t√¨nh hu·ªëng h∆°i kh√°c nhau. M√¨nh s·∫Ω **gi·∫£i th√≠ch ng·∫Øn g·ªçn** s·ª± kh√°c bi·ªát v√† √Ω nghƒ©a t·ª´ng ƒëo·∫°n:\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ ƒêo·∫°n 1 ‚Äì **Sinh vƒÉn b·∫£n v√† l·∫•y k·∫øt qu·∫£ v·ªÅ ƒë·ªÉ x·ª≠ l√Ω**\n",
        "```python\n",
        "outputs = model.generate(\n",
        "    input_ids = inputs,\n",
        "    max_new_tokens = 64,\n",
        "    use_cache = True,\n",
        "    temperature = 1.5,\n",
        "    min_p = 0.1\n",
        ")\n",
        "\n",
        "tokenizer.batch_decode(outputs)\n",
        "```\n",
        "\n",
        "- ‚úÖ D√πng `model.generate(...)` ƒë·ªÉ m√¥ h√¨nh sinh ra token m·ªõi.\n",
        "- ‚úÖ Sau ƒë√≥ d√πng `tokenizer.batch_decode(outputs)` ƒë·ªÉ chuy·ªÉn token th√†nh chu·ªói vƒÉn b·∫£n (string).\n",
        "- üëâ D·∫°ng n√†y d√πng khi b·∫°n **mu·ªën l·∫•y k·∫øt qu·∫£ ra ƒë·ªÉ l∆∞u, ph√¢n t√≠ch, ƒë√°nh gi√° t·ª± ƒë·ªông, ho·∫∑c hi·ªÉn th·ªã sau**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ ƒêo·∫°n 2 ‚Äì **Sinh vƒÉn b·∫£n tr·ª±c ti·∫øp ra m√†n h√¨nh (streaming)**\n",
        "```python\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "\n",
        "_ = model.generate(\n",
        "    input_ids = inputs,\n",
        "    streamer = text_streamer,\n",
        "    max_new_tokens = 128,\n",
        "    use_cache = True,\n",
        "    temperature = 1.5,\n",
        "    min_p = 0.1\n",
        ")\n",
        "```\n",
        "\n",
        "- ‚úÖ D√πng `TextStreamer` ƒë·ªÉ **hi·ªÉn th·ªã output theo th·ªùi gian th·ª±c**, gi·ªëng nh∆∞ chatbot ƒëang \"g√µ ch·ªØ\".\n",
        "- `skip_prompt=True`: ch·ªâ hi·ªÉn th·ªã ph·∫ßn m√¥ h√¨nh sinh ra, kh√¥ng in l·∫°i prompt.\n",
        "- üëâ D·∫°ng n√†y d√πng khi b·∫°n mu·ªën **xem k·∫øt qu·∫£ ngay l·∫≠p t·ª©c** (live demo, chatbot, giao di·ªán ng∆∞·ªùi d√πng‚Ä¶).\n",
        "\n",
        "---\n",
        "\n",
        "### üîÅ ƒêi·ªÉm chung:\n",
        "- C·∫£ hai ƒëo·∫°n ƒë·ªÅu:\n",
        "  - D√πng template chu·∫©n t·ª´ `get_chat_template`.\n",
        "  - C√≥ `add_generation_prompt=True` ƒë·ªÉ m√¥ h√¨nh bi·∫øt n√™n b·∫Øt ƒë·∫ßu sinh ti·∫øp.\n",
        "  - Chuy·ªÉn `inputs` sang `cuda` ƒë·ªÉ ch·∫°y b·∫±ng GPU.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùìN√™n d√πng ƒëo·∫°n n√†o?\n",
        "\n",
        "| M·ª•c ƒë√≠ch                        | N√™n d√πng ƒëo·∫°n |\n",
        "|-------------------------------|---------------|\n",
        "| L∆∞u k·∫øt qu·∫£, x·ª≠ l√Ω h√†ng lo·∫°t   | ƒêo·∫°n 1        |\n",
        "| Hi·ªÉn th·ªã tr·ª±c ti·∫øp nh∆∞ chat   | ƒêo·∫°n 2        |\n",
        "| Ch·∫°y trong notebook            | C·∫£ hai ƒë·ªÅu ·ªïn |\n",
        "| Giao di·ªán chatbot              | ƒêo·∫°n 2        |\n",
        "\n",
        "---\n",
        "\n",
        "N·∫øu b·∫°n c·∫ßn demo t∆∞∆°ng t√°c nhi·ªÅu l∆∞·ª£t, streaming ti·∫øng Vi·ªát ƒë·∫πp h∆°n, ho·∫∑c n·ªëi ti·∫øp h·ªôi tho·∫°i th√¨ m√¨nh c√≥ th·ªÉ gi√∫p b·∫°n m·ªü r·ªông ƒëo·∫°n code nh√©!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0yjIp1q5fmj"
      },
      "source": [
        "# SAVE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyeHMCR05Y_e"
      },
      "source": [
        "Sau khi b·∫°n **fine-tuning xong m√¥ h√¨nh v·ªõi Unsloth**, c√≥ **2 c√°ch ch√≠nh ƒë·ªÉ l∆∞u v√† inference (d·ª± ƒëo√°n)**:\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 1. **L∆∞u m√¥ h√¨nh sau khi hu·∫•n luy·ªán**\n",
        "\n",
        "Unsloth s·ª≠ d·ª•ng LoRA ‚Üí n√™n ch·ªâ c·∫ßn **l∆∞u c√°c adapter** (kh√¥ng c·∫ßn l∆∞u to√†n b·ªô m√¥ h√¨nh g·ªëc)\n",
        "\n",
        "### üîπ L∆∞u local:\n",
        "```python\n",
        "model.save_pretrained(\"lora_model\")         # L∆∞u adapter LoRA\n",
        "tokenizer.save_pretrained(\"lora_model\")     # L∆∞u tokenizer\n",
        "```\n",
        "\n",
        "üìÅ Sau ƒë√≥ b·∫°n s·∫Ω c√≥ th∆∞ m·ª•c `lora_model/` ch·ª©a:\n",
        "- `adapter_config.json`\n",
        "- `adapter_model.bin`\n",
        "- `tokenizer_config.json` + c√°c file tokenizer kh√°c\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Ho·∫∑c ƒë·∫©y l√™n Hugging Face Hub:\n",
        "```python\n",
        "model.push_to_hub(\"your_name/lora_model\", token = \"your_token\")\n",
        "tokenizer.push_to_hub(\"your_name/lora_model\", token = \"your_token\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 2. **Load l·∫°i v√† d√πng ƒë·ªÉ inference (d·ª± ƒëo√°n)**\n",
        "\n",
        "Sau khi ƒë√£ l∆∞u, b·∫°n c√≥ th·ªÉ **load l·∫°i m√¥ h√¨nh** nh∆∞ sau:\n",
        "\n",
        "```python\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"lora_model\",              # ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ƒë√£ l∆∞u\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")\n",
        "FastLanguageModel.for_inference(model)      # K√≠ch ho·∫°t ch·∫ø ƒë·ªô sinh nhanh\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ûï Inference:\n",
        "\n",
        "```python\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "from transformers import TextStreamer\n",
        "\n",
        "tokenizer = get_chat_template(tokenizer, chat_template=\"llama-3.1\")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"L·∫≠p gi√∫p t√¥i th·ªùi kho√° bi·ªÉu h·ªçc t·∫≠p\"}\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "_ = model.generate(\n",
        "    input_ids=inputs,\n",
        "    streamer=streamer,\n",
        "    max_new_tokens=128,\n",
        "    temperature=1.5,\n",
        "    min_p=0.1\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 3. **(Tu·ª≥ ch·ªçn) L∆∞u m√¥ h√¨nh sang ƒë·ªãnh d·∫°ng kh√°c ƒë·ªÉ d√πng ·ªü n∆°i kh√°c**\n",
        "\n",
        "### üîπ Merge th√†nh m√¥ h√¨nh float16 (cho vllm, TGI, triton‚Ä¶)\n",
        "```python\n",
        "model.save_pretrained_merged(\"model_fp16\", tokenizer, save_method = \"merged_16bit\")\n",
        "```\n",
        "\n",
        "### üîπ Merge th√†nh m√¥ h√¨nh int4 (nh·∫π, ti·∫øt ki·ªám RAM)\n",
        "```python\n",
        "model.save_pretrained_merged(\"model_4bit\", tokenizer, save_method = \"merged_4bit\")\n",
        "```\n",
        "\n",
        "### üîπ Export sang GGUF (d√πng cho Ollama, llama.cpp, Jan, OpenWebUI‚Ä¶)\n",
        "```python\n",
        "model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ 4. T·ªïng k·∫øt: C√°ch ch·ªçn\n",
        "\n",
        "| M·ª•c ƒë√≠ch                          | D√πng c√°ch n√†o                               |\n",
        "|----------------------------------|---------------------------------------------|\n",
        "| Ti·∫øp t·ª•c fine-tune               | L∆∞u b·∫±ng `save_pretrained()`               |\n",
        "| Inference b·∫±ng Python/Colab      | D√πng `FastLanguageModel.from_pretrained()` |\n",
        "| D√πng m√¥ h√¨nh ·ªü Ollama, WebUI     | D√πng `save_pretrained_gguf()`              |\n",
        "| ƒê·∫©y l√™n Hugging Face             | D√πng `push_to_hub()` ho·∫∑c `push_to_hub_gguf()` |\n",
        "| Tri·ªÉn khai ·ªü production          | D√πng `merged_16bit` ho·∫∑c `gguf`            |\n",
        "\n",
        "---\n",
        "\n",
        "N·∫øu b·∫°n mu·ªën m√¨nh:\n",
        "- ‚úÖ G·ª£i √Ω format file inference m·∫´u\n",
        "- ‚úÖ Vi·∫øt ƒëo·∫°n code inference c·ª• th·ªÉ cho Hugging Face, Gradio, LangChain, Ollama\n",
        "- ‚úÖ Export sang GGUF ƒë·ªÉ d√πng v·ªõi chatbot UI\n",
        "\n",
        "üëâ C·ª© b·∫£o m√¨nh nh√©!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2v6UM4_CR6w"
      },
      "outputs": [],
      "source": [
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsqDkY3RRlf3"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"lora_model_1B_6000steps\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model_1B_6000steps\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "9d85e6b5-27a4-49db-a94c-08c6e6b7211c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The iconic \"Chapelle de la Trinit√©\" located at the top of the Champs-√âlys√©es, a very tall tower in the city of Paris, is a symbol of French culture and history. The tower stands at over 20 stories high and offers breathtaking views of the city below. The interior of the tower is dedicated to the Trinity Church and is adorned with numerous artworks and furnishings. The tower itself is not only a tribute to the French history but also an impressive structure itself. The height of the tower is of note and makes it the highest tower in all of Europe. This particular tower stands as a testament to\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model_1B_600steps\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Describe a tall tower in the capital of France.\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload full merged_16bit model to Hugging Face\n",
        "model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\")\n",
        "from huggingface_hub import login\n",
        "\n",
        "# L·∫•y token t·ª´ https://huggingface.co/settings/tokens\n",
        "login(token=\"hf_\")  # paste token Hugging Face c√° nh√¢n c·ªßa b·∫°n\n",
        "\n",
        "model.push_to_hub_merged(\n",
        "    \"doanngoccuong/RountingTask_DataV1.2_1epoch60steps_Llama3.2-3B\",   # v√≠ d·ª•: \"quoc-ai/llama3-3b-routing\"\n",
        "    tokenizer,\n",
        "    save_method = \"merged_16bit\",      # ho·∫∑c \"merged_4bit\", \"lora\"\n",
        "    token = \"hf_\",                  # token HF c√° nh√¢n\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Saved merged model to https://huggingface.co/doanngoccuong/RountingTask_DataV1.2_1epoch60steps_Llama3.2-3B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_naIe97Dg5q"
      },
      "source": [
        "\n",
        "\n",
        "## üìä So s√°nh nhanh:\n",
        "\n",
        "| Save method     | D√πng ƒë∆∞·ª£c v·ªõi vLLM | D·ªÖ deploy | Nh·∫π | Ch·ª©a base model |\n",
        "|-----------------|--------------------|-----------|------|------------------|\n",
        "| `merged_16bit`  | ‚úÖ                  | ‚úÖ         | ‚ùå   | ‚úÖ               |\n",
        "| `merged_4bit`   | ‚ö†Ô∏è C√≥ th·ªÉ (tu·ª≥ engine) | ‚úÖ     | ‚úÖ   | ‚úÖ               |\n",
        "| `lora`          | ‚ùå (c·∫ßn merge l·∫°i)  | ‚ùå         | ‚úÖ‚úÖ‚úÖ | ‚ùå               |\n",
        "\n",
        "---\n",
        "\n",
        "| M·ª•c ti√™u | N√™n d√πng |\n",
        "|----------|----------|\n",
        "| Deploy vLLM ho·∫∑c Ollama | `merged_16bit` ‚úÖ |\n",
        "| Chia s·∫ª LoRA ƒë·ªÉ ng∆∞·ªùi kh√°c d√πng v·ªõi model g·ªëc | `lora` ‚úÖ |\n",
        "| T·ªëi ∆∞u RAM m√°y y·∫øu | `merged_4bit` ‚úÖ (n·∫øu engine support) |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Ge0bLgCvvQ"
      },
      "source": [
        "```\n",
        "Khi deploy th√¨ merge base model c·ªßa lora c√≥ kh√°c g√¨ v·ªõi merged_16bit khi deploy kh√¥ng\n",
        "Hay l√† deploy th√¨ n·∫∑ng nh∆∞ nhau\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVwy-QZzDABq"
      },
      "source": [
        "C√¢u h·ªèi qu√° hay lu√¥n C∆∞·ªùng ∆°i! üòé ƒê√¢y l√† m·ªôt **v·∫•n ƒë·ªÅ quan tr·ªçng** m√† nhi·ªÅu anh em hay nh·∫ßm: **merge t·∫°i th·ªùi ƒëi·ªÉm deploy** (t·ª©c l√† d√πng base model + adapter) **so v·ªõi ƒë√£ merge s·∫µn (`merged_16bit`)** ‚Äî v·ªÅ b·∫£n ch·∫•t th√¨ gi·ªëng nhau, nh∆∞ng **tri·ªÉn khai th·ª±c t·∫ø c√≥ kh√°c bi·ªát r√µ r√†ng**. M√¨nh ph√¢n t√≠ch nh√©:\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ V·ªÅ b·∫£n ch·∫•t khi inference:\n",
        "\n",
        "| So s√°nh                     | Merge L√∫c Deploy (`base + lora`) | `merged_16bit` (ƒë√£ merge s·∫µn) |\n",
        "|----------------------------|----------------------------------|-------------------------------|\n",
        "| **Th√¥ng tin m√¥ h√¨nh**      | Base model + LoRA ri√™ng bi·ªát     | M√¥ h√¨nh ƒë√£ gh√©p ho√†n ch·ªânh    |\n",
        "| **Th√¥ng s·ªë c·∫ßn d√πng**      | V·∫´n l√† full base + ph·∫ßn LoRA     | Ch√≠nh l√† base + LoRA          |\n",
        "| **Dung l∆∞·ª£ng GPU d√πng**    | ‚ö†Ô∏è Gi·ªëng nhau (~full 16bit)      | ‚ö†Ô∏è Gi·ªëng nhau (~full 16bit)   |\n",
        "| **Ch·∫•t l∆∞·ª£ng k·∫øt qu·∫£**     | ‚úÖ Gi·ªëng nhau ho√†n to√†n           | ‚úÖ Gi·ªëng nhau                  |\n",
        "\n",
        "> üëâ V√¨ d√π merge l√∫c deploy hay ƒë√£ merge s·∫µn, **inference ƒë·ªÅu ph·∫£i t·∫£i full model (bao g·ªìm LoRA)** l√™n GPU ƒë·ªÉ ch·∫°y.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùóKh√°c bi·ªát khi **tri·ªÉn khai th·ª±c t·∫ø**:\n",
        "\n",
        "| Ti√™u ch√≠                        | Merge t·∫°i runtime (`base + LoRA`) | `merged_16bit` (ƒë√£ merge)     |\n",
        "|--------------------------------|----------------------------------|-------------------------------|\n",
        "| **S·ªë file ph·∫£i load**          | 2 file (base + adapter)          | 1 file duy nh·∫•t               |\n",
        "| **T·ªëc ƒë·ªô kh·ªüi ƒë·ªông**           | ‚è≥ Ch·∫≠m h∆°n (ph·∫£i merge t·∫°i runtime) | ‚ö°Nhanh h∆°n (ch·ªâ load 1 model) |\n",
        "| **T∆∞∆°ng th√≠ch vLLM / Triton**  | ‚ùå Kh√¥ng h·ªó tr·ª£ tr·ª±c ti·∫øp         | ‚úÖ H·ªó tr·ª£ t·ªët                  |\n",
        "| **Kh·∫£ nƒÉng deploy quy m√¥ l·ªõn** | ‚ùå Kh√≥ scale (ph·∫£i merge t·ª´ng node) | ‚úÖ D·ªÖ d√†ng scale               |\n",
        "| **Y√™u c·∫ßu v·ªÅ code**            | C·∫ßn th√™m logic merge             | ƒê∆°n gi·∫£n, ch·ªâ load 1 model    |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ T√≥m l·∫°i:\n",
        "\n",
        "| N·∫øu b·∫°n‚Ä¶                           | Th√¨ d√πng‚Ä¶            |\n",
        "|------------------------------------|----------------------|\n",
        "| üíª Ch·∫°y local, th·ª≠ nghi·ªám          | Base + LoRA (merge runtime) |\n",
        "| üöÄ Mu·ªën deploy production (vLLM)   | `merged_16bit`       |\n",
        "| ‚òÅÔ∏è Mu·ªën upload Hugging Face        | `merged_16bit` ho·∫∑c `lora` tu·ª≥ m·ª•c ƒë√≠ch |\n",
        "| üß™ L√†m benchmark model sau train   | `merged_16bit`       |\n",
        "\n",
        "---\n",
        "\n",
        "## üëë K·∫øt lu·∫≠n ng·∫Øn g·ªçn:\n",
        "\n",
        "> ‚úÖ **Deploy th√¨ n·∫∑ng nh∆∞ nhau (c√πng t·∫£i full model)**  \n",
        "> ‚ùóNh∆∞ng **d√πng `merged_16bit` ti·ªán h∆°n, nhanh h∆°n, d·ªÖ t√≠ch h·ª£p h∆°n** ‚Üí ƒê√¢y l√† **chu·∫©n khi deploy** cho vLLM, Triton, Ollama...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxR-VjyIDcfD"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zqo-uxgB9lZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mTz_-1dODZD"
      },
      "source": [
        "# Deploy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiL2NVSVOEvj"
      },
      "source": [
        "```\n",
        "Em c·∫£m ∆°n anh nhi·ªÅu.\n",
        "---\n",
        "# B√ÄI EM ƒêANG L√ÄM:\n",
        "- Em ƒëang fine tune 1 con Llam3-3.2 - 1B/3B anh ·∫°.\n",
        "- Input l√† 1 c√¢u c·ªßa User. Output l√† d·∫°ng Routing 2 t·∫ßng: Tool - Action (1 tool c√≥ nhi·ªÅu lo·∫°i Action anh ·∫°).\n",
        "```\n",
        "{\n",
        "  \"tool\": \"todo\",\n",
        "  \"action\": \"get_all\",\n",
        "  \"details\": {\n",
        "    \"summary_task\": \"l·∫•y to√†n b·ªô danh s√°ch c√¥ng vi·ªác ƒë√£ note\",\n",
        "    \"event_time\": null\n",
        "  }\n",
        "}\n",
        "```\n",
        "- Con 1B run colab t·∫ßm 1-2s, con 3B th√¨ 4-5s. Con 3B 1 epoch - 60 step - data kho·∫£ng 1500 d√≤ng ƒë√£ qu√° ngon r·ªìi. Con 1B m√† 1 epoch th√¨ ch∆∞a ƒÉn thua g√¨ anh ·∫°.\n",
        "\n",
        "=== ===============\n",
        "\n",
        "C√¢u h·ªèi v·ªÅ RESPONSE TIME:\n",
        "- Anh c√≥ hay l√†m con 1B, 3B kh√¥ng ·∫°. Khi deploy server th√¨ response time v·∫´n s·∫Ω ngang ngang tr√™n colab anh nh·ªâ (·∫°). GPU m·∫°nh h∆°n th√¨ response time c√≥ th·ªÉ gi·∫£m.\n",
        "\n",
        "?\n",
        "\n",
        "\n",
        "1B t·∫ßm 1-2s anh ·∫°, GPU m·∫°nh th√¨ kh·∫£ nƒÉng gi·∫£m\n",
        "3B t·∫ßm 4-5s\n",
        "---\n",
        " 1 Bert t·∫ßm 100-200ms, P95 t·∫ßm 200ms,\n",
        "ƒê·ªÉ em ƒëo k·ªπ l·∫°i xem k·∫øt qu·∫£ th·∫ø n√†o anh ·∫°."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a-FS4nZOu_z"
      },
      "source": [
        "D∆∞·ªõi ƒë√¢y l√† b·∫£ng so s√°nh th·ªùi gian ph·∫£n h·ªìi (response time) **khi deploy m√¥ h√¨nh tr√™n server**, v·ªõi c√°c lo·∫°i GPU ph·ªï bi·∫øn (k√®m theo v√†i g·ª£i √Ω t·ªëi ∆∞u):\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ **B·∫£ng so s√°nh response time khi deploy (LLaMA 1B / 3B / BERT)**\n",
        "\n",
        "| M√¥ h√¨nh       | GPU         | Response Time (trung b√¨nh) | P95 (ms) | T·ªëi ∆∞u kh·∫£ d·ª•ng                   | Ghi ch√∫ th√™m                              |\n",
        "|---------------|-------------|-----------------------------|----------|-----------------------------------|-------------------------------------------|\n",
        "| **BERT-base** | T4 / A10     | ~100-200ms                  | ~200ms   | Kh√¥ng c·∫ßn cache, batch t·ªët        | D√πng nhi·ªÅu trong classification nhanh     |\n",
        "| **LLaMA 1B**  | T4          | ~1.8s                       | ~2.5s    | `use_cache=True`, template nh·∫π    | N·∫øu prompt d√†i, th·ªùi gian tƒÉng m·∫°nh       |\n",
        "| **LLaMA 1B**  | A10 / L4     | ~1.2s                       | ~1.6s    | C·∫Øt b·ªõt `system`, streaming JSON  | ƒê·∫°t P95 < 2s n·∫øu prompt ‚â§ 400 tokens      |\n",
        "| **LLaMA 3B**  | T4          | ~4‚Äì5s                       | ~6s      | Kh√≥ t·ªëi ∆∞u n·∫øu system d√†i         | Prefill (system) l√† bottleneck            |\n",
        "| **LLaMA 3B**  | A100        | ~1.8‚Äì2.5s                   | ~3.5s    | vLLM, cache KV, batch t·ªët         | T·ªëc ƒë·ªô tƒÉng x2-x3 so v·ªõi T4               |\n",
        "| **LLaMA 3B**  | vLLM + A10  | ~1.2‚Äì2s                     | ~2.5s    | vLLM hi·ªáu qu·∫£ v·ªõi JSON short gen  | N√™n d√πng cho production ho·∫∑c chatbot task |\n",
        "\n",
        "---\n",
        "\n",
        "### üîß **T·ªëi ∆∞u inference khi deploy:**\n",
        "\n",
        "| K·ªπ thu·∫≠t                | Hi·ªáu qu·∫£ | M√¥ t·∫£ ng·∫Øn                                                                 |\n",
        "|-------------------------|----------|----------------------------------------------------------------------------|\n",
        "| **vLLM**                | ‚≠ê‚≠ê‚≠ê‚≠ê     | Prefill/decode song song, reuse KV cache, c·ª±c nhanh                       |\n",
        "| **Merge LoRA 16bit**    | ‚≠ê‚≠ê‚≠ê      | ƒê·∫©y inference t·ªëc ƒë·ªô nh∆∞ base model (kh√¥ng c·∫ßn adapter)                   |\n",
        "| **System prompt ng·∫Øn**  | ‚≠ê‚≠ê‚≠ê‚≠ê     | Gi·∫£m token input ‚Üí gi·∫£m th·ªùi gian prefill (r·∫•t quan tr·ªçng v·ªõi LLaMA)      |\n",
        "| **Streaming (`TextStreamer`)** | ‚≠ê‚≠ê | C√≥ c·∫£m gi√°c nhanh h∆°n, m·∫∑c d√π t·ªïng th·ªùi gian v·∫´n v·∫≠y                      |\n",
        "| **Batch nh·ªè (batch=1)** | ‚≠ê‚≠ê       | Gi·∫£m latency (d√πng trong chatbot real-time)                               |\n",
        "| **Model nh·ªè h∆°n (1B)**  | ‚≠ê‚≠ê‚≠ê      | Trade-off gi·ªØa t·ªëc ƒë·ªô & ƒë·ªô ch√≠nh x√°c                                     |\n",
        "| **GGUF + llama.cpp**    | ‚≠ê‚≠ê       | Nhanh tr√™n CPU, th√≠ch h·ª£p n·∫øu kh√¥ng c√≥ GPU ho·∫∑c RAM nhi·ªÅu                 |\n",
        "\n",
        "---\n",
        "\n",
        "### üß† G·ª£i √Ω cho Qu·ªëc:\n",
        "- N·∫øu mu·ªën deploy m√¥ h√¨nh gen JSON routing nh∆∞ em ƒëang l√†m:\n",
        "  - üëâ D√πng **vLLM + merge_16bit**, r·∫•t ph√π h·ª£p task short-form gen.\n",
        "  - üëâ ƒê·ªÉ inference nhanh (P95 < 2s), ∆∞u ti√™n A10 ho·∫∑c A100.\n",
        "  - üëâ N·∫øu d√πng `llama.cpp` (GGUF), th√¨ target P95 kho·∫£ng ~3‚Äì4s (tr√™n CPU ngon).\n",
        "\n",
        "---\n",
        "\n",
        "C·∫ßn anh h·ªó tr·ª£ d·ª±ng backend FastAPI + vLLM m·∫´u cho task n√†y th√¨ b·∫£o anh nh√©, anh c√≥ template g·ªçn ƒë·∫πp chu·∫©n JSON streaming s·∫µn üòé"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGmTn7o1WIZp"
      },
      "source": [
        "```\n",
        "6, 7 con BERT kh√°c nhau v·ªÅ response time th√¨ ·ªïn s·∫øp ·∫°. C∆° m√† m·ªói con s·∫Ω c·∫Øn 3GB GPU. <ƒë√£ x√°c th·ª±c v√¨ em ƒëang tri·ªÉn ·ªü c√¥ng ty>\n",
        "\n",
        "1 con 1B s·∫Ω c·∫Øn t·∫ßm 4-6GB GPU.\n",
        "\n",
        "s·∫øp c·ª© ƒë·ªÉ em, c√≥ g√¨ em b√°o l·∫°i. (nhi·ªÅu BERT, m√† m·ªói BERT c·∫Øn 3GB RAM anh ·∫°, kiki, 6 con l√† 18GB th√¨ c≈©ng cƒÉng).\n",
        "B√†i n√†y anh ƒë·ªÉ em lo cho ·∫°. em report l·∫°i 1 gi·∫£i ph√°p ngon ngh·∫ª nh·∫•t nhen ·∫° ^^\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIO2jKYyV9BQ"
      },
      "source": [
        "Chu·∫©n lu√¥n s·∫øp ∆°i!  \n",
        "D∆∞·ªõi ƒë√¢y l√† b·∫£ng ∆∞·ªõc l∆∞·ª£ng **GPU memory consumption (VRAM)** cho 1 model trong l√∫c **inference**, kh√¥ng t√≠nh batch l·ªõn nh√© (batch size = 1, `use_cache=True`, context ~512 tokens):\n",
        "\n",
        "---\n",
        "\n",
        "### üìä **VRAM ti√™u th·ª• theo m√¥ h√¨nh (batch nh·ªè)**\n",
        "\n",
        "| M√¥ h√¨nh         | VRAM ∆∞·ªõc l∆∞·ª£ng | Ghi ch√∫ th√™m                                                             |\n",
        "|------------------|----------------|--------------------------------------------------------------------------|\n",
        "| **BERT-base**    | ~2.5‚Äì3 GB      | ƒê√£ t·ªëi ∆∞u, nhanh, nh·∫π, kh√¥ng c·∫ßn cache ph·ª©c t·∫°p                          |\n",
        "| **BERT-large**   | ~4.5‚Äì5 GB      | G·∫•p ƒë√¥i s·ªë layer, ng·ªën g·∫•p ƒë√¥i VRAM                                     |\n",
        "| **LLaMA 1B**     | ~4.5‚Äì6 GB      | N·∫øu ch·∫°y 16-bit, c√≥ th·ªÉ cao h∆°n n·∫øu context d√†i (~2048 tokens)          |\n",
        "| **LLaMA 3.2 - 1B (Unsloth, 4bit)** | ~3‚Äì4 GB | N·∫øu d√πng 4bit v·ªõi `load_in_4bit=True` th√¨ ti·∫øt ki·ªám r·∫•t nhi·ªÅu          |\n",
        "| **LLaMA 3B**     | ~8‚Äì10 GB       | C√πng c·∫•u h√¨nh, 3B ng·ªën g·∫ßn g·∫•p ƒë√¥i VRAM 1B                              |\n",
        "| **LLaMA 3.2 - 3B (Unsloth 4bit)** | ~6‚Äì7 GB | C√≥ th·ªÉ fit v√†o A10 24GB ƒë·ªÉ ch·∫°y nhi·ªÅu phi√™n song song                  |\n",
        "\n",
        "---\n",
        "\n",
        "### üß† T√≥m l·∫°i cho em:\n",
        "- ‚úÖ 1 con **LLaMA 3.2 - 1B**, n·∫øu d√πng Unsloth 4bit: **~3‚Äì4 GB** ‚Üí t∆∞∆°ng ƒë∆∞∆°ng 1 BERT.\n",
        "- ‚úÖ N·∫øu em deploy l√™n A10 (24GB) th√¨:\n",
        "  - Ch·∫°y song song ƒë∆∞·ª£c **6‚Äì7 con 1B** ho·∫∑c **2‚Äì3 con 3B**.\n",
        "- ‚úÖ Tr√™n T4 (16GB): 1B d∆∞ d·∫£, 3B v·ª´a ƒë·ªß 1 phi√™n.\n",
        "\n",
        "---\n",
        "\n",
        "N·∫øu em ƒëang d√πng **vLLM**, n√≥ s·∫Ω chia ri√™ng prefill v√† decode n√™n c≈©ng d√πng VRAM hi·ªáu qu·∫£ h∆°n ‚Äì ch·ªâ c·∫ßn **ch·∫°y test v√†i request r·ªìi check `nvidia-smi`** l√† confirm chu·∫©n nh√©.\n",
        "\n",
        "Mu·ªën anh h·ªó tr·ª£ d·ª±ng b·∫£ng c·∫•u h√¨nh A10 / A100 ch·∫°y bao nhi√™u request/s th√¨ b·∫£o anh ‚úåÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuWZGtdGXheC"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prLAmSVGkvmB"
      },
      "source": [
        "# GROQ V√ÉI NH√ÅI TH·∫¨T - 300ms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_rJLEQBl1dW"
      },
      "source": [
        "Gi·∫£i ph√°p ƒë√¢y r·ªìi anh ·∫°.\n",
        "- GROQ si√™u nhanh. 300ms\n",
        "- Gi√° c≈©ng h·∫°t r·∫ª.\n",
        "\n",
        "\n",
        "- D·∫´n ch·ª©ng:\n",
        "+, N·ªÅn t·∫£ng Groq n√†y, tr∆∞·ªõc em t·ª´ng c√≥ qu·∫£ Prompt t·ªëi ∆∞u cho c√¥ng ty 30 gi√¢y gi·∫£m c√≤n 5s khi x√†i n√≥. => Ch·∫°y tr√™n Production.\n",
        "+, Output ngon anh ·∫°. Em ch·∫°y th·ª≠ 300 m·∫´u th√¨ okela h·∫øt. L√°t v·ªÅ em g·ª≠i anh report.\n",
        "\n",
        "- Value: Fine tune 1B th√¨ k·∫øt qu·∫£ ƒëang t·ªá 600 steps - 10 epochs k·∫øt qu·∫£ nh∆∞ c·ª©c, 3B th√¨ k·∫øt qu·∫£ work ngay ·ªü 60 steps = 1 epoch ƒë·∫ßu nh∆∞ng response time colab T4 t·∫ßm 4-5s, response time ƒë·∫©y server th√¨ s·∫Ω gi·∫£m.\n",
        "\n",
        "D∆∞·ªõi ƒë√¢y l√† b·∫£n **t√≥m t·∫Øt ng·∫Øn g·ªçn cu·ªôc trao ƒë·ªïi gi·ªØa b·∫°n v√† anh ƒê·ª©c Nguy·ªÖn**:\n",
        "\n",
        "\n",
        "\n",
        "D∆∞·ªõi ƒë√¢y l√† ph·∫ßn **t√≥m t·∫Øt cu·ªôc trao ƒë·ªïi gi·ªØa b·∫°n v√† anh ƒê·ª©c Nguy·ªÖn**:\n",
        "\n",
        "---\n",
        "\n",
        "### üîé **B·ªëi c·∫£nh c√¥ng vi·ªác c·ªßa b·∫°n:**\n",
        "- B·∫°n ƒëang fine-tune m√¥ h√¨nh **LLaMA 3.2 (1B v√† 3B)** cho b√†i to√°n **routing 2 t·∫ßng**:\n",
        "  - Input: C√¢u l·ªánh ng∆∞·ªùi d√πng.\n",
        "  - Output: JSON ch·ª©a `tool`, `action`, v√† `details`.\n",
        "- K·∫øt qu·∫£:\n",
        "  - **1B:** inference 1‚Äì2s tr√™n Colab T4.\n",
        "  - **3B:** inference 4‚Äì5s, fine-tune 1 epoch (60 steps) v·ªõi ~1500 d√≤ng ƒë√£ cho k·∫øt qu·∫£ t·ªët.\n",
        "\n",
        "---\n",
        "\n",
        "### üí° **G·ª£i √Ω t·ª´ anh ƒê·ª©c:**\n",
        "\n",
        "1. **Kh√¥ng d√πng Colab cho production**\n",
        "   - L√Ω do: Ch·∫≠m, thi·∫øu ·ªïn ƒë·ªãnh, kh√¥ng ki·ªÉm so√°t ƒë∆∞·ª£c t√†i nguy√™n.\n",
        "\n",
        "2. **D√πng GPU m·∫°nh h∆°n (4090) + vLLM**\n",
        "   - Anh ƒê·ª©c ch·∫°y model 8B v·ªõi **vLLM + RTX 4090** ƒë·∫°t inference d∆∞·ªõi **1s**.\n",
        "   - G·ª£i √Ω b·∫°n chuy·ªÉn sang server ri√™ng ho·∫∑c GPU cloud n·∫øu mu·ªën t·ªëc ƒë·ªô t·ªët h∆°n.\n",
        "   - D√πng th√™m parallel\n",
        "\n",
        "3. **Kh√¥ng n√™n d√πng LLaMA 1B cho function calling**\n",
        "   - Anh ƒë√£ th·ª≠ v√† th·∫•y kh√¥ng ƒë·ªß th√¥ng minh, g·ª£i √Ω b·∫°n **d√πng 8B tr·ªü l√™n**. V√† b·∫°n b·∫£o b·∫°n d√πng 3B ƒë√£ work.\n",
        "\n",
        "4. **N√™n d√πng GROQ cho inference**\n",
        "   - B·∫°n ƒë·ªÅ xu·∫•t d√πng GROQ, anh ƒê·ª©c c√≤n ch∆∞a th·ª≠.\n",
        "\n",
        "5. **V·ªÄ ROUTING: anh ƒê·ª©c gi√∫p b·∫°n ph√¢n bi·ªát b√†i function calling v·ªõi b√†i routing. ROUTING: X√¢y d·ª±ng ki·∫øn tr√∫c linh ho·∫°t h∆°n:**\n",
        "   - üëâ **Proxy App** ƒë·ªÉ route request ƒë·∫øn c√°c provider (OpenAI, GROQ, LLM local‚Ä¶).\n",
        "   - üëâ **LangChain** ƒë·ªÉ:\n",
        "     - T·ªï ch·ª©c code ƒë·∫πp h∆°n.\n",
        "     - T√≠ch h·ª£p prompt enforce s·∫µn.\n",
        "     - D·ªÖ m·ªü r·ªông v·ªÅ sau (function calling, RAG, agent...).\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ K·∫øt lu·∫≠n:\n",
        "- B·∫°n ƒëang ƒëi ƒë√∫ng h∆∞·ªõng khi d√πng m√¥ h√¨nh nh·ªè ƒë·ªÉ fine-tune nhanh. B·∫°n ƒë√£ ƒë·ªïi sang x√†i GROQ kh√° th√¥ng minh\n",
        "- Anh ƒê·ª©c khuy·∫øn kh√≠ch d√πng**vLLM + GPU m·∫°nh + gpu Cloud + Parralel** ƒë·ªÉ t·ªëi ∆∞u inference.\n",
        "- Tri·ªÉn khai production n√™n c√≥ **proxy + LangChain** ƒë·ªÉ d·ªÖ scale, d·ªÖ maintain, v√† ti·∫øt ki·ªám chi ph√≠.\n",
        "\n",
        "N·∫øu b·∫°n c·∫ßn m√¨nh **v·∫Ω s∆° ƒë·ªì ki·∫øn tr√∫c ho·∫∑c c·∫•u tr√∫c code m·∫´u**, c·ª© nh·∫Øn nha!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD4mdQfnmFL2"
      },
      "source": [
        "D∆∞·ªõi ƒë√¢y l√† ph·∫ßn **t√≥m t·∫Øt c√°c l·ªùi khuy√™n c·ªßa anh ƒê·ª©c Nguy·ªÖn d√†nh cho b·∫°n** trong cu·ªôc trao ƒë·ªïi:\n",
        "\n",
        "---\n",
        "\n",
        "### üß† **L·ªùi khuy√™n ch√≠nh t·ª´ anh ƒê·ª©c:**\n",
        "\n",
        "1. ### ‚ùå **Kh√¥ng d√πng Colab ƒë·ªÉ ch·∫°y production**\n",
        "   - Colab **ch·ªâ ph√π h·ª£p cho h·ªçc t·∫≠p, th·ª≠ nghi·ªám**, kh√¥ng ƒë·∫£m b·∫£o t·ªëc ƒë·ªô v√† ƒë·ªô ·ªïn ƒë·ªãnh.\n",
        "   - B·∫°n c·∫ßn d√πng **GPU server th·ª±c t·∫ø** n·∫øu mu·ªën build h·ªá th·ªëng ph·ª•c v·ª• th·ª±c.\n",
        "\n",
        "2. ### ‚ö° **D√πng GPU m·∫°nh + vLLM ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô inference**\n",
        "   - Anh ƒê·ª©c d√πng **vLLM + RTX 4090** ƒë·ªÉ ch·∫°y **m√¥ h√¨nh 8B**, cho t·ªëc ƒë·ªô **d∆∞·ªõi 1 gi√¢y**.\n",
        "   - G·ª£i √Ω b·∫°n chuy·ªÉn qua GPU Cloud ho·∫∑c server c·∫•u h√¨nh m·∫°nh.\n",
        "   - Nh·∫•n m·∫°nh **config parallel t·ªët trong vLLM** ƒë·ªÉ t·∫≠n d·ª•ng hi·ªáu qu·∫£ ph·∫ßn c·ª©ng.\n",
        "\n",
        "3. ### üìâ **Kh√¥ng khuy·∫øn kh√≠ch d√πng LLaMA 1B cho function calling**\n",
        "   - 1B qu√° y·∫øu, ƒë√£ th·ª≠ v√† **kh√¥ng x·ª≠ l√Ω t·ªët c√°c b√†i function routing**.\n",
        "   - G·ª£i √Ω: **T·ªëi thi·ªÉu d√πng 3B**, t·ªët nh·∫•t l√† **8B tr·ªü l√™n** n·∫øu b√†i to√°n y√™u c·∫ßu logic r√µ v√† ph·∫£n h·ªìi ch√≠nh x√°c.\n",
        "\n",
        "4. ### üîÅ **X√¢y d·ª±ng ki·∫øn tr√∫c linh ho·∫°t ‚Äì Routing ki·ªÉu proxy**\n",
        "   - Khuy√™n b·∫°n n√™n **vi·∫øt m·ªôt proxy app** ƒë·ª©ng gi·ªØa ƒë·ªÉ **route request ƒë·∫øn c√°c provider** (OpenAI, GROQ, Local model‚Ä¶).\n",
        "   - M·ª•c ti√™u: Linh ho·∫°t, d·ªÖ thay ƒë·ªïi provider, t·ªëi ∆∞u chi ph√≠ v√† t·ªëc ƒë·ªô.\n",
        "\n",
        "5. ### üß© **S·ª≠ d·ª•ng LangChain ƒë·ªÉ t·ªï ch·ª©c code v√† logic g·ªçn g√†ng h∆°n**\n",
        "   - LangChain c√≥ s·∫µn c√°c ƒëo·∫°n **prompt enforce**, h·ªó tr·ª£ function calling, RAG, agents.\n",
        "   - Code r√µ r√†ng, d·ªÖ maintain, d·ªÖ scale khi h·ªá th·ªëng l·ªõn d·∫ßn.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ T·ªïng k·∫øt:\n",
        "| M·∫£ng | G·ª£i √Ω c·ªßa anh ƒê·ª©c |\n",
        "|------|--------------------|\n",
        "| Training | Kh√¥ng d√πng Colab cho production |\n",
        "| Inference | D√πng vLLM + GPU m·∫°nh (nh∆∞ 4090), t·ªëi ∆∞u parallel |\n",
        "| Model | Tr√°nh d√πng 1B, khuy√™n d√πng ‚â• 3B, t·ªët nh·∫•t l√† 8B |\n",
        "| Ki·∫øn tr√∫c | T·∫°o **proxy app** ƒë·ªÉ routing gi·ªØa c√°c model/provider |\n",
        "| Framework | D√πng **LangChain** ƒë·ªÉ code s·∫°ch, d·ªÖ m·ªü r·ªông |\n",
        "\n",
        "---\n",
        "\n",
        "N·∫øu b·∫°n c·∫ßn **b·∫£n ki·∫øn tr√∫c minh ho·∫°** ho·∫∑c h∆∞·ªõng d·∫´n vi·∫øt proxy + LangChain demo, m√¨nh s·∫µn s√†ng h·ªó tr·ª£ nh√©!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "017876ee706e46ad8a6b501fb13ee20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03c07ba76cdf42468333d70f1a2a60de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "049d88b5159a44dc9d5a2e6c49eddc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05551557875a4640aa0073d692c7059a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058d6688c859483aae3d4208f4675b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09f2a0084d134dbe92402177266492b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa857b7a66ee4e1caac5e820f55a45b6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4c321ed9a4f446e1ac577db35b555111",
            "value": "‚Äá1.10G/1.10G‚Äá[00:10&lt;00:00,‚Äá342MB/s]"
          }
        },
        "0d6209bf037b49be8127d2dc262361b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142e10c4b2c7411884a7d2cea478ac00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16ee02d4b9054159a3897bf8105c903f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d327df941f44ef80c83ce64e70cfbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ca2662b396459195b2bf6c76f21297": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab62048a3e6404f86f6f06bfc9b6f09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b463ba27b514b73861066a86b410b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_250257655a514463819c8a9e3719dcd2",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_058d6688c859483aae3d4208f4675b4c",
            "value": 100000
          }
        },
        "1c6384b1f212446abd327aa3d13091de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1d74c2f15044af9fe4033077e7f7ae",
              "IPY_MODEL_69a34e345a93486593ac6043f3458004",
              "IPY_MODEL_09f2a0084d134dbe92402177266492b6"
            ],
            "layout": "IPY_MODEL_7452ccb8a900428f8e92e0e1cb79ca22"
          }
        },
        "1e2bff362abb474ba86bd044c58f292c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23185bc9d81340a7a51d900570721665": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "250257655a514463819c8a9e3719dcd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26f5a1ec2e7549f19ac3bff1dfd54d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2bff362abb474ba86bd044c58f292c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e801fc7156854a61b049432c17b4abba",
            "value": "‚Äá100000/100000‚Äá[00:06&lt;00:00,‚Äá15670.44‚Äáexamples/s]"
          }
        },
        "27b1e06990f9471ab885b6be8328e960": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee5f8ba2dec94153821f3bc81b59457b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d5990b6766dc454fba8c81bfc6c7b1e4",
            "value": "‚Äá234/234‚Äá[00:00&lt;00:00,‚Äá22.2kB/s]"
          }
        },
        "287048456b4644d28e36a25266fdb6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae08fe4e1844336814ab54d16807ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f35a35a7881043ffad022b243e26d327",
            "max": 54674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d69e2407465448dfb2360c1dad38b0ff",
            "value": 54674
          }
        },
        "2d5734dad68f4fe4a95d129fe48686f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37bd22ef564d4aa8ae9c9e8bb3c10376": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38629e76fb6f4d60b9f4ef878f735a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ad85c98d2494064b6268d1d92762e04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c8d9dce829e4389bf54d3d2dff32902": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_899d1a1d58714f1d902dbc1aa4dd21c9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_017876ee706e46ad8a6b501fb13ee20e",
            "value": "‚Äá454/454‚Äá[00:00&lt;00:00,‚Äá40.1kB/s]"
          }
        },
        "3f4d3686e13342eea8c4bb8195ef11de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f573ea4e5554044b4019374859b50b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce47bc3177604cd2ad4da725dd32d803",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_aa7146540c344f1b9b69f2daa54977e8",
            "value": "Map:‚Äá100%"
          }
        },
        "4453329737c8482baf632a4dac7268b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287048456b4644d28e36a25266fdb6bc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_47eed36adad442d59853f8a1243d90e8",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "447774b34e4142049108ae0d2b0e4a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "448d404648b04e518b5e7d36bb9a5cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0513a34e9524c069a9dd270ea438a17",
            "max": 116531415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_447774b34e4142049108ae0d2b0e4a88",
            "value": 116531404
          }
        },
        "4577563c881a4376a3b2ea4a22432384": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4709697b6c984ade8286340931bb322f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a77d4f34524d0aa5ca353ea8b2203c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d3faa712ce464b4aa314f3e3bfd3522f",
            "value": "README.md:‚Äá100%"
          }
        },
        "47ceb466537a44a3aa1cbc1936c035c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47eed36adad442d59853f8a1243d90e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4859770bd8f04f09aec5e52f7253d7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c07ba76cdf42468333d70f1a2a60de",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e93a06aa6e504616890890eb80dc23c7",
            "value": 100000
          }
        },
        "4c321ed9a4f446e1ac577db35b555111": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c9798584a174ab4ac499bcd2f1a10ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba2037c504b64a3db24f725cce2afa6e",
              "IPY_MODEL_c1d904edfd3f4efda7be1015c68d4a07",
              "IPY_MODEL_3c8d9dce829e4389bf54d3d2dff32902"
            ],
            "layout": "IPY_MODEL_533eb9d0e2a347908c77bcde4caf323f"
          }
        },
        "4f4ada6605bd46b28aad94cb299a1667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cf7c623df60435ead23ade8189a25e2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_78361572656643dbba4ae7e0c93e67b9",
            "value": "‚Äá54.7k/54.7k‚Äá[00:00&lt;00:00,‚Äá5.05MB/s]"
          }
        },
        "506095da4fcb41f4b25cf399c8eed31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5081494531e04b9eba67cedbf2d54f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81831cba627e49c383ff94c884c2faa4",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_842ef96b344a4511ad31591fd147edf3",
            "value": 100000
          }
        },
        "533eb9d0e2a347908c77bcde4caf323f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57da248e03014383abaed60ea25d85f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da578300a4f149f2b49131f86285b4a3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_940fc2a62f7b4d6d944c4472aaa893d4",
            "value": "‚Äá3892/3892‚Äá[00:00&lt;00:00,‚Äá6305.72‚Äáexamples/s]"
          }
        },
        "588d180dd44f42bc95dafc198e40191f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f573ea4e5554044b4019374859b50b9",
              "IPY_MODEL_1b463ba27b514b73861066a86b410b51",
              "IPY_MODEL_d19900d70c0245baa491690339acb455"
            ],
            "layout": "IPY_MODEL_0d6209bf037b49be8127d2dc262361b4"
          }
        },
        "5a8ac1b0b9184b168dd0a1370ef64f07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf7c623df60435ead23ade8189a25e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6041f6abb32b4edb84a591ee4f11d19b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64013e3effda4ef69c70a594dee38c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e0c1d99321547f49263bec84dcda4bb",
              "IPY_MODEL_4859770bd8f04f09aec5e52f7253d7b6",
              "IPY_MODEL_26f5a1ec2e7549f19ac3bff1dfd54d07"
            ],
            "layout": "IPY_MODEL_d1cd17b85c1c4634a06991bae10a42b6"
          }
        },
        "69a34e345a93486593ac6043f3458004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ee02d4b9054159a3897bf8105c903f",
            "max": 1102370060,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23185bc9d81340a7a51d900570721665",
            "value": 1102369955
          }
        },
        "6fa5b2ba9b7d47c9aa9762e3af119d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72e8f2ad4c5149bab1ae408fbb7256b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e80052a8c8b841bba8deeb1932026498",
              "IPY_MODEL_78599ca1e4b5497d923fffef679b5b9b",
              "IPY_MODEL_deb38efb9cc24884a5791146222588f3"
            ],
            "layout": "IPY_MODEL_1ab62048a3e6404f86f6f06bfc9b6f09"
          }
        },
        "7452ccb8a900428f8e92e0e1cb79ca22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746bedf554884b95aabe9123a5c33599": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75149660c3ef43e1a5a7cf035684354d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78361572656643dbba4ae7e0c93e67b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78599ca1e4b5497d923fffef679b5b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c756e9df18a74abb8a077f1afe4fec4f",
            "max": 3892,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_def75a05364f447096be1e47fb0802f7",
            "value": 3892
          }
        },
        "7afbad83e0a743bdbc1f6ee9bf835ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c1d74c2f15044af9fe4033077e7f7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a12d857b48e849488cb897ebf978371a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d0f5c5a096184bf18b2436b622b9ae2e",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "7fa865db91204697b2b2f48b728cc1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c204744f05a541958dbfba729f44726a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4577563c881a4376a3b2ea4a22432384",
            "value": "train-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "7fb7c8f739e949a7a1c05e96b8fe3f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37bd22ef564d4aa8ae9c9e8bb3c10376",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_142e10c4b2c7411884a7d2cea478ac00",
            "value": "‚Äá100000/100000‚Äá[00:04&lt;00:00,‚Äá10546.78‚Äáexamples/s]"
          }
        },
        "81831cba627e49c383ff94c884c2faa4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82c0e3ffbf344f2ab2db5a560112925d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "842ef96b344a4511ad31591fd147edf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84e1da25e8e74367baa91f079f32a894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85a83f0d471f4d7dadc74c504a93e6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8629eaef818349ccbda2ba25763c97a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "899d1a1d58714f1d902dbc1aa4dd21c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aab516dd25d4dbba9a442a38f0f1675": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2f0fd0badb54f0b9a9c632570d46a95",
            "max": 982,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1d0aff021ec42cf80196a7ec7a3aae8",
            "value": 982
          }
        },
        "8bb9efb10f9544c8bdebdfa47699dda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6b0e10816aa491399a90d8d6ef3d8bf",
              "IPY_MODEL_aff7d7105b3949ada048dbabcb94676f",
              "IPY_MODEL_a7eb4b7641fc4ecbacb49a4c69e02a05"
            ],
            "layout": "IPY_MODEL_8faeb5a617fb48a2a4040059710942e9"
          }
        },
        "8e0c1d99321547f49263bec84dcda4bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82c0e3ffbf344f2ab2db5a560112925d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_afd2a2e6db0041be993f9c402a3691bc",
            "value": "Unsloth:‚ÄáStandardizing‚Äáformats‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "8faeb5a617fb48a2a4040059710942e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940233f16aaf437c8c6fbb2eeb225cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940fc2a62f7b4d6d944c4472aaa893d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98285664db874bef8ca985d4cf2e1f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b705313e5fb34662a143f00ac1e72e81",
              "IPY_MODEL_2ae08fe4e1844336814ab54d16807ee6",
              "IPY_MODEL_4f4ada6605bd46b28aad94cb299a1667"
            ],
            "layout": "IPY_MODEL_e24e40079d804d4f8607d4ecfd512423"
          }
        },
        "9b2e4804311a4bbc86d91893732fe34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a863698fa76f4de5ab960232ed367bf8",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee48ecaab31d4df2a007f24e8346828e",
            "value": 234
          }
        },
        "9d0f018c0207448b8c386f7526a30b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a12d857b48e849488cb897ebf978371a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d0aff021ec42cf80196a7ec7a3aae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4a77d4f34524d0aa5ca353ea8b2203c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b0e10816aa491399a90d8d6ef3d8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f02daceba54740c6956f204f77a08a4f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8629eaef818349ccbda2ba25763c97a1",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "a7eb4b7641fc4ecbacb49a4c69e02a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6041f6abb32b4edb84a591ee4f11d19b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7afbad83e0a743bdbc1f6ee9bf835ade",
            "value": "‚Äá17.2M/17.2M‚Äá[00:00&lt;00:00,‚Äá38.5MB/s]"
          }
        },
        "a863698fa76f4de5ab960232ed367bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa7146540c344f1b9b69f2daa54977e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abe819fba71245d5942a0cca19d4ad90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c573e52a2a494e3989ed592e5da79289",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_746bedf554884b95aabe9123a5c33599",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "afd2a2e6db0041be993f9c402a3691bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aff7d7105b3949ada048dbabcb94676f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19ca2662b396459195b2bf6c76f21297",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_506095da4fcb41f4b25cf399c8eed31f",
            "value": 17209920
          }
        },
        "b705313e5fb34662a143f00ac1e72e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba407c2e00fa4d24bed452f30b5634f6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9d0f018c0207448b8c386f7526a30b5d",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "ba2037c504b64a3db24f725cce2afa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d244239f6107409e925a2838a354b741",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6fa5b2ba9b7d47c9aa9762e3af119d93",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "ba407c2e00fa4d24bed452f30b5634f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf7c96661bf4415a271112654b259f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4453329737c8482baf632a4dac7268b8",
              "IPY_MODEL_9b2e4804311a4bbc86d91893732fe34f",
              "IPY_MODEL_27b1e06990f9471ab885b6be8328e960"
            ],
            "layout": "IPY_MODEL_dcd94f17eacd416fb18448496b024922"
          }
        },
        "c0513a34e9524c069a9dd270ea438a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d904edfd3f4efda7be1015c68d4a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05551557875a4640aa0073d692c7059a",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8f6fa2912644d1ebdac0a59d8eb9dbf",
            "value": 454
          }
        },
        "c204744f05a541958dbfba729f44726a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f0fd0badb54f0b9a9c632570d46a95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c573e52a2a494e3989ed592e5da79289": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a82899b3f844ce9729ada19592e71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fa865db91204697b2b2f48b728cc1fd",
              "IPY_MODEL_448d404648b04e518b5e7d36bb9a5cc5",
              "IPY_MODEL_cafaa12878c14f6b9d2408599ac00306"
            ],
            "layout": "IPY_MODEL_f725dc3f6d694996a80b36ea07b08597"
          }
        },
        "c756e9df18a74abb8a077f1afe4fec4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f6fa2912644d1ebdac0a59d8eb9dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cad345523e7a40db90d8dbfd735e8387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafaa12878c14f6b9d2408599ac00306": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75149660c3ef43e1a5a7cf035684354d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cad345523e7a40db90d8dbfd735e8387",
            "value": "‚Äá117M/117M‚Äá[00:00&lt;00:00,‚Äá121MB/s]"
          }
        },
        "cdd25e0c0e9b432dbd14386b86baa23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdd8aadb8dca437fa27a89c4485572c1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_47ceb466537a44a3aa1cbc1936c035c4",
            "value": "‚Äá982/982‚Äá[00:00&lt;00:00,‚Äá102kB/s]"
          }
        },
        "cdd8aadb8dca437fa27a89c4485572c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce47bc3177604cd2ad4da725dd32d803": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d04c5cdf93ae4632a0bfa75a3577ec43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebef9e31e63d4909ba0067eeef482e37",
              "IPY_MODEL_d951a1aca8ab4bf5baa32b9051507e7c",
              "IPY_MODEL_57da248e03014383abaed60ea25d85f1"
            ],
            "layout": "IPY_MODEL_e8ed858cc8c448b5a02fd5666a0e5749"
          }
        },
        "d0f5c5a096184bf18b2436b622b9ae2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d19900d70c0245baa491690339acb455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a8ac1b0b9184b168dd0a1370ef64f07",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2d5734dad68f4fe4a95d129fe48686f5",
            "value": "‚Äá100000/100000‚Äá[00:18&lt;00:00,‚Äá10795.85‚Äáexamples/s]"
          }
        },
        "d1cd17b85c1c4634a06991bae10a42b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d244239f6107409e925a2838a354b741": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3faa712ce464b4aa314f3e3bfd3522f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5990b6766dc454fba8c81bfc6c7b1e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d69e2407465448dfb2360c1dad38b0ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d951a1aca8ab4bf5baa32b9051507e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f4d3686e13342eea8c4bb8195ef11de",
            "max": 3892,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3d1352f4c404c9d8884eac634fc15a1",
            "value": 3892
          }
        },
        "da578300a4f149f2b49131f86285b4a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd94f17eacd416fb18448496b024922": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb38efb9cc24884a5791146222588f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85a83f0d471f4d7dadc74c504a93e6bb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_38629e76fb6f4d60b9f4ef878f735a86",
            "value": "‚Äá3892/3892‚Äá[00:00&lt;00:00,‚Äá7044.93‚Äáexamples/s]"
          }
        },
        "def75a05364f447096be1e47fb0802f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e24e40079d804d4f8607d4ecfd512423": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e68ee188d19d41f0a4bcdaae03ab507f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4709697b6c984ade8286340931bb322f",
              "IPY_MODEL_8aab516dd25d4dbba9a442a38f0f1675",
              "IPY_MODEL_cdd25e0c0e9b432dbd14386b86baa23f"
            ],
            "layout": "IPY_MODEL_fb6b52578aff4b2c9c69f7d0dd36647d"
          }
        },
        "e80052a8c8b841bba8deeb1932026498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18d327df941f44ef80c83ce64e70cfbc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_84e1da25e8e74367baa91f079f32a894",
            "value": "Unsloth:‚ÄáStandardizing‚Äáformats‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "e801fc7156854a61b049432c17b4abba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8ed858cc8c448b5a02fd5666a0e5749": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e93a06aa6e504616890890eb80dc23c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebef9e31e63d4909ba0067eeef482e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_940233f16aaf437c8c6fbb2eeb225cb6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_049d88b5159a44dc9d5a2e6c49eddc71",
            "value": "Map:‚Äá100%"
          }
        },
        "ee48ecaab31d4df2a007f24e8346828e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee5f8ba2dec94153821f3bc81b59457b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeab2ee6dc8748bc8bad5698ab9deb88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abe819fba71245d5942a0cca19d4ad90",
              "IPY_MODEL_5081494531e04b9eba67cedbf2d54f10",
              "IPY_MODEL_7fb7c8f739e949a7a1c05e96b8fe3f81"
            ],
            "layout": "IPY_MODEL_3ad85c98d2494064b6268d1d92762e04"
          }
        },
        "f02daceba54740c6956f204f77a08a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35a35a7881043ffad022b243e26d327": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d1352f4c404c9d8884eac634fc15a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f725dc3f6d694996a80b36ea07b08597": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa857b7a66ee4e1caac5e820f55a45b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb6b52578aff4b2c9c69f7d0dd36647d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
