{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGzwlSh_Dces"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGQMUC7zDcew"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i22jwpfiDcex"
      },
      "source": [
        "**Read our [Gemma 3 blog](https://unsloth.ai/blog/gemma3) for what's new in Unsloth and our [Reasoning blog](https://unsloth.ai/blog/r1-reasoning) on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgzRh1JxDcex"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHcnMLNMDcey"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLW1bNuIDcez"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "798cca80f27f4e76a84a5e4722fca4ab",
            "e62a9675952b487bb1144a6faa834c14",
            "47fd4cd89df94138880ad1e59a70bd11",
            "66867dd10cde4f51ae7c106ebc914758",
            "892787c5662c4466a04ccb2a62a49d16",
            "007c75fd113d45519aca4f744c2a9941",
            "e8d246d539e24b2c88eb5a93d930b4b4",
            "1fb570fe4f204d44af55665dfbe56db0",
            "4708411d0d274b8e91982b19708e2cc3",
            "4f0fd1fbe6da493f82812f0f6670d8d0",
            "2ef7b44f2ee9485b8765f59f5feddf16",
            "7e49529f1a124498be682c72bb8c4e70",
            "831583833d3749b8849ba7aee9e58715",
            "d4d37043532c43609a8cbf2364000e31",
            "f688d367e1c64eafa930af4cc66a6c54",
            "55bc4ab554a542d5908886ad5b98a449",
            "026ca58c2a54473bb3f939310566afb1",
            "33358b3d957b4c1dbacd9ce07a8339a3",
            "a53869e54a094f16978d0c67281c96c8",
            "5070622f631c4916b95c47e99474bd45",
            "118fa571fc0a4696b1dd9a84a3ea74ae",
            "6ee6a5287a4e4e9b8fdc97be297480bb",
            "f3f4cf774da24ca6bede3c2c21922583",
            "e0de8a5b172947348931367047429527",
            "d497eb8cc7c34c359930b6f0dd1fc9af",
            "6f0e94a109ad4058be2a5f58e817a150",
            "d327101e169441928a343fb90ea2cc54",
            "9fa35136b1d349dda04c2111a728a3b4",
            "c8afccc63aa741bdb73a70abdc8e05bc",
            "63ec18ccc3264140bc170226ebd9fe82",
            "32e2f4111e514cc6b5666321d30b3a3e",
            "5654eaa262b54d9696fdaf4ab58eae92",
            "c0aeb6d5f4f84de58c73ed237ae3ce82",
            "5796e0df331646909b82aa18ec0b1bff",
            "31dba2047019487c85837310a02334f1",
            "4bc5fe1bfc0742319554ede3a5c8cc3a",
            "f7396523b90c43028e84edc4dbe5c4b3",
            "dca07581328847d280595afe9ddada7c",
            "9c3e6cc9759e442381d02be513389542",
            "95331b2a93bb4b128bcf6fc21d93520a",
            "a038fe1a5f4c48e5b6c16102f57f3648",
            "d78442baa0f04d8080a53e3dcb067dc2",
            "49e5546522cb4a2b95f2eefa7592e41d",
            "13d4cead911d4eefa8f1d53ea4214643",
            "d36f1825a3ae4ebcaae202f7d8c07059",
            "b4da22e2e64b446ea8b745e04596efe7",
            "436e91f6210d4d1585afe914bbefcb54",
            "8dbfdc4e23b449c683c29e60f13d926f",
            "a45d461f178246508f4f2f5c62a9d029",
            "b263d61463a94e22aa896a4960cabbf4",
            "fa0ee322f0874cccb95de9d154824f4c",
            "13eb99a3ed8d4f95b3a4d4e9c5a9cce8",
            "e91cf7705864468caa557ae4db180f5a",
            "4659e671d8364964b2db9d10767bf3b8",
            "29a599136d5d4dd1a9f7b5629742838a"
          ]
        },
        "id": "8HIHvIjIDce0",
        "outputId": "844d9f0e-5a3b-4d27-89af-26f172613cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.18: Fast Llama patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "798cca80f27f4e76a84a5e4722fca4ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e49529f1a124498be682c72bb8c4e70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3f4cf774da24ca6bede3c2c21922583"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5796e0df331646909b82aa18ec0b1bff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d36f1825a3ae4ebcaae202f7d8c07059"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
        "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-1B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "47c608f2-f264-4735-82ce-b175b12a5e2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.18 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "I'm great thanks!<|eot_id|>\n",
        "```\n",
        "\n",
        "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "# from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "# tokenizer = get_chat_template(\n",
        "#     tokenizer,\n",
        "#     chat_template = \"llama-3.1\",\n",
        "# )\n",
        "\n",
        "# def formatting_prompts_func(examples):\n",
        "#     convos = examples[\"conversations\"]\n",
        "#     texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "#     return { \"text\" : texts, }\n",
        "# pass\n",
        "\n",
        "# from datasets import load_dataset\n",
        "# dataset = load_dataset(\"mlabonne/FineTome-100k\", split = \"train\")\n",
        "\n",
        "# Nhập hàm get_chat_template từ module unsloth.chat_templates\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "# Sử dụng hàm get_chat_template để cấu hình lại tokenizer theo template chat \"llama-3.1\"\n",
        "# Lưu ý: biến tokenizer phải được định nghĩa trước đó hoặc được truyền vào từ một nguồn khác\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,                      # Biến tokenizer đã có\n",
        "    chat_template=\"llama-3.1\",      # Chọn template chat \"llama-3.1\" để định dạng các cuộc hội thoại\n",
        ")\n",
        "\n",
        "# Định nghĩa hàm formatting_prompts_func với tham số đầu vào là examples\n",
        "def formatting_prompts_func(examples):\n",
        "    # Lấy danh sách các cuộc hội thoại từ key \"conversations\" trong đối tượng examples\n",
        "    convos = examples[\"conversations\"]\n",
        "    # Áp dụng template chat cho mỗi cuộc hội thoại trong convos, không thực hiện tokenize và không thêm generation prompt\n",
        "    # Kết quả là danh sách các chuỗi văn bản đã được định dạng\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
        "    # Trả về một dictionary với key \"text\" chứa danh sách các chuỗi văn bản đã định dạng\n",
        "    return {\"text\": texts,}\n",
        "\n",
        "# Dòng pass ở đây không có tác dụng cụ thể vì đã có return, có thể được giữ lại hoặc loại bỏ tùy ý\n",
        "pass\n",
        "\n",
        "# Nhập hàm load_dataset từ thư viện datasets để tải bộ dữ liệu\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Tải bộ dữ liệu \"mlabonne/FineTome-100k\" với phần dữ liệu huấn luyện (split=\"train\")\n",
        "dataset = load_dataset(\"mlabonne/FineTome-100k\", split=\"train\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFOddryqGby-",
        "outputId": "c04d0c92-9c67-4acf-942d-0904309814ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['conversations', 'source', 'score'],\n",
            "    num_rows: 100000\n",
            "})\n",
            "Mẫu dữ liệu thứ 0:  {'conversations': [{'from': 'human', 'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'}, {'from': 'gpt', 'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}], 'source': 'infini-instruct-top-500k', 'score': 5.212620735168457}\n",
            "Mẫu dữ liệu thứ 1:  {'conversations': [{'from': 'human', 'value': 'Explain how recursion works and provide a recursive function in Python that calculates the factorial of a given number.'}, {'from': 'gpt', 'value': \"Recursion is a programming technique where a function calls itself to solve a problem. It breaks down a complex problem into smaller, more manageable subproblems until a base case is reached. The base case is a condition where the function does not call itself, but instead returns a specific value or performs a specific action.\\n\\nIn the case of calculating the factorial of a number, recursion can be used to break down the problem into simpler subproblems. The factorial of a non-negative integer n is the product of all positive integers less than or equal to n.\\n\\nHere is a recursive function in Python that calculates the factorial of a given number:\\n\\n```python\\ndef factorial(n):\\n    # Base case: factorial of 0 or 1 is 1\\n    if n == 0 or n == 1:\\n        return 1\\n    # Recursive case: factorial of n is n multiplied by factorial of (n-1)\\n    else:\\n        return n * factorial(n - 1)\\n```\\n\\nIn this function, the base case is when n equals 0 or 1, as the factorial of these numbers is defined as 1. For any other positive integer, the function calls itself with a smaller value (n-1) and multiplies the result by n.\\n\\nFor example, let's calculate the factorial of 5 using this function:\\n\\n```python\\nprint(factorial(5))\\n```\\n\\nThe function will execute as follows:\\n1. factorial(5) calls factorial(4) and multiplies the result by 5.\\n2. factorial(4) calls factorial(3) and multiplies the result by 4.\\n3. factorial(3) calls factorial(2) and multiplies the result by 3.\\n4. factorial(2) calls factorial(1) and multiplies the result by 2.\\n5. factorial(1) is a base case and returns 1.\\n6. The final result is calculated as: 5 * 4 * 3 * 2 * 1 = 1\"}], 'source': 'infini-instruct-top-500k', 'score': 5.157649040222168}\n",
            "Mẫu dữ liệu thứ 2:  {'conversations': [{'from': 'human', 'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions.\\n\\nFurthermore, discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. Finally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions.'}, {'from': 'gpt', 'value': 'Boolean operators are logical operators used to combine or manipulate boolean values in programming. They allow you to perform comparisons and create complex logical expressions. The three main boolean operators are:\\n\\n1. AND operator (&&): Returns true if both operands are true. Otherwise, it returns false. For example:\\n   - `true && true` returns true\\n   - `true && false` returns false\\n\\n2. OR operator (||): Returns true if either of the operands is true. Otherwise, it returns false. For example:\\n   - `true || false` returns true\\n   - `false || false` returns false\\n\\n3. NOT operator (!): Returns the opposite of the operand\\'s boolean value. If the operand is true, it returns false, and vice versa. For example:\\n   - `!true` returns false\\n   - `!false` returns true\\n\\nBoolean operators are commonly used in conditional statements and loops to control the flow of execution based on certain conditions. They help make decisions and determine the truthiness or falsiness of expressions.\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. In programming languages, certain operators have higher precedence than others, and they are evaluated first. For example, in the expression `a && b || c`, the && operator has higher precedence than the || operator, so `a && b` is evaluated first, and then the result is combined with c using ||.\\n\\nParentheses can be used to alter the precedence of operators. For example, `(a && b) || c` ensures that the && operator is evaluated before the || operator.\\n\\nShort-circuit evaluation is a behavior exhibited by some programming languages when evaluating boolean expressions. In short-circuit evaluation, the evaluation stops as soon as the final result is determined. For example, in the expression `a && b`, if a is false, there is no need to evaluate b because the overall result will always be false. Similarly, in the expression `a || b`, if a is true, there is no need to evaluate b because the overall result will always be true. This behavior can be useful for optimizing code and preventing unnecessary evaluations.\\n\\nHere are examples demonstrating short-circuit evaluation in code:\\n\\n```python\\n# Example 1\\na = False\\nb = True\\nif a and b:  # Since a is False, b is not evaluated\\n    print(\"This line won\\'t be executed\")\\n\\n# Example 2\\nx = 10\\ny = 0\\nif y != 0 and x / y > 2:  # Since y is 0, the division is not evaluated to avoid division by zero error\\n    print(\"This line won\\'t be executed\")\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are treated as booleans in certain contexts. In many programming languages, values other than true or false can be implicitly converted to boolean values. In this context, truthiness means that a value evaluates to true, and falsiness means that a value evaluates to false.\\n\\nIn most programming languages, the following values are considered falsy:\\n- false\\n- 0 (zero)\\n- \"\" (empty string)\\n- null or undefined\\n- NaN (not-a-number)\\n\\nAll other values are considered truthy.\\n\\nTruthiness and falsiness affect the evaluation of boolean expressions. For example, in an if statement, if the condition is a non-boolean value, it will be implicitly converted to a boolean value based on its truthiness or falsiness.\\n\\n```javascript\\n// Example\\nlet value = 0;\\nif (value) {\\n    console.log(\"This line won\\'t be executed\"); // value is falsy, so the condition is false\\n}\\n```\\n\\nUnderstanding boolean operators, operator precedence, short-circuit evaluation, and truthiness/falsiness is crucial for writing effective and correct code, especially in conditional logic.'}], 'source': 'infini-instruct-top-500k', 'score': 5.147540092468262}\n",
            "Mẫu dữ liệu thứ 3:  {'conversations': [{'from': 'human', 'value': 'Explain the concept of recursion with an example, while also implementing a recursive function in a programming language of your choice. Your implementation should include at least two base cases and demonstrate the proper use of recursive calls.'}, {'from': 'gpt', 'value': \"Recursion is a programming concept where a function calls itself to solve a problem by breaking it down into smaller, more manageable subproblems. Each recursive call works on a smaller portion of the problem until a base case is reached, at which point the recursion stops and the function returns the result.\\n\\nLet's explain recursion with an example of calculating the factorial of a number. The factorial of a non-negative integer n, denoted by n!, is the product of all positive integers less than or equal to n.\\n\\nHere's an example implementation of a recursive function to calculate the factorial in Python:\\n\\n```python\\ndef factorial(n):\\n    # Base case 1: factorial of 0 or 1 is 1\\n    if n == 0 or n == 1:\\n        return 1\\n\\n    # Recursive call: factorial of n is n multiplied by factorial of (n-1)\\n    return n * factorial(n - 1)\\n```\\n\\nIn this implementation, we have two base cases. When n is 0 or 1, we know that the factorial is 1, so we return 1 to stop the recursion.\\n\\nFor any other positive integer n, we make a recursive call to the factorial function with n - 1. This breaks down the problem into smaller subproblems until one of the base cases is reached.\\n\\nHere's an example usage of the factorial function:\\n\\n```python\\nprint(factorial(5))  # Output: 120\\n```\\n\\nWhen we call `factorial(5)`, it starts the recursion process. The function calculates `5 * factorial(4)`, which further calculates `4 * factorial(3)`, and so on. Eventually, the recursion reaches the base case of `factorial(1)`, which returns 1. The intermediate results are then propagated back, and the final result of `5 * 4 * 3 * 2 * 1` is returned, which equals 1\"}], 'source': 'infini-instruct-top-500k', 'score': 5.053655624389648}\n",
            "Mẫu dữ liệu thứ 4:  {'conversations': [{'from': 'human', 'value': 'Print the reverse of a string using a for loop.'}, {'from': 'gpt', 'value': 'Here is an example code using a for loop to print the reverse of a string along with a detailed docstring:\\n\\n```python\\ndef print_reverse_string(string):\\n    \"\"\"\\n    Prints the reverse of a given string using a for loop.\\n\\n    Parameters:\\n    string (str): The string to be reversed and printed.\\n\\n    Returns:\\n    None.\\n    \"\"\"\\n\\n    # Iterate through the characters of the string in reverse order\\n    for i in range(len(string)-1, -1, -1):\\n        print(string[i], end=\\'\\')\\n\\n    # Print a new line after printing the whole reversed string\\n    print()\\n\\n# Example usage\\ninput_string = input(\"Enter a string: \")\\nprint_reverse_string(input_string)\\n```\\n\\nIn this code, the `print_reverse_string` function takes a string as input. It uses a for loop to iterate through the characters of the string in reverse order. The for loop starts from the index of the last character (`len(string)-1`) and goes until the first character (`-1`), with a step of `-1`. In each iteration, the function prints the character using the `print` function and `end=\\'\\'` is used to avoid printing the default newline character after each character. Finally, after printing the whole reversed string, `print()` is called to print a new line.'}], 'source': 'infini-instruct-top-500k', 'score': 5.045647621154785}\n"
          ]
        }
      ],
      "source": [
        "# In ra thông tin tổng quan của dataset\n",
        "print(dataset)\n",
        "\n",
        "# In ra 5 mẫu dữ liệu đầu tiên trong dataset\n",
        "for i in range(5):\n",
        "    print(f\"Mẫu dữ liệu thứ {i}: \", dataset[i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NOEtNJvNg-C",
        "outputId": "cabc88b2-f791-4f45-ff5b-d1737f9fe7a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'from': 'human',\n",
              "  'value': 'How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?'},\n",
              " {'from': 'gpt',\n",
              "  'value': 'Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "dataset[5][\"conversations\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "We now use `standardize_sharegpt` to convert ShareGPT style datasets into HuggingFace's generic format. This changes the dataset from looking like:\n",
        "```\n",
        "{\"from\": \"system\", \"value\": \"You are an assistant\"}\n",
        "{\"from\": \"human\", \"value\": \"What is 2+2?\"}\n",
        "{\"from\": \"gpt\", \"value\": \"It's 4.\"}\n",
        "```\n",
        "to\n",
        "```\n",
        "{\"role\": \"system\", \"content\": \"You are an assistant\"}\n",
        "{\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
        "{\"role\": \"assistant\", \"content\": \"It's 4.\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dXTSyNynI5-H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "47475fb3e483454aa26b6d71516620b3",
            "3037c9a058a14b868e52e6bd9f25d823",
            "0d170b66d0fe47e98a9220bf325d697a",
            "5f0d75d525d341b5a21e2efab7aa179c",
            "8f71ef527f914518ab536c5892a369b4",
            "ad5c1e25ad784961a778e6e1591f5d99",
            "601ceedefcb946209c6d6e5e3e5cde3d",
            "4b01ac32a5d1434a8c71be19b24d802b",
            "320c2351438343009f434ff31c36cc59",
            "bd79c1e8e8074c29a39c73412cc3a9d9",
            "839150163edb40c48f0fc359f662fe50"
          ]
        },
        "id": "oPXzJZzHEgXe",
        "outputId": "194c0620-7660-494c-a5bf-a3037aacfb28"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47475fb3e483454aa26b6d71516620b3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# from unsloth.chat_templates import standardize_sharegpt\n",
        "# dataset = standardize_sharegpt(dataset)\n",
        "# dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "\n",
        "# Nhập hàm standardize_sharegpt từ module unsloth.chat_templates để chuẩn hóa định dạng dữ liệu\n",
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "\n",
        "# Sử dụng hàm standardize_sharegpt để chuẩn hóa dataset về định dạng sharegpt\n",
        "dataset = standardize_sharegpt(dataset)\n",
        "\n",
        "# Áp dụng hàm formatting_prompts_func cho từng mẫu trong dataset bằng cách sử dụng phương thức map\n",
        "# Tham số batched=True cho phép xử lý nhiều mẫu cùng lúc, giúp tăng hiệu quả khi áp dụng hàm\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE9zYJjIHnyE"
      },
      "source": [
        "Hỏi:\n",
        "```\n",
        "Hàm này chỉ xử lý conversations thui chứ source, với score ko xử lý nhỉ. giờ tôi đang có 1 bộ dataset khác ý nó có conversations ko có source với score\n",
        "```\n",
        "=> Đúng vậy. Hàm `formatting_prompts_func` mà bạn đã định nghĩa chỉ tập trung xử lý trường `conversations`, còn các trường như `source` và `score` không được ảnh hưởng. Nếu bạn có một bộ dataset khác mà chỉ chứa trường `conversations` (không có `source` và `score`), thì hàm này vẫn hoạt động bình thường, vì nó chỉ lấy và xử lý nội dung của `conversations` để tạo ra các prompt định dạng. Bạn không cần thay đổi gì nếu bạn chỉ muốn xử lý cuộc hội thoại.\n",
        "\n",
        "Hỏi:\n",
        "```\n",
        "tức là nếu nó chuẩn rồi thì sao, kiểu data của mình đã chuẩn luôn system - user - assistant rồi\n",
        "```\n",
        "\n",
        "\n",
        "Nếu dữ liệu của bạn đã có cấu trúc chuẩn (các tin nhắn đã có khóa \"role\" và \"content\", với giá trị của \"role\" là \"system\", \"user\", \"assistant\"), thì hàm `standardize_data_formats` vẫn sẽ thực hiện các bước kiểm tra và ánh xạ như bình thường. Cụ thể:\n",
        "\n",
        "- Hàm sẽ duyệt qua một số mẫu từ trường `conversations` và lấy ra các khóa của từng tin nhắn.  \n",
        "- Nó sẽ nhận thấy rằng có đúng 2 khóa (giả sử là `\"role\"` và `\"content\"`).  \n",
        "- Sau đó, dựa vào số lượng giá trị duy nhất, nó sẽ xác định khóa nào là vai trò (role) và khóa nào là nội dung (content).  \n",
        "- Tiếp theo, nó sẽ kiểm tra các giá trị của khóa vai trò có nằm trong tập các alias đã định nghĩa hay không. Nếu dữ liệu của bạn đã chuẩn thì các giá trị này đã là `\"system\"`, `\"user\"` hoặc `\"assistant\"` nên sẽ khớp với alias đã được mapping.  \n",
        "- Cuối cùng, mỗi tin nhắn sẽ được xây dựng lại với định dạng: `{\"role\": <role chuẩn>, \"content\": <nội dung>}`. Nếu dữ liệu đã chuẩn, kết quả cuối cùng sẽ giống với dữ liệu ban đầu.\n",
        "\n",
        "Tóm lại, nếu dữ liệu của bạn đã chuẩn, hàm này sẽ không thay đổi nội dung, mà chỉ \"tái đóng gói\" dữ liệu theo đúng định dạng tiêu chuẩn của Hugging Face. Bạn có thể chạy hàm này mà không lo bị lỗi, nhưng về cơ bản nó sẽ không tạo ra sự khác biệt so với dữ liệu ban đầu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for item 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFzmplrEy9I",
        "outputId": "62352753-41b7-475d-d1b5-acd4162d6d5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': 'How do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?',\n",
              "  'role': 'user'},\n",
              " {'content': 'Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.',\n",
              "  'role': 'assistant'}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "dataset[5][\"conversations\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfzTdMtvGE6w"
      },
      "source": [
        "And we see how the chat template transformed these conversations.\n",
        "\n",
        "**[Notice]** Llama 3.1 Instruct's default chat template default adds `\"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\"`, so do not be alarmed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "vhXv0xFMGNKE",
        "outputId": "b3cdc285-3d88-4bf2-e239-05cefce083f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed_vNxySOA9Z"
      },
      "source": [
        "### ✅ Tóm tắt quá trình chuẩn hóa và định dạng dữ liệu với `standardize_sharegpt` + `formatting_prompts_func`\n",
        "\n",
        "1. **`standardize_sharegpt(dataset)`**  \n",
        "   → Chuyển dữ liệu về định dạng chuẩn kiểu ShareGPT:\n",
        "   - Mỗi tin nhắn có dạng `{\"from\": ..., \"value\": ...}`\n",
        "   - Chuyển `from = \"human\"` thành `\"user\"`, `\"gpt\"` thành `\"assistant\"` để đồng bộ vai trò.\n",
        "\n",
        "2. **`dataset.map(formatting_prompts_func, batched=True)`**  \n",
        "   → Duyệt từng hội thoại, áp dụng **chat template** để tạo chuỗi định dạng có token đặc biệt:\n",
        "   - Sinh ra trường `\"text\"` chứa nội dung đã được chèn các thẻ như:  \n",
        "     `<|begin_of_text|>`, `<|start_header_id|>user<|end_header_id|>`, `<|eot_id|>`, v.v.\n",
        "\n",
        "---\n",
        "\n",
        "👉 **Mục tiêu**:  \n",
        "Định dạng lại hội thoại sao cho mô hình dễ hiểu vai trò `system`, `user`, `assistant` và ngữ cảnh từng lượt nói.\n",
        "\n",
        "📌 **Kết quả**:  \n",
        "Dataset có thêm cột `\"text\"` → dùng để huấn luyện mô hình ngôn ngữ theo phong cách chat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVZKVOKpKbJf"
      },
      "source": [
        "## My Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from datasets import Dataset\n",
        "from unsloth.chat_templates import standardize_data_formats  # Hoặc hàm tương đương\n",
        "\n",
        "# Bước 1: Đọc file Excel\n",
        "# Giả sử file nằm tại \"/content/DataFineTunev1.1_conversations_format.xlsx\"\n",
        "df = pd.read_excel(\"/content/DataFineTunev1.2_conversations_format.xlsx\")\n",
        "\n",
        "# Kiểm tra nhanh 5 dòng đầu\n",
        "print(\"Dữ liệu gốc (5 dòng đầu):\")\n",
        "print(df.head())\n",
        "\n",
        "# Bước 2: Mỗi dòng trong df đã chứa một cuộc hội thoại ở dạng chuỗi JSON.\n",
        "# Ta cần chuyển cột `conversations` từ chuỗi JSON sang list[dict].\n",
        "\n",
        "all_data = []\n",
        "for idx, row in df.iterrows():\n",
        "    # row[\"conversations\"] là một chuỗi JSON,\n",
        "    # ví dụ: '[{\"role\": \"system\", \"content\": \"You are...\"}, {\"role\": \"user\", \"content\": \"Hello\"}, ...]'\n",
        "    conv_str = row[\"conversations\"]\n",
        "\n",
        "    # Kiểm tra chuỗi JSON có bị rỗng, None hoặc lỗi format không\n",
        "    if not isinstance(conv_str, str):\n",
        "        raise ValueError(f\"Hàng thứ {idx} không phải chuỗi JSON hợp lệ: {conv_str}\")\n",
        "\n",
        "    # Giải mã chuỗi JSON thành list[dict]\n",
        "    conv_list = json.loads(conv_str)\n",
        "\n",
        "    # Tạo dictionary có key \"conversations\" cho mỗi hàng\n",
        "    all_data.append({\"conversations\": conv_list})\n",
        "\n",
        "# Bước 3: Tạo Dataset của Hugging Face từ danh sách all_data\n",
        "my_dataset = Dataset.from_list(all_data)\n",
        "\n",
        "# Kiểm tra cấu trúc phần tử đầu tiên\n",
        "print(\"\\nPhần tử đầu tiên của my_dataset trước khi chuẩn hóa:\")\n",
        "print(my_dataset[0])\n",
        "\n",
        "# Bước 4: Chuẩn hóa dữ liệu (nếu cần) bằng hàm standardize_data_formats\n",
        "# - Hàm này sẽ đồng nhất role = system / user / assistant theo alias\n",
        "my_dataset = standardize_data_formats(my_dataset)\n",
        "\n",
        "# - Trong quá trình format, có thể `formatting_prompts_func` (hoặc một hàm template tương tự) chèn các token đặc biệt và các thẻ đánh dấu vai trò (system/user/assistant).\n",
        "# - Các thẻ này giúp mô hình (hoặc pipeline huấn luyện) phân biệt ranh giới từng vai trò trong hội thoại, cũng như hỗ trợ một số tính năng nội bộ (như “end of text”, “start header”, v.v.).\n",
        "# Tham số batched=True cho phép xử lý nhiều mẫu cùng lúc, giúp tăng hiệu quả khi áp dụng hàm\n",
        "my_dataset = my_dataset.map(formatting_prompts_func, batched=True,)\n",
        "\n",
        "# Kiểm tra sau chuẩn hóa\n",
        "print(\"\\nPhần tử đầu tiên sau khi chuẩn hóa:\")\n",
        "print(my_dataset[0])\n",
        "print(my_dataset[0][\"conversations\"])\n",
        "print(my_dataset[0][\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d7705bed644d4a77aaf0ad6e1e17570c",
            "41a0954e29ad42daafda3a834a2551b1",
            "7b6ad06aea44487b9d2176a887baadff",
            "425c6125d47c4c88bfd86b4de2714ef2",
            "15f352652452421fafb6f2e0577ebd6c",
            "3b2ba60ef3374bb5989d5d80c2a826a1",
            "9b678ab529694b68b33ad6bc5f141265",
            "53f83196081c40969af282970daba8fe",
            "3bf5456dfa9147f39d54e4b8f2c67432",
            "09d4c15ed6c7444b95a26c25ff839dc1",
            "bd8d1470b2344265b325af62b14a0f79",
            "1cf30525c0754eae87e4709a81aa6aa7",
            "b63225519d844022b0af5945bcbef227",
            "5d9c350a36d8487db17079e897cbd00c",
            "7495b9b355fe45d99e8e5dcf061049f4",
            "5236e1b8c8344962ab8103af711a7135",
            "ee4a906ab7e64bdda022d57b424ba822",
            "8ab6358233e440c28d3f2e0a0effad2f",
            "4a03e363beab466b812f811752f067c6",
            "e17e91216cd7433a8136c6692d2fd14c",
            "4efdc30bd6954551ac2c1006c9545f3d",
            "4e89c96ec0204dd380974ce0c566a03c"
          ]
        },
        "id": "dCOl1LRm4akb",
        "outputId": "97c5f2f8-334f-4d16-ec35-70265bad047b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dữ liệu gốc (5 dòng đầu):\n",
            "                                       conversations\n",
            "0  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "1  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "2  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "3  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "4  [{   \"role\": \"system\",   \"content\": \"You are a...\n",
            "\n",
            "Phần tử đầu tiên của my_dataset trước khi chuẩn hóa:\n",
            "{'conversations': [{'content': 'You are an intelligent task classification and response generation assistant.\\nYour job is to analyze user commands and generate structured JSON responses according to the correct task category.\\n\\nYou will be given a User Input – a natural language command from the user.\\n\\nYour task is to:\\n1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\\n- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\\n2. Determine the appropriate action based on user intent:\\n   - \"todo\" → [create, get_all, update, delete, complete]\\n   - \"todo_with_calendar\" → [create, get_upcoming, get_past, get_now, update, delete, invite]\\n   - \"email\" → [compose, get_inbox, reply, save_draft, delete, mark_important]\\n   - \"article\" → [create, get_all, get_published, update, delete, publish, save_draft]\\n   - \"thutuchanhchinh\" → [lookup_inf]\\n\\n3. Extract any relevant summary_task and event_time.\\n\\nRespond ONLY with a valid JSON object following this exact template:\\n{\\n  \"tool\": \"<tool>\",\\n  \"action\": \"<action>\",\\n  \"details\": {\\n    \"summary_task\": \"<summary>\",\\n    \"event_time\": \"<time or null>\"\\n  }\\n}\\n\\nDO NOT explain. DO NOT include markdown. DO NOT add extra text.', 'role': 'system'}, {'content': 'Tiếp tục học tiếng anh', 'role': 'user'}, {'content': '\\n{\\n  \"tool\": \"todo\",\\n  \"action\": \"create\",\\n  \"details\": {\\n    \"summary_task\": \"Tiếp tục học tiếng Anh\",\\n    \"event_time\": null\\n  }\\n}\\n', 'role': 'assistant'}]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Standardizing formats (num_proc=2):   0%|          | 0/3892 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7705bed644d4a77aaf0ad6e1e17570c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3892 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cf30525c0754eae87e4709a81aa6aa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Phần tử đầu tiên sau khi chuẩn hóa:\n",
            "{'conversations': [{'content': 'You are an intelligent task classification and response generation assistant.\\nYour job is to analyze user commands and generate structured JSON responses according to the correct task category.\\n\\nYou will be given a User Input – a natural language command from the user.\\n\\nYour task is to:\\n1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\\n- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\\n2. Determine the appropriate action based on user intent:\\n   - \"todo\" → [create, get_all, update, delete, complete]\\n   - \"todo_with_calendar\" → [create, get_upcoming, get_past, get_now, update, delete, invite]\\n   - \"email\" → [compose, get_inbox, reply, save_draft, delete, mark_important]\\n   - \"article\" → [create, get_all, get_published, update, delete, publish, save_draft]\\n   - \"thutuchanhchinh\" → [lookup_inf]\\n\\n3. Extract any relevant summary_task and event_time.\\n\\nRespond ONLY with a valid JSON object following this exact template:\\n{\\n  \"tool\": \"<tool>\",\\n  \"action\": \"<action>\",\\n  \"details\": {\\n    \"summary_task\": \"<summary>\",\\n    \"event_time\": \"<time or null>\"\\n  }\\n}\\n\\nDO NOT explain. DO NOT include markdown. DO NOT add extra text.', 'role': 'system'}, {'content': 'Tiếp tục học tiếng anh', 'role': 'user'}, {'content': '\\n{\\n  \"tool\": \"todo\",\\n  \"action\": \"create\",\\n  \"details\": {\\n    \"summary_task\": \"Tiếp tục học tiếng Anh\",\\n    \"event_time\": null\\n  }\\n}\\n', 'role': 'assistant'}], 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\nYou are an intelligent task classification and response generation assistant.\\nYour job is to analyze user commands and generate structured JSON responses according to the correct task category.\\n\\nYou will be given a User Input – a natural language command from the user.\\n\\nYour task is to:\\n1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\\n- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\\n2. Determine the appropriate action based on user intent:\\n   - \"todo\" → [create, get_all, update, delete, complete]\\n   - \"todo_with_calendar\" → [create, get_upcoming, get_past, get_now, update, delete, invite]\\n   - \"email\" → [compose, get_inbox, reply, save_draft, delete, mark_important]\\n   - \"article\" → [create, get_all, get_published, update, delete, publish, save_draft]\\n   - \"thutuchanhchinh\" → [lookup_inf]\\n\\n3. Extract any relevant summary_task and event_time.\\n\\nRespond ONLY with a valid JSON object following this exact template:\\n{\\n  \"tool\": \"<tool>\",\\n  \"action\": \"<action>\",\\n  \"details\": {\\n    \"summary_task\": \"<summary>\",\\n    \"event_time\": \"<time or null>\"\\n  }\\n}\\n\\nDO NOT explain. DO NOT include markdown. DO NOT add extra text.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTiếp tục học tiếng anh<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\\n{\\n  \"tool\": \"todo\",\\n  \"action\": \"create\",\\n  \"details\": {\\n    \"summary_task\": \"Tiếp tục học tiếng Anh\",\\n    \"event_time\": null\\n  }\\n}\\n<|eot_id|>'}\n",
            "[{'content': 'You are an intelligent task classification and response generation assistant.\\nYour job is to analyze user commands and generate structured JSON responses according to the correct task category.\\n\\nYou will be given a User Input – a natural language command from the user.\\n\\nYour task is to:\\n1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\\n- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\\n2. Determine the appropriate action based on user intent:\\n   - \"todo\" → [create, get_all, update, delete, complete]\\n   - \"todo_with_calendar\" → [create, get_upcoming, get_past, get_now, update, delete, invite]\\n   - \"email\" → [compose, get_inbox, reply, save_draft, delete, mark_important]\\n   - \"article\" → [create, get_all, get_published, update, delete, publish, save_draft]\\n   - \"thutuchanhchinh\" → [lookup_inf]\\n\\n3. Extract any relevant summary_task and event_time.\\n\\nRespond ONLY with a valid JSON object following this exact template:\\n{\\n  \"tool\": \"<tool>\",\\n  \"action\": \"<action>\",\\n  \"details\": {\\n    \"summary_task\": \"<summary>\",\\n    \"event_time\": \"<time or null>\"\\n  }\\n}\\n\\nDO NOT explain. DO NOT include markdown. DO NOT add extra text.', 'role': 'system'}, {'content': 'Tiếp tục học tiếng anh', 'role': 'user'}, {'content': '\\n{\\n  \"tool\": \"todo\",\\n  \"action\": \"create\",\\n  \"details\": {\\n    \"summary_task\": \"Tiếp tục học tiếng Anh\",\\n    \"event_time\": null\\n  }\\n}\\n', 'role': 'assistant'}]\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an intelligent task classification and response generation assistant.\n",
            "Your job is to analyze user commands and generate structured JSON responses according to the correct task category.\n",
            "\n",
            "You will be given a User Input – a natural language command from the user.\n",
            "\n",
            "Your task is to:\n",
            "1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\n",
            "- `\"thutuchanhchinh\"`: For legal and administrative procedure queries.\n",
            "2. Determine the appropriate action based on user intent:\n",
            "   - \"todo\" → [create, get_all, update, delete, complete]\n",
            "   - \"todo_with_calendar\" → [create, get_upcoming, get_past, get_now, update, delete, invite]\n",
            "   - \"email\" → [compose, get_inbox, reply, save_draft, delete, mark_important]\n",
            "   - \"article\" → [create, get_all, get_published, update, delete, publish, save_draft]\n",
            "   - \"thutuchanhchinh\" → [lookup_inf]\n",
            "\n",
            "3. Extract any relevant summary_task and event_time.\n",
            "\n",
            "Respond ONLY with a valid JSON object following this exact template:\n",
            "{\n",
            "  \"tool\": \"<tool>\",\n",
            "  \"action\": \"<action>\",\n",
            "  \"details\": {\n",
            "    \"summary_task\": \"<summary>\",\n",
            "    \"event_time\": \"<time or null>\"\n",
            "  }\n",
            "}\n",
            "\n",
            "DO NOT explain. DO NOT include markdown. DO NOT add extra text.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Tiếp tục học tiếng anh<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "\n",
            "{\n",
            "  \"tool\": \"todo\",\n",
            "  \"action\": \"create\",\n",
            "  \"details\": {\n",
            "    \"summary_task\": \"Tiếp tục học tiếng Anh\",\n",
            "    \"event_time\": null\n",
            "  }\n",
            "}\n",
            "<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoainQgOPXyZ"
      },
      "source": [
        "Nội dung hiển thị cho ta thấy rõ cách thức dữ liệu đang được “đóng gói” và “định dạng” sau khi sử dụng các hàm chuẩn hóa từ thư viện `unsloth`. Cụ thể:\n",
        "\n",
        "1. **Có trường** `\"conversations\"` **lưu danh sách tin nhắn**  \n",
        "   Mỗi tin nhắn là một dictionary gồm:\n",
        "   - `\"role\"`: xác định người gửi là `system`, `user`, hay `assistant`.\n",
        "   - `\"content\"`: nội dung văn bản thực tế.\n",
        "\n",
        "2. **Xuất hiện trường** `\"text\"` **chứa nội dung đã được thêm các token đặc biệt**  \n",
        "   Trong đó gồm những token như:\n",
        "   - `\"<|begin_of_text|>\"` và `\"<|eot_id|>\"` để đánh dấu bắt đầu/kết thúc nội dung.  \n",
        "   - `\"<|start_header_id|>system<|end_header_id|>\"`, `\"<|start_header_id|>user<|end_header_id|>\"`, `\"<|start_header_id|>assistant<|end_header_id|>\"` để biểu diễn vai trò.  \n",
        "   - Các dòng “Cutting Knowledge Date: …” và “Today Date: …” cho thấy mô phỏng ngữ cảnh hoặc metadata về ngày tháng (nếu có).  \n",
        "\n",
        "3. **Cấu trúc text**  \n",
        "   Text này trộn cả nội dung thực tế (ví dụ “You are an intelligent …,” “Tiếp tục học tiếng anh,” …) với các đoạn đánh dấu (token đặc biệt), nhờ đó mô hình huấn luyện hoặc mô hình inference có thể phân biệt ranh giới giữa các vai trò, hoặc nhận biết các siêu thông tin khác.\n",
        "\n",
        "4. **Nhận xét tổng quan**  \n",
        "   - Dữ liệu ở dạng `\"conversations\"` + `\"text\"` này rất hữu ích để **huấn luyện mô hình** theo kịch bản hội thoại (chat-based).  \n",
        "   - Phần `\"text\"` được “render” dựa trên template, giúp **đồng nhất** việc cung cấp ngữ cảnh, role, và nội dung cho mô hình.  \n",
        "   - Nếu bạn không muốn các token đặc biệt (như `\"<|begin_of_text|>\"`…), bạn có thể tùy biến lại phần template.  \n",
        "   - Ngược lại, nếu bạn cần mô hình hiểu được ngữ cảnh “system” / “user” / “assistant” tách biệt, thì cách tạo những token này là cần thiết.\n",
        "\n",
        "Như vậy, toàn bộ đoạn “text” này đơn giản là **sản phẩm** của quá trình chuyển đổi và định dạng nhằm phục vụ nhu cầu huấn luyện mô hình kiểu hội thoại."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrdefPpwRcLz"
      },
      "source": [
        "### ✅ Tóm tắt: **Token được tính từ đâu đến đâu?**\n",
        "\n",
        "- **Token được tính từ toàn bộ nội dung trong trường `\"text\"`**, sau khi áp dụng template ChatML.\n",
        "  \n",
        "- Bao gồm tất cả:\n",
        "  - `<|begin_of_text|>` – bắt đầu chuỗi\n",
        "  - `<|start_header_id|>system<|end_header_id|>` + nội dung system\n",
        "  - `<|start_header_id|>user<|end_header_id|>` + prompt người dùng\n",
        "  - `<|start_header_id|>assistant<|end_header_id|>` + câu trả lời\n",
        "  - `<|eot_id|>` – đánh dấu kết thúc mỗi phần\n",
        "\n",
        "- 👉 Vì prompt `\"system\"` của bạn rất dài, bạn nên **tăng `max_seq_length`** (nếu mô hình hỗ trợ), ví dụ:\n",
        "  - 1024 → có thể bị cắt\n",
        "  - 2048 hoặc 4096 → an toàn hơn\n",
        "\n",
        "- ✅ Bạn có thể dùng `tokenizer(text)` để đếm chính xác số token.\n",
        "\n",
        "---\n",
        "\n",
        "Nếu cần, mình có thể giúp bạn:  \n",
        "- Tính số token thật sự của từng mẫu  \n",
        "- Gợi ý rút gọn prompt `\"system\"`  \n",
        "- Tối ưu hóa cho LoRA hoặc cấu hình huấn luyện phù hợp hơn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ec56767edb4b4c599a0044b985c54bff",
            "97ae0fd3db434198892e1489428d0d72",
            "4da7a83b7a554e64b1d05565b8eb5921",
            "2e77aa4b2a054353b4b06f2c42a3afa0",
            "fdc06a0df66d42a8946c1fa92c84f2ef",
            "ae7646d9be27489bbe95fd9104bcaf46",
            "ff1275c77bb749a7b567bb458d3bb757",
            "351b9cf735964a7abe7c17272cd407a5",
            "0951d61c34544b00a4c08d591c00ff86",
            "c5eddb0136a2478fb5a1c897639a0a83",
            "e307f23140684317af950e255623ec49",
            "67faf64792d642008489c523d96c4eb8",
            "7fb5579de1624238b679cc2a570b2e35",
            "4298194ebcdc4978942c6921daef6ee1",
            "fc8e5d8aa6f9420b8be3587a23d4cf11",
            "2d8b4bedb98d4a3bbf1b81722a6e6913",
            "3fb477982dad4175a81b7642f13be6d5",
            "80ecdf89c9694122b4d9800c5379423c",
            "a9b4f4d935bf4fe4bac461ba690ee1b3",
            "100ab9c4651444cab459e6f1ce6d44ec",
            "93e14e92bb094504a2f08d3012ec1dd2",
            "b8a06888ef2d4bdaadf879ea2b42b6b6",
            "cac30dd0a2ea40bc942aecb35bc7b193",
            "38278c13d806430ea440b9dec597ffa0",
            "77a9b15551314a1aa532bc4552aeb944",
            "a673d03531c34bb29dc9f1de2ec077c3",
            "2e9eb62494dd4d52b3409d1f88d201e8",
            "467892f05d494b7c8451fdbb4007efaa",
            "08f085ed3c454ea1ab26097d0daafcf8",
            "9e84fd6504224c57849942ba4f9ef6cb",
            "1c6daad1e16e4c2e8c96742dca76c43c",
            "492cd90843c7464ba755c5b0cb113df1",
            "19564989d8644c7f86519fa6df478ac4"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "cf398a52-c6bc-4ecd-fd5e-a88fa8a59811"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying chat template to train dataset (num_proc=2):   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec56767edb4b4c599a0044b985c54bff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset (num_proc=2):   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67faf64792d642008489c523d96c4eb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset (num_proc=2):   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cac30dd0a2ea40bc942aecb35bc7b193"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# from trl import SFTTrainer\n",
        "# from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "# from unsloth import is_bfloat16_supported\n",
        "\n",
        "# trainer = SFTTrainer(\n",
        "#     model = model,\n",
        "#     tokenizer = tokenizer,\n",
        "#     train_dataset = dataset,\n",
        "#     dataset_text_field = \"text\",\n",
        "#     max_seq_length = max_seq_length,\n",
        "#     data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "#     dataset_num_proc = 2,\n",
        "#     packing = False, # Can make training 5x faster for short sequences.\n",
        "#     args = TrainingArguments(\n",
        "#         per_device_train_batch_size = 2,\n",
        "#         gradient_accumulation_steps = 4,\n",
        "#         warmup_steps = 5,\n",
        "#         # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "#         max_steps = 60,\n",
        "#         learning_rate = 2e-4,\n",
        "#         fp16 = not is_bfloat16_supported(),\n",
        "#         bf16 = is_bfloat16_supported(),\n",
        "#         logging_steps = 1,\n",
        "#         optim = \"adamw_8bit\",\n",
        "#         weight_decay = 0.01,\n",
        "#         lr_scheduler_type = \"linear\",\n",
        "#         seed = 3407,\n",
        "#         output_dir = \"outputs\",\n",
        "#         report_to = \"none\", # Use this for WandB etc\n",
        "#     ),\n",
        "# )\n",
        "\n",
        "\n",
        "# Import các hàm và lớp cần thiết\n",
        "# - SFTTrainer: Lớp huấn luyện mô hình kiểu \"Supervised Fine-Tuning\" (điều chỉnh có giám sát)\n",
        "# - TrainingArguments: Đối tượng cấu hình cho quá trình huấn luyện (ví dụ số bước, lr, v.v.)\n",
        "# - DataCollatorForSeq2Seq: Công cụ gom dữ liệu theo batch, phù hợp với mô hình dạng seq2seq\n",
        "# - is_bfloat16_supported: Hàm kiểm tra xem máy tính có hỗ trợ kiểu số bfloat16 không\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "# Khởi tạo đối tượng SFTTrainer để huấn luyện mô hình\n",
        "trainer = SFTTrainer(\n",
        "    model = model,                       # Mô hình (đã được nạp sẵn)\n",
        "    tokenizer = tokenizer,               # Tokenizer để biến văn bản thành số và ngược lại\n",
        "    train_dataset = dataset,             # Dữ liệu huấn luyện (dạng Dataset)\n",
        "    dataset_text_field = \"text\",         # Tên cột (field) chứa chuỗi văn bản trong dataset\n",
        "    max_seq_length = max_seq_length,     # Độ dài tối đa của mỗi chuỗi sau khi tokenizer\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    # DataCollatorForSeq2Seq giúp gom các mẫu theo batch, thêm mã hoá đặc biệt nếu cần\n",
        "\n",
        "    dataset_num_proc = 2,               # Số luồng CPU để xử lý dữ liệu song song\n",
        "    packing = False,                     # Có gộp (packing) các chuỗi ngắn lại hay không\n",
        "    # (tắt packing có thể huấn luyện chậm hơn, nhưng code dễ theo dõi hơn)\n",
        "\n",
        "    # Các tham số huấn luyện được đưa vào TrainingArguments\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2, # Mỗi thiết bị (GPU/CPU) sẽ lấy 2 mẫu cho mỗi batch\n",
        "        gradient_accumulation_steps = 4, # Tích lũy gradient 4 lần trước khi cập nhật mô hình\n",
        "        warmup_steps = 5,               # Số bước \"hâm nóng\" (warmup) trước khi vào giai đoạn chính\n",
        "        max_steps = 6000,                 # Huấn luyện tổng cộng 60 bước\n",
        "        learning_rate = 2e-4,           # Tốc độ học (learning rate) là 0.0002\n",
        "        fp16 = not is_bfloat16_supported(), # Nếu máy không hỗ trợ bfloat16 thì dùng fp16\n",
        "        bf16 = is_bfloat16_supported(), # Nếu máy hỗ trợ bfloat16 thì dùng bfloat16\n",
        "        logging_steps = 1,              # Cứ 1 bước thì in thông tin log (tiến trình) 1 lần\n",
        "        optim = \"adamw_8bit\",           # Sử dụng trình tối ưu AdamW, tính toán với số 8-bit để tiết kiệm bộ nhớ\n",
        "        weight_decay = 0.01,            # Hệ số trừng phạt độ lớn tham số (regularization)\n",
        "        lr_scheduler_type = \"linear\",   # Kiểu thay đổi learning rate (tuyến tính)\n",
        "        seed = 3407,                    # Hạt ngẫu nhiên (random seed) để kết quả lặp lại được\n",
        "        output_dir = \"outputs\",         # Thư mục để lưu kết quả và mô hình sau huấn luyện\n",
        "        report_to = \"none\",             # Chỗ báo cáo kết quả (none = không báo)\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsRDH37fQvIx"
      },
      "source": [
        "Đây là thông báo quá trình xử lý dữ liệu khi huấn luyện, mỗi dòng cho biết một bước và tiến độ thực hiện:\n",
        "\n",
        "1. **Converting train dataset to ChatML (num_proc=2): 100%**  \n",
        "   - Hệ thống đang **chuyển đổi** bộ dữ liệu huấn luyện (train dataset) sang **định dạng ChatML** (một định dạng đặc biệt để mô hình hiểu được hội thoại).  \n",
        "   - `num_proc=2` cho biết đang xử lý bằng 2 luồng (hoặc 2 tiến trình) song song.  \n",
        "   - Khi báo `100000/100000 [00:24<00:00, 1501.55 examples/s]` nghĩa là đã xử lý xong **100.000 mẫu** trong **24 giây**, tốc độ khoảng **1.501 mẫu/giây**.\n",
        "\n",
        "2. **Applying chat template to train dataset (num_proc=2): 100%**  \n",
        "   - Sau bước chuyển đổi sang ChatML, hệ thống **áp dụng một “chat template”** (một khuôn mẫu định dạng) cho dữ liệu.  \n",
        "   - Dữ liệu được duyệt qua và bổ sung các token đặc biệt (ví dụ: hiển thị user/assistant, cắt bớt, v.v.) theo template mà bạn đã cấu hình.  \n",
        "   - Tương tự, `100000/100000 [00:30<00:00, 4935.73 examples/s]` cho thấy đã xử lý xong 100.000 mẫu trong 30 giây, tốc độ gần 4.935 mẫu/giây.\n",
        "\n",
        "3. **Tokenizing train dataset (num_proc=2): 100%**  \n",
        "   - Đây là **bước biến đổi văn bản thành các token** – nghĩa là biến câu chữ thành các chỉ số (số nguyên) để mô hình hiểu được.  \n",
        "   - Với 100.000 mẫu, quá trình này mất khoảng 3 phút 31 giây (tốc độ ~503 mẫu/giây).\n",
        "\n",
        "4. **Truncating train dataset (num_proc=2): 100%**  \n",
        "   - Bước **truncating** (cắt ngắn) sẽ giới hạn độ dài mỗi mẫu (thường là theo `max_seq_length`) để tránh vượt quá mức cho phép của mô hình.  \n",
        "   - Thời gian thực hiện ngắn (chỉ 2 giây) do đây là thao tác cắt bỏ phần vượt quá. Tốc độ khá cao (~44.089 mẫu/giây).\n",
        "\n",
        "Tóm lại, các dòng log này cho thấy **bốn bước nối tiếp** trong việc chuẩn bị dữ liệu huấn luyện:  \n",
        "- Chuyển đổi sang ChatML,  \n",
        "- Áp dụng template hội thoại,  \n",
        "- Tokenize (mã hóa văn bản),  \n",
        "- Và cuối cùng là cắt ngắn dữ liệu vượt quá độ dài cho phép.  \n",
        "\n",
        "Mỗi bước có `num_proc=2` nghĩa là chia việc xử lý cho 2 tiến trình, tăng tốc độ so với việc chạy đơn luồng."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahxwh6_CRp7m"
      },
      "source": [
        "### ✅ Tóm tắt: **Token được tính từ đâu đến đâu?**\n",
        "\n",
        "- **Token được tính từ toàn bộ nội dung trong trường `\"text\"`**, sau khi áp dụng template ChatML.\n",
        "  \n",
        "- Bao gồm tất cả:\n",
        "  - `<|begin_of_text|>` – bắt đầu chuỗi\n",
        "  - `<|start_header_id|>system<|end_header_id|>` + nội dung system\n",
        "  - `<|start_header_id|>user<|end_header_id|>` + prompt người dùng\n",
        "  - `<|start_header_id|>assistant<|end_header_id|>` + câu trả lời\n",
        "  - `<|eot_id|>` – đánh dấu kết thúc mỗi phần\n",
        "\n",
        "- 👉 Vì prompt `\"system\"` của bạn rất dài, bạn nên **tăng `max_seq_length`** (nếu mô hình hỗ trợ), ví dụ:\n",
        "  - 1024 → có thể bị cắt\n",
        "  - 2048 hoặc 4096 → an toàn hơn\n",
        "\n",
        "- ✅ Bạn có thể dùng `tokenizer(text)` để đếm chính xác số token.\n",
        "\n",
        "---\n",
        "\n",
        "Nếu cần, mình có thể giúp bạn:  \n",
        "- Tính số token thật sự của từng mẫu  \n",
        "- Gợi ý rút gọn prompt `\"system\"`  \n",
        "- Tối ưu hóa cho LoRA hoặc cấu hình huấn luyện phù hợp hơn.\n",
        "\n",
        "---\n",
        "\n",
        "Đếm = tool: 608"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVuk-fowRumq",
        "outputId": "a078335e-3acd-448b-bd7b-55421e53f7a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng token: 381\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Giả sử bạn đã có tokenizer\n",
        "text = my_dataset[0][\"text\"]  # hoặc standardized_dataset[0][\"text\"]\n",
        "tokens = tokenizer(text, return_tensors=\"pt\")\n",
        "print(f\"Số lượng token: {len(tokens['input_ids'][0])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4a8823242d6a47a7909b4d3291917b38",
            "b434b28e356045b29dc98c521fd647f0",
            "35008b025f204e1e91ccfbec43dfd886",
            "ef6f7f9d2ddc418c957ba2fb3bb5acbf",
            "e7482c4693f7487e9ff219419ae3a214",
            "59cf3b986bf84d53a2d91a5c804ba0c9",
            "e7532d2e5a2d427facd93992358b78c6",
            "9da4d939c91c49d39c342b2e945476ab",
            "2637e470e04e499499693a95119e7ddd",
            "3c8bf3c4504d42f09e1d51226a0e0ead",
            "d5285a351f8c47969ebba552c71545d6"
          ]
        },
        "id": "juQiExuBG5Bt",
        "outputId": "5bc36d4c-216d-42d8-d903-d7c3ddb00600"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a8823242d6a47a7909b4d3291917b38"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "We verify masking is actually done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "LtsMVtlkUhja",
        "outputId": "0485879b-2cb6-46cc-ebd9-1d2892bd30ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "_rD6fl8EUxnG",
        "outputId": "660d3f77-dc62-43c9-952a-f7e9475d15b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                                  Astronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enWUM0jV-jV"
      },
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "c470732f-0b29-43cf-be38-0167eed00454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.741 GB.\n",
            "4.131 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "2fe422d6-e57d-4c8e-b59c-bee99df7c754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 100,000 | Num Epochs = 1 | Total steps = 6,000\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 11,272,192/1,000,000,000 (1.13% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  50/6000 02:06 < 4:21:21, 0.38 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.711500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.783800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.943900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.860300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.915400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.619100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.909300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.783100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.917100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.174100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.969500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.680300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.933000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.651200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.052200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.885500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.823800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.921200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.934600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.930900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.911200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.705000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.881000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.885400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.832400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.201800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.140400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.724700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.603200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.674700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.831900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.068400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.970700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.788200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.853300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.094500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.832600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.155900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.842100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.921800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.842300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.969700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.847500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.746300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WvsZ9ydUnTt"
      },
      "source": [
        "### ✅ Tóm tắt kết quả huấn luyện từ log Unsloth\n",
        "\n",
        "---\n",
        "\n",
        "#### 🚀 **Cấu hình huấn luyện:**\n",
        "- **Tổng số mẫu:** 100,000  \n",
        "- **Số epoch:** 1  \n",
        "- **Số bước huấn luyện (steps):** 60  \n",
        "- **Batch size:**  \n",
        "  - Mỗi thiết bị: 2  \n",
        "  - `gradient_accumulation_steps = 4`  \n",
        "  - Tổng batch size: `2 x 4 x 1 GPU = 8`  \n",
        "- **Số tham số được huấn luyện:** 24.3 triệu / 3 tỷ (~0.81%) → đang dùng **LoRA hoặc partial fine-tuning**\n",
        "- ✅ **Tối ưu VRAM:** có offload gradients thông minh.\n",
        "\n",
        "---\n",
        "\n",
        "#### 📉 **Diễn biến Loss qua từng bước:**\n",
        "- Loss dao động từ khoảng **0.45 đến 1.3**, trung bình ~**0.8–0.9**\n",
        "- Có vài bước loss cao đột biến (ví dụ bước 53: **1.3178**), nhưng phần lớn giữ ở mức ổn định.\n",
        "- Một số bước có loss thấp rõ rệt (ví dụ bước 51: **0.4573**, bước 34: **0.5803**) → mô hình có thể học tốt trên các mẫu đó.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🔍 **Đánh giá nhanh:**\n",
        "- Với chỉ **60 bước training**, đây là giai đoạn **warmup hoặc thử nghiệm nhanh**, không đại diện cho training dài hạn.\n",
        "- Mức loss tương đối ổn định, không tăng liên tục ⇒ **mô hình đang học được**.\n",
        "- Bạn có thể:\n",
        "  - ✅ Dùng checkpoint này để **inference thử**.\n",
        "  - 🔁 Tăng số bước (hoặc epoch) nếu muốn huấn luyện thực sự nghiêm túc.\n",
        "  - 📉 Theo dõi thêm `eval loss` (nếu có tập validation) để đánh giá overfitting.\n",
        "\n",
        "---\n",
        "\n",
        "Nếu bạn muốn mình:\n",
        "- Vẽ biểu đồ Loss  \n",
        "- Gợi ý cách đánh giá output sau huấn luyện  \n",
        "- Gợi ý checkpoint saving, inference hoặc tiếp tục training  \n",
        "\n",
        "👉 cứ nói nhé!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCqnaKmlO1U9"
      },
      "outputs": [],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Unsloth_Studio.ipynb)**\n",
        "\n",
        "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR3gIAX-SM2q"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2pEuRb1r2Vg"
      },
      "outputs": [],
      "source": [
        "from transformers import TextStreamer\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "FastLanguageModel.for_inference(model)  # Bật chế độ suy luận nhanh\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"\n",
        "You are an intelligent task classification and response generation assistant.\n",
        "Your job is to analyze user commands and generate structured JSON responses according to the correct task category.\n",
        "\n",
        "You will be given a User Input – a natural language command from the user.\n",
        "\n",
        "Your task is to:\n",
        "1. Identify the correct tool: \"todo\", \"todo_with_calendar\", \"email\", \"article\", \"thutuchanhchinh\".\n",
        "2. Determine the appropriate action based on user intent:\n",
        "   - \"todo\" → [create, get_all, update, delete, complete]\n",
        "   - \"todo_with_calendar\" → [create, get_upcoming, get_past, get_now, update, delete, invite]\n",
        "   - \"email\" → [compose, get_inbox, reply, save_draft, delete, mark_important]\n",
        "   - \"article\" → [create, get_all, get_published, update, delete, publish, save_draft]\n",
        "   - \"thutuchanhchinh\" → [lookup_inf]\n",
        "\n",
        "3. Extract any relevant summary_task and event_time.\n",
        "\n",
        "Respond ONLY with a valid JSON object following this exact template:\n",
        "{\n",
        "  \"tool\": \"<tool>\",\n",
        "  \"action\": \"<action>\",\n",
        "  \"details\": {\n",
        "    \"summary_task\": \"<summary>\",\n",
        "    \"event_time\": \"<time or null>\"\n",
        "  }\n",
        "}\n",
        "\n",
        "DO NOT explain. DO NOT include markdown. DO NOT add extra text.\n",
        "\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Gặp đối tác chiến lược để kể về cuộc hành trình 15 ngày\"\n",
        "    }\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "_ = model.generate(\n",
        "    input_ids=inputs,\n",
        "    streamer=text_streamer,\n",
        "    max_new_tokens=128,\n",
        "    use_cache=True,\n",
        "    temperature=1.5,\n",
        "    min_p=0.1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_0ByZfaZUyg"
      },
      "source": [
        "1 prompt được GPT đề xuất để chống việc gen thừa. Ngon phết. (trong khi prompt cũ của mình bị gen thừa nhiều)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiJcmMC7VfUA"
      },
      "source": [
        "Bạn vừa đưa ra hai đoạn code sử dụng mô hình ngôn ngữ (có vẻ là LLaMA 3.1 qua Unsloth) để **sinh văn bản (generate)** dựa trên input người dùng. Cả hai đoạn đều đúng, và dùng trong các tình huống hơi khác nhau. Mình sẽ **giải thích ngắn gọn** sự khác biệt và ý nghĩa từng đoạn:\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Đoạn 1 – **Sinh văn bản và lấy kết quả về để xử lý**\n",
        "```python\n",
        "outputs = model.generate(\n",
        "    input_ids = inputs,\n",
        "    max_new_tokens = 64,\n",
        "    use_cache = True,\n",
        "    temperature = 1.5,\n",
        "    min_p = 0.1\n",
        ")\n",
        "\n",
        "tokenizer.batch_decode(outputs)\n",
        "```\n",
        "\n",
        "- ✅ Dùng `model.generate(...)` để mô hình sinh ra token mới.\n",
        "- ✅ Sau đó dùng `tokenizer.batch_decode(outputs)` để chuyển token thành chuỗi văn bản (string).\n",
        "- 👉 Dạng này dùng khi bạn **muốn lấy kết quả ra để lưu, phân tích, đánh giá tự động, hoặc hiển thị sau**.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Đoạn 2 – **Sinh văn bản trực tiếp ra màn hình (streaming)**\n",
        "```python\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "\n",
        "_ = model.generate(\n",
        "    input_ids = inputs,\n",
        "    streamer = text_streamer,\n",
        "    max_new_tokens = 128,\n",
        "    use_cache = True,\n",
        "    temperature = 1.5,\n",
        "    min_p = 0.1\n",
        ")\n",
        "```\n",
        "\n",
        "- ✅ Dùng `TextStreamer` để **hiển thị output theo thời gian thực**, giống như chatbot đang \"gõ chữ\".\n",
        "- `skip_prompt=True`: chỉ hiển thị phần mô hình sinh ra, không in lại prompt.\n",
        "- 👉 Dạng này dùng khi bạn muốn **xem kết quả ngay lập tức** (live demo, chatbot, giao diện người dùng…).\n",
        "\n",
        "---\n",
        "\n",
        "### 🔁 Điểm chung:\n",
        "- Cả hai đoạn đều:\n",
        "  - Dùng template chuẩn từ `get_chat_template`.\n",
        "  - Có `add_generation_prompt=True` để mô hình biết nên bắt đầu sinh tiếp.\n",
        "  - Chuyển `inputs` sang `cuda` để chạy bằng GPU.\n",
        "\n",
        "---\n",
        "\n",
        "### ❓Nên dùng đoạn nào?\n",
        "\n",
        "| Mục đích                        | Nên dùng đoạn |\n",
        "|-------------------------------|---------------|\n",
        "| Lưu kết quả, xử lý hàng loạt   | Đoạn 1        |\n",
        "| Hiển thị trực tiếp như chat   | Đoạn 2        |\n",
        "| Chạy trong notebook            | Cả hai đều ổn |\n",
        "| Giao diện chatbot              | Đoạn 2        |\n",
        "\n",
        "---\n",
        "\n",
        "Nếu bạn cần demo tương tác nhiều lượt, streaming tiếng Việt đẹp hơn, hoặc nối tiếp hội thoại thì mình có thể giúp bạn mở rộng đoạn code nhé!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVE MODEL"
      ],
      "metadata": {
        "id": "v0yjIp1q5fmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sau khi bạn **fine-tuning xong mô hình với Unsloth**, có **2 cách chính để lưu và inference (dự đoán)**:\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 1. **Lưu mô hình sau khi huấn luyện**\n",
        "\n",
        "Unsloth sử dụng LoRA → nên chỉ cần **lưu các adapter** (không cần lưu toàn bộ mô hình gốc)\n",
        "\n",
        "### 🔹 Lưu local:\n",
        "```python\n",
        "model.save_pretrained(\"lora_model\")         # Lưu adapter LoRA\n",
        "tokenizer.save_pretrained(\"lora_model\")     # Lưu tokenizer\n",
        "```\n",
        "\n",
        "📁 Sau đó bạn sẽ có thư mục `lora_model/` chứa:\n",
        "- `adapter_config.json`\n",
        "- `adapter_model.bin`\n",
        "- `tokenizer_config.json` + các file tokenizer khác\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 Hoặc đẩy lên Hugging Face Hub:\n",
        "```python\n",
        "model.push_to_hub(\"your_name/lora_model\", token = \"your_token\")\n",
        "tokenizer.push_to_hub(\"your_name/lora_model\", token = \"your_token\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 2. **Load lại và dùng để inference (dự đoán)**\n",
        "\n",
        "Sau khi đã lưu, bạn có thể **load lại mô hình** như sau:\n",
        "\n",
        "```python\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"lora_model\",              # đường dẫn thư mục đã lưu\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        "    load_in_4bit = True,\n",
        ")\n",
        "FastLanguageModel.for_inference(model)      # Kích hoạt chế độ sinh nhanh\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ➕ Inference:\n",
        "\n",
        "```python\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "from transformers import TextStreamer\n",
        "\n",
        "tokenizer = get_chat_template(tokenizer, chat_template=\"llama-3.1\")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Lập giúp tôi thời khoá biểu học tập\"}\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=True,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
        "\n",
        "_ = model.generate(\n",
        "    input_ids=inputs,\n",
        "    streamer=streamer,\n",
        "    max_new_tokens=128,\n",
        "    temperature=1.5,\n",
        "    min_p=0.1\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 3. **(Tuỳ chọn) Lưu mô hình sang định dạng khác để dùng ở nơi khác**\n",
        "\n",
        "### 🔹 Merge thành mô hình float16 (cho vllm, TGI, triton…)\n",
        "```python\n",
        "model.save_pretrained_merged(\"model_fp16\", tokenizer, save_method = \"merged_16bit\")\n",
        "```\n",
        "\n",
        "### 🔹 Merge thành mô hình int4 (nhẹ, tiết kiệm RAM)\n",
        "```python\n",
        "model.save_pretrained_merged(\"model_4bit\", tokenizer, save_method = \"merged_4bit\")\n",
        "```\n",
        "\n",
        "### 🔹 Export sang GGUF (dùng cho Ollama, llama.cpp, Jan, OpenWebUI…)\n",
        "```python\n",
        "model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 4. Tổng kết: Cách chọn\n",
        "\n",
        "| Mục đích                          | Dùng cách nào                               |\n",
        "|----------------------------------|---------------------------------------------|\n",
        "| Tiếp tục fine-tune               | Lưu bằng `save_pretrained()`               |\n",
        "| Inference bằng Python/Colab      | Dùng `FastLanguageModel.from_pretrained()` |\n",
        "| Dùng mô hình ở Ollama, WebUI     | Dùng `save_pretrained_gguf()`              |\n",
        "| Đẩy lên Hugging Face             | Dùng `push_to_hub()` hoặc `push_to_hub_gguf()` |\n",
        "| Triển khai ở production          | Dùng `merged_16bit` hoặc `gguf`            |\n",
        "\n",
        "---\n",
        "\n",
        "Nếu bạn muốn mình:\n",
        "- ✅ Gợi ý format file inference mẫu\n",
        "- ✅ Viết đoạn code inference cụ thể cho Hugging Face, Gradio, LangChain, Ollama\n",
        "- ✅ Export sang GGUF để dùng với chatbot UI\n",
        "\n",
        "👉 Cứ bảo mình nhé!"
      ],
      "metadata": {
        "id": "SyeHMCR05Y_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)"
      ],
      "metadata": {
        "id": "_2v6UM4_CR6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "c962e43a-2027-4a39-ea03-870b707a22d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "f22dbd75-ea37-48bb-9f75-4178aebe9353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Eiffel Tower, located in the heart of Paris, stands tall among the city's historic and cultural landmarks. This iron structure, standing at an impressive 324 meters high, offers breathtaking views of the City of Light's iconic landscape. The Eiffel Tower was built for the 1889 World's Fair and has since become a symbol of French engineering and culture.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Describe a tall tower in the capital of France.\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 📊 So sánh nhanh:\n",
        "\n",
        "| Save method     | Dùng được với vLLM | Dễ deploy | Nhẹ | Chứa base model |\n",
        "|-----------------|--------------------|-----------|------|------------------|\n",
        "| `merged_16bit`  | ✅                  | ✅         | ❌   | ✅               |\n",
        "| `merged_4bit`   | ⚠️ Có thể (tuỳ engine) | ✅     | ✅   | ✅               |\n",
        "| `lora`          | ❌ (cần merge lại)  | ❌         | ✅✅✅ | ❌               |\n",
        "\n",
        "---\n",
        "\n",
        "| Mục tiêu | Nên dùng |\n",
        "|----------|----------|\n",
        "| Deploy vLLM hoặc Ollama | `merged_16bit` ✅ |\n",
        "| Chia sẻ LoRA để người khác dùng với model gốc | `lora` ✅ |\n",
        "| Tối ưu RAM máy yếu | `merged_4bit` ✅ (nếu engine support) |\n",
        "\n"
      ],
      "metadata": {
        "id": "x_naIe97Dg5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Khi deploy thì merge base model của lora có khác gì với merged_16bit khi deploy không\n",
        "Hay là deploy thì nặng như nhau\n",
        "```"
      ],
      "metadata": {
        "id": "V1Ge0bLgCvvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Câu hỏi quá hay luôn Cường ơi! 😎 Đây là một **vấn đề quan trọng** mà nhiều anh em hay nhầm: **merge tại thời điểm deploy** (tức là dùng base model + adapter) **so với đã merge sẵn (`merged_16bit`)** — về bản chất thì giống nhau, nhưng **triển khai thực tế có khác biệt rõ ràng**. Mình phân tích nhé:\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Về bản chất khi inference:\n",
        "\n",
        "| So sánh                     | Merge Lúc Deploy (`base + lora`) | `merged_16bit` (đã merge sẵn) |\n",
        "|----------------------------|----------------------------------|-------------------------------|\n",
        "| **Thông tin mô hình**      | Base model + LoRA riêng biệt     | Mô hình đã ghép hoàn chỉnh    |\n",
        "| **Thông số cần dùng**      | Vẫn là full base + phần LoRA     | Chính là base + LoRA          |\n",
        "| **Dung lượng GPU dùng**    | ⚠️ Giống nhau (~full 16bit)      | ⚠️ Giống nhau (~full 16bit)   |\n",
        "| **Chất lượng kết quả**     | ✅ Giống nhau hoàn toàn           | ✅ Giống nhau                  |\n",
        "\n",
        "> 👉 Vì dù merge lúc deploy hay đã merge sẵn, **inference đều phải tải full model (bao gồm LoRA)** lên GPU để chạy.\n",
        "\n",
        "---\n",
        "\n",
        "## ❗Khác biệt khi **triển khai thực tế**:\n",
        "\n",
        "| Tiêu chí                        | Merge tại runtime (`base + LoRA`) | `merged_16bit` (đã merge)     |\n",
        "|--------------------------------|----------------------------------|-------------------------------|\n",
        "| **Số file phải load**          | 2 file (base + adapter)          | 1 file duy nhất               |\n",
        "| **Tốc độ khởi động**           | ⏳ Chậm hơn (phải merge tại runtime) | ⚡Nhanh hơn (chỉ load 1 model) |\n",
        "| **Tương thích vLLM / Triton**  | ❌ Không hỗ trợ trực tiếp         | ✅ Hỗ trợ tốt                  |\n",
        "| **Khả năng deploy quy mô lớn** | ❌ Khó scale (phải merge từng node) | ✅ Dễ dàng scale               |\n",
        "| **Yêu cầu về code**            | Cần thêm logic merge             | Đơn giản, chỉ load 1 model    |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Tóm lại:\n",
        "\n",
        "| Nếu bạn…                           | Thì dùng…            |\n",
        "|------------------------------------|----------------------|\n",
        "| 💻 Chạy local, thử nghiệm          | Base + LoRA (merge runtime) |\n",
        "| 🚀 Muốn deploy production (vLLM)   | `merged_16bit`       |\n",
        "| ☁️ Muốn upload Hugging Face        | `merged_16bit` hoặc `lora` tuỳ mục đích |\n",
        "| 🧪 Làm benchmark model sau train   | `merged_16bit`       |\n",
        "\n",
        "---\n",
        "\n",
        "## 👑 Kết luận ngắn gọn:\n",
        "\n",
        "> ✅ **Deploy thì nặng như nhau (cùng tải full model)**  \n",
        "> ❗Nhưng **dùng `merged_16bit` tiện hơn, nhanh hơn, dễ tích hợp hơn** → Đây là **chuẩn khi deploy** cho vLLM, Triton, Ollama...\n",
        "\n"
      ],
      "metadata": {
        "id": "YVwy-QZzDABq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxR-VjyIDcfD"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ⭐️ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐️\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_zqo-uxgB9lZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy\n"
      ],
      "metadata": {
        "id": "2mTz_-1dODZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Em cảm ơn anh nhiều.\n",
        "---\n",
        "# BÀI EM ĐANG LÀM:\n",
        "- Em đang fine tune 1 con Llam3-3.2 - 1B/3B anh ạ.\n",
        "- Input là 1 câu của User. Output là dạng Routing 2 tầng: Tool - Action (1 tool có nhiều loại Action anh ạ).\n",
        "```\n",
        "{\n",
        "  \"tool\": \"todo\",\n",
        "  \"action\": \"get_all\",\n",
        "  \"details\": {\n",
        "    \"summary_task\": \"lấy toàn bộ danh sách công việc đã note\",\n",
        "    \"event_time\": null\n",
        "  }\n",
        "}\n",
        "```\n",
        "- Con 1B run colab tầm 1-2s, con 3B thì 4-5s. Con 3B 1 epoch - 60 step - data khoảng 1500 dòng đã quá ngon rồi. Con 1B mà 1 epoch thì chưa ăn thua gì anh ạ.\n",
        "\n",
        "=== ===============\n",
        "\n",
        "Câu hỏi về RESPONSE TIME:\n",
        "- Anh có hay làm con 1B, 3B không ạ. Khi deploy server thì response time vẫn sẽ ngang ngang trên colab anh nhỉ (ạ). GPU mạnh hơn thì response time có thể giảm.\n",
        "\n",
        "?\n",
        "\n",
        "\n",
        "1B tầm 1-2s anh ạ, GPU mạnh thì khả năng giảm\n",
        "3B tầm 4-5s\n",
        "---\n",
        " 1 Bert tầm 100-200ms, P95 tầm 200ms,\n",
        "Để em đo kỹ lại xem kết quả thế nào anh ạ."
      ],
      "metadata": {
        "id": "qiL2NVSVOEvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dưới đây là bảng so sánh thời gian phản hồi (response time) **khi deploy mô hình trên server**, với các loại GPU phổ biến (kèm theo vài gợi ý tối ưu):\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ **Bảng so sánh response time khi deploy (LLaMA 1B / 3B / BERT)**\n",
        "\n",
        "| Mô hình       | GPU         | Response Time (trung bình) | P95 (ms) | Tối ưu khả dụng                   | Ghi chú thêm                              |\n",
        "|---------------|-------------|-----------------------------|----------|-----------------------------------|-------------------------------------------|\n",
        "| **BERT-base** | T4 / A10     | ~100-200ms                  | ~200ms   | Không cần cache, batch tốt        | Dùng nhiều trong classification nhanh     |\n",
        "| **LLaMA 1B**  | T4          | ~1.8s                       | ~2.5s    | `use_cache=True`, template nhẹ    | Nếu prompt dài, thời gian tăng mạnh       |\n",
        "| **LLaMA 1B**  | A10 / L4     | ~1.2s                       | ~1.6s    | Cắt bớt `system`, streaming JSON  | Đạt P95 < 2s nếu prompt ≤ 400 tokens      |\n",
        "| **LLaMA 3B**  | T4          | ~4–5s                       | ~6s      | Khó tối ưu nếu system dài         | Prefill (system) là bottleneck            |\n",
        "| **LLaMA 3B**  | A100        | ~1.8–2.5s                   | ~3.5s    | vLLM, cache KV, batch tốt         | Tốc độ tăng x2-x3 so với T4               |\n",
        "| **LLaMA 3B**  | vLLM + A10  | ~1.2–2s                     | ~2.5s    | vLLM hiệu quả với JSON short gen  | Nên dùng cho production hoặc chatbot task |\n",
        "\n",
        "---\n",
        "\n",
        "### 🔧 **Tối ưu inference khi deploy:**\n",
        "\n",
        "| Kỹ thuật                | Hiệu quả | Mô tả ngắn                                                                 |\n",
        "|-------------------------|----------|----------------------------------------------------------------------------|\n",
        "| **vLLM**                | ⭐⭐⭐⭐     | Prefill/decode song song, reuse KV cache, cực nhanh                       |\n",
        "| **Merge LoRA 16bit**    | ⭐⭐⭐      | Đẩy inference tốc độ như base model (không cần adapter)                   |\n",
        "| **System prompt ngắn**  | ⭐⭐⭐⭐     | Giảm token input → giảm thời gian prefill (rất quan trọng với LLaMA)      |\n",
        "| **Streaming (`TextStreamer`)** | ⭐⭐ | Có cảm giác nhanh hơn, mặc dù tổng thời gian vẫn vậy                      |\n",
        "| **Batch nhỏ (batch=1)** | ⭐⭐       | Giảm latency (dùng trong chatbot real-time)                               |\n",
        "| **Model nhỏ hơn (1B)**  | ⭐⭐⭐      | Trade-off giữa tốc độ & độ chính xác                                     |\n",
        "| **GGUF + llama.cpp**    | ⭐⭐       | Nhanh trên CPU, thích hợp nếu không có GPU hoặc RAM nhiều                 |\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 Gợi ý cho Quốc:\n",
        "- Nếu muốn deploy mô hình gen JSON routing như em đang làm:\n",
        "  - 👉 Dùng **vLLM + merge_16bit**, rất phù hợp task short-form gen.\n",
        "  - 👉 Để inference nhanh (P95 < 2s), ưu tiên A10 hoặc A100.\n",
        "  - 👉 Nếu dùng `llama.cpp` (GGUF), thì target P95 khoảng ~3–4s (trên CPU ngon).\n",
        "\n",
        "---\n",
        "\n",
        "Cần anh hỗ trợ dựng backend FastAPI + vLLM mẫu cho task này thì bảo anh nhé, anh có template gọn đẹp chuẩn JSON streaming sẵn 😎"
      ],
      "metadata": {
        "id": "4a-FS4nZOu_z"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "798cca80f27f4e76a84a5e4722fca4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e62a9675952b487bb1144a6faa834c14",
              "IPY_MODEL_47fd4cd89df94138880ad1e59a70bd11",
              "IPY_MODEL_66867dd10cde4f51ae7c106ebc914758"
            ],
            "layout": "IPY_MODEL_892787c5662c4466a04ccb2a62a49d16"
          }
        },
        "e62a9675952b487bb1144a6faa834c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_007c75fd113d45519aca4f744c2a9941",
            "placeholder": "​",
            "style": "IPY_MODEL_e8d246d539e24b2c88eb5a93d930b4b4",
            "value": "model.safetensors: 100%"
          }
        },
        "47fd4cd89df94138880ad1e59a70bd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb570fe4f204d44af55665dfbe56db0",
            "max": 1102370060,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4708411d0d274b8e91982b19708e2cc3",
            "value": 1102369955
          }
        },
        "66867dd10cde4f51ae7c106ebc914758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f0fd1fbe6da493f82812f0f6670d8d0",
            "placeholder": "​",
            "style": "IPY_MODEL_2ef7b44f2ee9485b8765f59f5feddf16",
            "value": " 1.10G/1.10G [00:13&lt;00:00, 493MB/s]"
          }
        },
        "892787c5662c4466a04ccb2a62a49d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "007c75fd113d45519aca4f744c2a9941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d246d539e24b2c88eb5a93d930b4b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fb570fe4f204d44af55665dfbe56db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4708411d0d274b8e91982b19708e2cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f0fd1fbe6da493f82812f0f6670d8d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef7b44f2ee9485b8765f59f5feddf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e49529f1a124498be682c72bb8c4e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_831583833d3749b8849ba7aee9e58715",
              "IPY_MODEL_d4d37043532c43609a8cbf2364000e31",
              "IPY_MODEL_f688d367e1c64eafa930af4cc66a6c54"
            ],
            "layout": "IPY_MODEL_55bc4ab554a542d5908886ad5b98a449"
          }
        },
        "831583833d3749b8849ba7aee9e58715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_026ca58c2a54473bb3f939310566afb1",
            "placeholder": "​",
            "style": "IPY_MODEL_33358b3d957b4c1dbacd9ce07a8339a3",
            "value": "generation_config.json: 100%"
          }
        },
        "d4d37043532c43609a8cbf2364000e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a53869e54a094f16978d0c67281c96c8",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5070622f631c4916b95c47e99474bd45",
            "value": 234
          }
        },
        "f688d367e1c64eafa930af4cc66a6c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_118fa571fc0a4696b1dd9a84a3ea74ae",
            "placeholder": "​",
            "style": "IPY_MODEL_6ee6a5287a4e4e9b8fdc97be297480bb",
            "value": " 234/234 [00:00&lt;00:00, 25.6kB/s]"
          }
        },
        "55bc4ab554a542d5908886ad5b98a449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "026ca58c2a54473bb3f939310566afb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33358b3d957b4c1dbacd9ce07a8339a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a53869e54a094f16978d0c67281c96c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5070622f631c4916b95c47e99474bd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "118fa571fc0a4696b1dd9a84a3ea74ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ee6a5287a4e4e9b8fdc97be297480bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3f4cf774da24ca6bede3c2c21922583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0de8a5b172947348931367047429527",
              "IPY_MODEL_d497eb8cc7c34c359930b6f0dd1fc9af",
              "IPY_MODEL_6f0e94a109ad4058be2a5f58e817a150"
            ],
            "layout": "IPY_MODEL_d327101e169441928a343fb90ea2cc54"
          }
        },
        "e0de8a5b172947348931367047429527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fa35136b1d349dda04c2111a728a3b4",
            "placeholder": "​",
            "style": "IPY_MODEL_c8afccc63aa741bdb73a70abdc8e05bc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d497eb8cc7c34c359930b6f0dd1fc9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63ec18ccc3264140bc170226ebd9fe82",
            "max": 54674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32e2f4111e514cc6b5666321d30b3a3e",
            "value": 54674
          }
        },
        "6f0e94a109ad4058be2a5f58e817a150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5654eaa262b54d9696fdaf4ab58eae92",
            "placeholder": "​",
            "style": "IPY_MODEL_c0aeb6d5f4f84de58c73ed237ae3ce82",
            "value": " 54.7k/54.7k [00:00&lt;00:00, 3.19MB/s]"
          }
        },
        "d327101e169441928a343fb90ea2cc54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fa35136b1d349dda04c2111a728a3b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8afccc63aa741bdb73a70abdc8e05bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63ec18ccc3264140bc170226ebd9fe82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e2f4111e514cc6b5666321d30b3a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5654eaa262b54d9696fdaf4ab58eae92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0aeb6d5f4f84de58c73ed237ae3ce82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5796e0df331646909b82aa18ec0b1bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31dba2047019487c85837310a02334f1",
              "IPY_MODEL_4bc5fe1bfc0742319554ede3a5c8cc3a",
              "IPY_MODEL_f7396523b90c43028e84edc4dbe5c4b3"
            ],
            "layout": "IPY_MODEL_dca07581328847d280595afe9ddada7c"
          }
        },
        "31dba2047019487c85837310a02334f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3e6cc9759e442381d02be513389542",
            "placeholder": "​",
            "style": "IPY_MODEL_95331b2a93bb4b128bcf6fc21d93520a",
            "value": "tokenizer.json: 100%"
          }
        },
        "4bc5fe1bfc0742319554ede3a5c8cc3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a038fe1a5f4c48e5b6c16102f57f3648",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d78442baa0f04d8080a53e3dcb067dc2",
            "value": 17209920
          }
        },
        "f7396523b90c43028e84edc4dbe5c4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49e5546522cb4a2b95f2eefa7592e41d",
            "placeholder": "​",
            "style": "IPY_MODEL_13d4cead911d4eefa8f1d53ea4214643",
            "value": " 17.2M/17.2M [00:00&lt;00:00, 65.1MB/s]"
          }
        },
        "dca07581328847d280595afe9ddada7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3e6cc9759e442381d02be513389542": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95331b2a93bb4b128bcf6fc21d93520a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a038fe1a5f4c48e5b6c16102f57f3648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d78442baa0f04d8080a53e3dcb067dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49e5546522cb4a2b95f2eefa7592e41d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13d4cead911d4eefa8f1d53ea4214643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d36f1825a3ae4ebcaae202f7d8c07059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4da22e2e64b446ea8b745e04596efe7",
              "IPY_MODEL_436e91f6210d4d1585afe914bbefcb54",
              "IPY_MODEL_8dbfdc4e23b449c683c29e60f13d926f"
            ],
            "layout": "IPY_MODEL_a45d461f178246508f4f2f5c62a9d029"
          }
        },
        "b4da22e2e64b446ea8b745e04596efe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b263d61463a94e22aa896a4960cabbf4",
            "placeholder": "​",
            "style": "IPY_MODEL_fa0ee322f0874cccb95de9d154824f4c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "436e91f6210d4d1585afe914bbefcb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13eb99a3ed8d4f95b3a4d4e9c5a9cce8",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e91cf7705864468caa557ae4db180f5a",
            "value": 454
          }
        },
        "8dbfdc4e23b449c683c29e60f13d926f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4659e671d8364964b2db9d10767bf3b8",
            "placeholder": "​",
            "style": "IPY_MODEL_29a599136d5d4dd1a9f7b5629742838a",
            "value": " 454/454 [00:00&lt;00:00, 51.7kB/s]"
          }
        },
        "a45d461f178246508f4f2f5c62a9d029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b263d61463a94e22aa896a4960cabbf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0ee322f0874cccb95de9d154824f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13eb99a3ed8d4f95b3a4d4e9c5a9cce8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e91cf7705864468caa557ae4db180f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4659e671d8364964b2db9d10767bf3b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a599136d5d4dd1a9f7b5629742838a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47475fb3e483454aa26b6d71516620b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3037c9a058a14b868e52e6bd9f25d823",
              "IPY_MODEL_0d170b66d0fe47e98a9220bf325d697a",
              "IPY_MODEL_5f0d75d525d341b5a21e2efab7aa179c"
            ],
            "layout": "IPY_MODEL_8f71ef527f914518ab536c5892a369b4"
          }
        },
        "3037c9a058a14b868e52e6bd9f25d823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad5c1e25ad784961a778e6e1591f5d99",
            "placeholder": "​",
            "style": "IPY_MODEL_601ceedefcb946209c6d6e5e3e5cde3d",
            "value": "Map: 100%"
          }
        },
        "0d170b66d0fe47e98a9220bf325d697a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b01ac32a5d1434a8c71be19b24d802b",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_320c2351438343009f434ff31c36cc59",
            "value": 100000
          }
        },
        "5f0d75d525d341b5a21e2efab7aa179c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd79c1e8e8074c29a39c73412cc3a9d9",
            "placeholder": "​",
            "style": "IPY_MODEL_839150163edb40c48f0fc359f662fe50",
            "value": " 100000/100000 [00:15&lt;00:00, 9291.77 examples/s]"
          }
        },
        "8f71ef527f914518ab536c5892a369b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad5c1e25ad784961a778e6e1591f5d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601ceedefcb946209c6d6e5e3e5cde3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b01ac32a5d1434a8c71be19b24d802b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "320c2351438343009f434ff31c36cc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd79c1e8e8074c29a39c73412cc3a9d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "839150163edb40c48f0fc359f662fe50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7705bed644d4a77aaf0ad6e1e17570c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41a0954e29ad42daafda3a834a2551b1",
              "IPY_MODEL_7b6ad06aea44487b9d2176a887baadff",
              "IPY_MODEL_425c6125d47c4c88bfd86b4de2714ef2"
            ],
            "layout": "IPY_MODEL_15f352652452421fafb6f2e0577ebd6c"
          }
        },
        "41a0954e29ad42daafda3a834a2551b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b2ba60ef3374bb5989d5d80c2a826a1",
            "placeholder": "​",
            "style": "IPY_MODEL_9b678ab529694b68b33ad6bc5f141265",
            "value": "Unsloth: Standardizing formats (num_proc=2): 100%"
          }
        },
        "7b6ad06aea44487b9d2176a887baadff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f83196081c40969af282970daba8fe",
            "max": 3892,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bf5456dfa9147f39d54e4b8f2c67432",
            "value": 3892
          }
        },
        "425c6125d47c4c88bfd86b4de2714ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09d4c15ed6c7444b95a26c25ff839dc1",
            "placeholder": "​",
            "style": "IPY_MODEL_bd8d1470b2344265b325af62b14a0f79",
            "value": " 3892/3892 [00:00&lt;00:00, 5723.48 examples/s]"
          }
        },
        "15f352652452421fafb6f2e0577ebd6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2ba60ef3374bb5989d5d80c2a826a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b678ab529694b68b33ad6bc5f141265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f83196081c40969af282970daba8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf5456dfa9147f39d54e4b8f2c67432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09d4c15ed6c7444b95a26c25ff839dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8d1470b2344265b325af62b14a0f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cf30525c0754eae87e4709a81aa6aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b63225519d844022b0af5945bcbef227",
              "IPY_MODEL_5d9c350a36d8487db17079e897cbd00c",
              "IPY_MODEL_7495b9b355fe45d99e8e5dcf061049f4"
            ],
            "layout": "IPY_MODEL_5236e1b8c8344962ab8103af711a7135"
          }
        },
        "b63225519d844022b0af5945bcbef227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee4a906ab7e64bdda022d57b424ba822",
            "placeholder": "​",
            "style": "IPY_MODEL_8ab6358233e440c28d3f2e0a0effad2f",
            "value": "Map: 100%"
          }
        },
        "5d9c350a36d8487db17079e897cbd00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a03e363beab466b812f811752f067c6",
            "max": 3892,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e17e91216cd7433a8136c6692d2fd14c",
            "value": 3892
          }
        },
        "7495b9b355fe45d99e8e5dcf061049f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4efdc30bd6954551ac2c1006c9545f3d",
            "placeholder": "​",
            "style": "IPY_MODEL_4e89c96ec0204dd380974ce0c566a03c",
            "value": " 3892/3892 [00:01&lt;00:00, 1834.99 examples/s]"
          }
        },
        "5236e1b8c8344962ab8103af711a7135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee4a906ab7e64bdda022d57b424ba822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ab6358233e440c28d3f2e0a0effad2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a03e363beab466b812f811752f067c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17e91216cd7433a8136c6692d2fd14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4efdc30bd6954551ac2c1006c9545f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e89c96ec0204dd380974ce0c566a03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec56767edb4b4c599a0044b985c54bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97ae0fd3db434198892e1489428d0d72",
              "IPY_MODEL_4da7a83b7a554e64b1d05565b8eb5921",
              "IPY_MODEL_2e77aa4b2a054353b4b06f2c42a3afa0"
            ],
            "layout": "IPY_MODEL_fdc06a0df66d42a8946c1fa92c84f2ef"
          }
        },
        "97ae0fd3db434198892e1489428d0d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7646d9be27489bbe95fd9104bcaf46",
            "placeholder": "​",
            "style": "IPY_MODEL_ff1275c77bb749a7b567bb458d3bb757",
            "value": "Applying chat template to train dataset (num_proc=2): 100%"
          }
        },
        "4da7a83b7a554e64b1d05565b8eb5921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_351b9cf735964a7abe7c17272cd407a5",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0951d61c34544b00a4c08d591c00ff86",
            "value": 100000
          }
        },
        "2e77aa4b2a054353b4b06f2c42a3afa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5eddb0136a2478fb5a1c897639a0a83",
            "placeholder": "​",
            "style": "IPY_MODEL_e307f23140684317af950e255623ec49",
            "value": " 100000/100000 [00:22&lt;00:00, 5311.38 examples/s]"
          }
        },
        "fdc06a0df66d42a8946c1fa92c84f2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7646d9be27489bbe95fd9104bcaf46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1275c77bb749a7b567bb458d3bb757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "351b9cf735964a7abe7c17272cd407a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0951d61c34544b00a4c08d591c00ff86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5eddb0136a2478fb5a1c897639a0a83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e307f23140684317af950e255623ec49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67faf64792d642008489c523d96c4eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fb5579de1624238b679cc2a570b2e35",
              "IPY_MODEL_4298194ebcdc4978942c6921daef6ee1",
              "IPY_MODEL_fc8e5d8aa6f9420b8be3587a23d4cf11"
            ],
            "layout": "IPY_MODEL_2d8b4bedb98d4a3bbf1b81722a6e6913"
          }
        },
        "7fb5579de1624238b679cc2a570b2e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb477982dad4175a81b7642f13be6d5",
            "placeholder": "​",
            "style": "IPY_MODEL_80ecdf89c9694122b4d9800c5379423c",
            "value": "Tokenizing train dataset (num_proc=2): 100%"
          }
        },
        "4298194ebcdc4978942c6921daef6ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9b4f4d935bf4fe4bac461ba690ee1b3",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_100ab9c4651444cab459e6f1ce6d44ec",
            "value": 100000
          }
        },
        "fc8e5d8aa6f9420b8be3587a23d4cf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93e14e92bb094504a2f08d3012ec1dd2",
            "placeholder": "​",
            "style": "IPY_MODEL_b8a06888ef2d4bdaadf879ea2b42b6b6",
            "value": " 100000/100000 [03:31&lt;00:00, 482.26 examples/s]"
          }
        },
        "2d8b4bedb98d4a3bbf1b81722a6e6913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fb477982dad4175a81b7642f13be6d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80ecdf89c9694122b4d9800c5379423c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9b4f4d935bf4fe4bac461ba690ee1b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "100ab9c4651444cab459e6f1ce6d44ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93e14e92bb094504a2f08d3012ec1dd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a06888ef2d4bdaadf879ea2b42b6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cac30dd0a2ea40bc942aecb35bc7b193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38278c13d806430ea440b9dec597ffa0",
              "IPY_MODEL_77a9b15551314a1aa532bc4552aeb944",
              "IPY_MODEL_a673d03531c34bb29dc9f1de2ec077c3"
            ],
            "layout": "IPY_MODEL_2e9eb62494dd4d52b3409d1f88d201e8"
          }
        },
        "38278c13d806430ea440b9dec597ffa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_467892f05d494b7c8451fdbb4007efaa",
            "placeholder": "​",
            "style": "IPY_MODEL_08f085ed3c454ea1ab26097d0daafcf8",
            "value": "Truncating train dataset (num_proc=2): 100%"
          }
        },
        "77a9b15551314a1aa532bc4552aeb944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e84fd6504224c57849942ba4f9ef6cb",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c6daad1e16e4c2e8c96742dca76c43c",
            "value": 100000
          }
        },
        "a673d03531c34bb29dc9f1de2ec077c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_492cd90843c7464ba755c5b0cb113df1",
            "placeholder": "​",
            "style": "IPY_MODEL_19564989d8644c7f86519fa6df478ac4",
            "value": " 100000/100000 [00:07&lt;00:00, 39476.94 examples/s]"
          }
        },
        "2e9eb62494dd4d52b3409d1f88d201e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "467892f05d494b7c8451fdbb4007efaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08f085ed3c454ea1ab26097d0daafcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e84fd6504224c57849942ba4f9ef6cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6daad1e16e4c2e8c96742dca76c43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "492cd90843c7464ba755c5b0cb113df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19564989d8644c7f86519fa6df478ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a8823242d6a47a7909b4d3291917b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b434b28e356045b29dc98c521fd647f0",
              "IPY_MODEL_35008b025f204e1e91ccfbec43dfd886",
              "IPY_MODEL_ef6f7f9d2ddc418c957ba2fb3bb5acbf"
            ],
            "layout": "IPY_MODEL_e7482c4693f7487e9ff219419ae3a214"
          }
        },
        "b434b28e356045b29dc98c521fd647f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59cf3b986bf84d53a2d91a5c804ba0c9",
            "placeholder": "​",
            "style": "IPY_MODEL_e7532d2e5a2d427facd93992358b78c6",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "35008b025f204e1e91ccfbec43dfd886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da4d939c91c49d39c342b2e945476ab",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2637e470e04e499499693a95119e7ddd",
            "value": 100000
          }
        },
        "ef6f7f9d2ddc418c957ba2fb3bb5acbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c8bf3c4504d42f09e1d51226a0e0ead",
            "placeholder": "​",
            "style": "IPY_MODEL_d5285a351f8c47969ebba552c71545d6",
            "value": " 100000/100000 [00:46&lt;00:00, 1823.36 examples/s]"
          }
        },
        "e7482c4693f7487e9ff219419ae3a214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59cf3b986bf84d53a2d91a5c804ba0c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7532d2e5a2d427facd93992358b78c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9da4d939c91c49d39c342b2e945476ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2637e470e04e499499693a95119e7ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c8bf3c4504d42f09e1d51226a0e0ead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5285a351f8c47969ebba552c71545d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}